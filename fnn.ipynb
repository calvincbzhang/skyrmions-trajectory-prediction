{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# change the following to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import trackpy as tp\n",
    "\n",
    "from tqdm import tqdm  # for progress bar\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>mass</th>\n",
       "      <th>size</th>\n",
       "      <th>ecc</th>\n",
       "      <th>signal</th>\n",
       "      <th>raw_mass</th>\n",
       "      <th>ep</th>\n",
       "      <th>frame</th>\n",
       "      <th>particle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24.420047</td>\n",
       "      <td>61.809992</td>\n",
       "      <td>33.895088</td>\n",
       "      <td>3.785002</td>\n",
       "      <td>0.048289</td>\n",
       "      <td>0.451671</td>\n",
       "      <td>91.250977</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31.518261</td>\n",
       "      <td>109.009463</td>\n",
       "      <td>33.850101</td>\n",
       "      <td>3.792741</td>\n",
       "      <td>0.067499</td>\n",
       "      <td>0.455270</td>\n",
       "      <td>91.282349</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>51.658864</td>\n",
       "      <td>41.007417</td>\n",
       "      <td>34.208199</td>\n",
       "      <td>3.811746</td>\n",
       "      <td>0.062159</td>\n",
       "      <td>0.449871</td>\n",
       "      <td>92.517654</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60.994689</td>\n",
       "      <td>82.173861</td>\n",
       "      <td>34.559098</td>\n",
       "      <td>3.818268</td>\n",
       "      <td>0.046138</td>\n",
       "      <td>0.455270</td>\n",
       "      <td>93.368622</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61.572998</td>\n",
       "      <td>129.252586</td>\n",
       "      <td>33.747531</td>\n",
       "      <td>3.807508</td>\n",
       "      <td>0.059245</td>\n",
       "      <td>0.453470</td>\n",
       "      <td>91.835289</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          y           x       mass      size       ecc    signal  \\\n",
       "0           0  24.420047   61.809992  33.895088  3.785002  0.048289  0.451671   \n",
       "1           1  31.518261  109.009463  33.850101  3.792741  0.067499  0.455270   \n",
       "2           2  51.658864   41.007417  34.208199  3.811746  0.062159  0.449871   \n",
       "3           3  60.994689   82.173861  34.559098  3.818268  0.046138  0.455270   \n",
       "4           4  61.572998  129.252586  33.747531  3.807508  0.059245  0.453470   \n",
       "\n",
       "    raw_mass        ep  frame  particle  \n",
       "0  91.250977  0.000493      0         0  \n",
       "1  91.282349  0.000493      0         1  \n",
       "2  92.517654  0.000486      0         2  \n",
       "3  93.368622  0.000482      0         3  \n",
       "4  91.835289  0.000490      0         4  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = 'Rec_EDGE_300K_1L_50MA.out'\n",
    "\n",
    "data = pd.read_csv(directory + '/trajectories.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop the unused columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>frame</th>\n",
       "      <th>particle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.420047</td>\n",
       "      <td>61.809992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.518261</td>\n",
       "      <td>109.009463</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.658864</td>\n",
       "      <td>41.007417</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.994689</td>\n",
       "      <td>82.173861</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.572998</td>\n",
       "      <td>129.252586</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           y           x  frame  particle\n",
       "0  24.420047   61.809992      0         0\n",
       "1  31.518261  109.009463      0         1\n",
       "2  51.658864   41.007417      0         2\n",
       "3  60.994689   82.173861      0         3\n",
       "4  61.572998  129.252586      0         4"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unused_columns = ['Unnamed: 0', 'mass', 'size', 'ecc', 'signal', 'raw_mass', 'ep']\n",
    "\n",
    "data = data.drop(columns=unused_columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill in missing values with average positions (if a skyrmion is missing for more than one frame, it might not be very precise, but it should not be a big issue here)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_skyrmions = data[data['frame'] == 0].shape[0]\n",
    "no_skyrmions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 800/800 [00:15<00:00, 52.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# ids of initial particles\n",
    "ids = list(range(no_skyrmions))\n",
    "\n",
    "# iterate through the frames\n",
    "for f in tqdm(data['frame'].unique()):\n",
    "    for p in range(no_skyrmions):\n",
    "        # this means the skyrmion p is missing in frame f\n",
    "        if not any(data[data['frame'] == f]['particle'] == p):\n",
    "            \n",
    "            # find previous coorinates\n",
    "            x_prev = data[(data['frame'] == f-1) & (data['particle'] == p)]['x'].values[0]\n",
    "            y_prev = data[(data['frame'] == f-1) & (data['particle'] == p)]['y'].values[0]\n",
    "            \n",
    "            x_next = x_prev\n",
    "            y_next = y_prev\n",
    "            \n",
    "            #find next coordinates\n",
    "            for next_frame in range((f+1).astype(int), len(data['frame'].unique())):\n",
    "                if any(data[data['frame'] == f]['particle'] == p):\n",
    "                    x_next = data[(data['frame'] == next_frame) & (data['particle'] == p)]['x'].values[0]\n",
    "                    y_next = data[(data['frame'] == next_frame) & (data['particle'] == p)]['y'].values[0]\n",
    "                    break\n",
    "                    \n",
    "            # new coordinates\n",
    "            x_new = (x_prev + x_next) / 2\n",
    "            y_new = (y_prev + y_next) / 2\n",
    "            \n",
    "            data = data.append({'y' : y_new,\n",
    "                                'x' : x_new,\n",
    "                                'frame' : f,\n",
    "                                'particle': p}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by=['frame', 'particle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>frame</th>\n",
       "      <th>particle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.420047</td>\n",
       "      <td>61.809992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.518261</td>\n",
       "      <td>109.009463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.658864</td>\n",
       "      <td>41.007417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.994689</td>\n",
       "      <td>82.173861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.572998</td>\n",
       "      <td>129.252586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11922</th>\n",
       "      <td>26.838018</td>\n",
       "      <td>9158.734705</td>\n",
       "      <td>799.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11927</th>\n",
       "      <td>92.153535</td>\n",
       "      <td>8909.539660</td>\n",
       "      <td>799.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11935</th>\n",
       "      <td>160.675052</td>\n",
       "      <td>8812.401110</td>\n",
       "      <td>799.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11934</th>\n",
       "      <td>156.663224</td>\n",
       "      <td>8600.194927</td>\n",
       "      <td>799.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>93.779025</td>\n",
       "      <td>8679.555818</td>\n",
       "      <td>799.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                y            x  frame  particle\n",
       "0       24.420047    61.809992    0.0       0.0\n",
       "1       31.518261   109.009463    0.0       1.0\n",
       "2       51.658864    41.007417    0.0       2.0\n",
       "3       60.994689    82.173861    0.0       3.0\n",
       "4       61.572998   129.252586    0.0       4.0\n",
       "...           ...          ...    ...       ...\n",
       "11922   26.838018  9158.734705  799.0      10.0\n",
       "11927   92.153535  8909.539660  799.0      11.0\n",
       "11935  160.675052  8812.401110  799.0      12.0\n",
       "11934  156.663224  8600.194927  799.0      13.0\n",
       "11928   93.779025  8679.555818  799.0      14.0\n",
       "\n",
       "[12000 rows x 4 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that there are no more missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 800/800 [00:00<00:00, 2804.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(data['frame'].unique()):\n",
    "    if (data[data['frame'] == f]['particle'].shape[0] < no_skyrmions):\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put data in list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 800/800 [00:07<00:00, 111.59it/s]\n"
     ]
    }
   ],
   "source": [
    "no_skyrmions = int(max(data[data['frame'] == 0]['particle']) + 1)\n",
    "\n",
    "# iterate through the frames\n",
    "for f in tqdm(data['frame'].unique()):\n",
    "    coordinates = None\n",
    "    for p in data[data['frame'] == f]['particle']:\n",
    "        particle = data[(data['frame'] == f) & (data['particle'] == p)]\n",
    "        coordinates = np.append(coordinates, [particle['x'].values[0], particle['y'].values[0]]) if coordinates is not None else [particle['x'].values[0], particle['y'].values[0]]\n",
    "    \n",
    "    frames = np.append(frames, coordinates) if frames is not None else [coordinates]\n",
    "                                                                        \n",
    "frames = frames.reshape(-1, 2 * no_skyrmions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One image input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make data samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples are (frame, next_frame)\n",
    "\n",
    "X = frames[:-1]\n",
    "y = frames[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data for training and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4162, 30)\n",
      "y_train shape: (4162, 30)\n",
      "X_test shape: (1041, 30)\n",
      "y_test shape: (1041, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"y_train shape: \" + str(y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "\n",
    "optimizer = 'NAdam'\n",
    "loss = 'mae'\n",
    "metrics = ['accuracy']\n",
    "training_epochs = 500\n",
    "batch_size = 64\n",
    "\n",
    "n_input = 2 * no_skyrmions\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 64\n",
    "n_hidden_3 = 64\n",
    "n_output = 2 * no_skyrmions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_1, input_dim=n_input, activation=activation))\n",
    "model.add(Dense(n_hidden_2, activation=activation))\n",
    "model.add(Dense(n_hidden_3, activation=activation))\n",
    "model.add(Dense(n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4162 samples, validate on 1041 samples\n",
      "Epoch 1/500\n",
      "4162/4162 [==============================] - 0s 72us/step - loss: 429.7657 - accuracy: 0.2124 - val_loss: 199.6942 - val_accuracy: 0.3247\n",
      "Epoch 2/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 126.4280 - accuracy: 0.4041 - val_loss: 112.4881 - val_accuracy: 0.3468\n",
      "Epoch 3/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 105.2713 - accuracy: 0.3936 - val_loss: 45.4507 - val_accuracy: 0.3064\n",
      "Epoch 4/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 103.8364 - accuracy: 0.4558 - val_loss: 152.0716 - val_accuracy: 0.3996\n",
      "Epoch 5/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 95.0313 - accuracy: 0.4476 - val_loss: 186.7882 - val_accuracy: 0.5850\n",
      "Epoch 6/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 92.5225 - accuracy: 0.4582 - val_loss: 178.8029 - val_accuracy: 0.2767\n",
      "Epoch 7/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 90.0228 - accuracy: 0.5235 - val_loss: 136.7547 - val_accuracy: 0.6753\n",
      "Epoch 8/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 79.3350 - accuracy: 0.4822 - val_loss: 70.3764 - val_accuracy: 0.4793\n",
      "Epoch 9/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 82.8791 - accuracy: 0.5658 - val_loss: 143.7291 - val_accuracy: 0.4390\n",
      "Epoch 10/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 81.5702 - accuracy: 0.5461 - val_loss: 83.0316 - val_accuracy: 0.4428\n",
      "Epoch 11/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 74.0814 - accuracy: 0.5444 - val_loss: 185.7668 - val_accuracy: 0.4505\n",
      "Epoch 12/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 73.9560 - accuracy: 0.5469 - val_loss: 40.4850 - val_accuracy: 0.6052\n",
      "Epoch 13/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 71.8807 - accuracy: 0.5951 - val_loss: 59.7443 - val_accuracy: 0.5303\n",
      "Epoch 14/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 66.8184 - accuracy: 0.5567 - val_loss: 146.2531 - val_accuracy: 0.6033\n",
      "Epoch 15/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 68.4667 - accuracy: 0.5781 - val_loss: 36.4971 - val_accuracy: 0.5965\n",
      "Epoch 16/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 66.7525 - accuracy: 0.5822 - val_loss: 171.1471 - val_accuracy: 0.5744\n",
      "Epoch 17/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 66.9264 - accuracy: 0.5920 - val_loss: 64.8721 - val_accuracy: 0.6148\n",
      "Epoch 18/500\n",
      "4162/4162 [==============================] - 0s 38us/step - loss: 61.7119 - accuracy: 0.6189 - val_loss: 33.9877 - val_accuracy: 0.5985\n",
      "Epoch 19/500\n",
      "4162/4162 [==============================] - 0s 40us/step - loss: 60.4879 - accuracy: 0.6007 - val_loss: 34.8258 - val_accuracy: 0.6340\n",
      "Epoch 20/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 59.6376 - accuracy: 0.5656 - val_loss: 32.0730 - val_accuracy: 0.6282\n",
      "Epoch 21/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 58.6815 - accuracy: 0.5997 - val_loss: 117.6230 - val_accuracy: 0.7080\n",
      "Epoch 22/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 57.9311 - accuracy: 0.5819 - val_loss: 38.1942 - val_accuracy: 0.6369\n",
      "Epoch 23/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 56.0045 - accuracy: 0.6254 - val_loss: 87.7654 - val_accuracy: 0.6206\n",
      "Epoch 24/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 53.4589 - accuracy: 0.5959 - val_loss: 52.2185 - val_accuracy: 0.4438\n",
      "Epoch 25/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 52.7423 - accuracy: 0.5935 - val_loss: 31.1677 - val_accuracy: 0.7176\n",
      "Epoch 26/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 52.4983 - accuracy: 0.6069 - val_loss: 96.4680 - val_accuracy: 0.5293\n",
      "Epoch 27/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 52.3857 - accuracy: 0.6086 - val_loss: 36.5985 - val_accuracy: 0.6302\n",
      "Epoch 28/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 50.2017 - accuracy: 0.6062 - val_loss: 66.8371 - val_accuracy: 0.5648\n",
      "Epoch 29/500\n",
      "4162/4162 [==============================] - 0s 39us/step - loss: 49.4068 - accuracy: 0.6079 - val_loss: 60.4725 - val_accuracy: 0.6513\n",
      "Epoch 30/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 47.3700 - accuracy: 0.6052 - val_loss: 58.9871 - val_accuracy: 0.5648\n",
      "Epoch 31/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 48.0245 - accuracy: 0.5699 - val_loss: 75.4805 - val_accuracy: 0.6503\n",
      "Epoch 32/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 46.0987 - accuracy: 0.5843 - val_loss: 32.5366 - val_accuracy: 0.6330\n",
      "Epoch 33/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 43.9896 - accuracy: 0.5461 - val_loss: 64.7790 - val_accuracy: 0.6061\n",
      "Epoch 34/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 45.1151 - accuracy: 0.5887 - val_loss: 100.9506 - val_accuracy: 0.6081\n",
      "Epoch 35/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 44.3649 - accuracy: 0.5750 - val_loss: 67.5506 - val_accuracy: 0.5639\n",
      "Epoch 36/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 43.4779 - accuracy: 0.5699 - val_loss: 59.5155 - val_accuracy: 0.6013\n",
      "Epoch 37/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 42.9089 - accuracy: 0.5555 - val_loss: 26.4942 - val_accuracy: 0.6071\n",
      "Epoch 38/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 41.4531 - accuracy: 0.5836 - val_loss: 89.4976 - val_accuracy: 0.5985\n",
      "Epoch 39/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 40.1562 - accuracy: 0.5769 - val_loss: 76.6471 - val_accuracy: 0.5860\n",
      "Epoch 40/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 39.8501 - accuracy: 0.5980 - val_loss: 82.3697 - val_accuracy: 0.5937\n",
      "Epoch 41/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 40.2652 - accuracy: 0.6055 - val_loss: 31.5996 - val_accuracy: 0.6244\n",
      "Epoch 42/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 38.9174 - accuracy: 0.6019 - val_loss: 57.1867 - val_accuracy: 0.5716\n",
      "Epoch 43/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 37.9952 - accuracy: 0.6033 - val_loss: 48.4323 - val_accuracy: 0.6378\n",
      "Epoch 44/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 37.5626 - accuracy: 0.5889 - val_loss: 45.7510 - val_accuracy: 0.5658\n",
      "Epoch 45/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 37.0720 - accuracy: 0.5954 - val_loss: 57.5576 - val_accuracy: 0.4659\n",
      "Epoch 46/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 37.5946 - accuracy: 0.5778 - val_loss: 28.6285 - val_accuracy: 0.4179\n",
      "Epoch 47/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 35.9938 - accuracy: 0.5961 - val_loss: 112.4565 - val_accuracy: 0.6196\n",
      "Epoch 48/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 36.5027 - accuracy: 0.5949 - val_loss: 75.3545 - val_accuracy: 0.6215\n",
      "Epoch 49/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 35.1286 - accuracy: 0.6093 - val_loss: 28.6972 - val_accuracy: 0.6609\n",
      "Epoch 50/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 33.7877 - accuracy: 0.6177 - val_loss: 37.3784 - val_accuracy: 0.6359\n",
      "Epoch 51/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 33.9918 - accuracy: 0.6129 - val_loss: 25.3739 - val_accuracy: 0.6695\n",
      "Epoch 52/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 33.6547 - accuracy: 0.6180 - val_loss: 24.8197 - val_accuracy: 0.6081\n",
      "Epoch 53/500\n",
      "4162/4162 [==============================] - ETA: 0s - loss: 34.1839 - accuracy: 0.611 - 0s 34us/step - loss: 33.0268 - accuracy: 0.6115 - val_loss: 32.5016 - val_accuracy: 0.4861\n",
      "Epoch 54/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 32.5126 - accuracy: 0.6019 - val_loss: 26.3389 - val_accuracy: 0.6378\n",
      "Epoch 55/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 31.6598 - accuracy: 0.6261 - val_loss: 57.6484 - val_accuracy: 0.5850\n",
      "Epoch 56/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 31.0945 - accuracy: 0.6110 - val_loss: 71.0988 - val_accuracy: 0.6311\n",
      "Epoch 57/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 31.7219 - accuracy: 0.6100 - val_loss: 44.2241 - val_accuracy: 0.4640\n",
      "Epoch 58/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 30.5532 - accuracy: 0.6141 - val_loss: 45.8896 - val_accuracy: 0.6417\n",
      "Epoch 59/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 30.8831 - accuracy: 0.6105 - val_loss: 72.4536 - val_accuracy: 0.6311\n",
      "Epoch 60/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 30.2877 - accuracy: 0.6086 - val_loss: 66.5745 - val_accuracy: 0.5725\n",
      "Epoch 61/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 30.4127 - accuracy: 0.6314 - val_loss: 28.6907 - val_accuracy: 0.6475\n",
      "Epoch 62/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 28.9170 - accuracy: 0.6406 - val_loss: 54.9736 - val_accuracy: 0.6311\n",
      "Epoch 63/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 30.0057 - accuracy: 0.6326 - val_loss: 31.6311 - val_accuracy: 0.6244\n",
      "Epoch 64/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 28.8026 - accuracy: 0.6348 - val_loss: 31.0809 - val_accuracy: 0.6407\n",
      "Epoch 65/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 28.7115 - accuracy: 0.6360 - val_loss: 41.1560 - val_accuracy: 0.6254\n",
      "Epoch 66/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 28.7190 - accuracy: 0.6273 - val_loss: 27.9257 - val_accuracy: 0.6148\n",
      "Epoch 67/500\n",
      "4162/4162 [==============================] - ETA: 0s - loss: 28.1160 - accuracy: 0.635 - 0s 35us/step - loss: 28.0515 - accuracy: 0.6314 - val_loss: 27.5966 - val_accuracy: 0.6330\n",
      "Epoch 68/500\n",
      "4162/4162 [==============================] - ETA: 0s - loss: 29.0571 - accuracy: 0.623 - 0s 37us/step - loss: 28.1626 - accuracy: 0.6201 - val_loss: 48.8169 - val_accuracy: 0.6273\n",
      "Epoch 69/500\n",
      "4162/4162 [==============================] - ETA: 0s - loss: 26.5563 - accuracy: 0.608 - 0s 35us/step - loss: 27.6168 - accuracy: 0.6086 - val_loss: 28.9414 - val_accuracy: 0.5677\n",
      "Epoch 70/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 27.3018 - accuracy: 0.6151 - val_loss: 36.9537 - val_accuracy: 0.5408\n",
      "Epoch 71/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 26.9294 - accuracy: 0.6259 - val_loss: 61.8621 - val_accuracy: 0.6599\n",
      "Epoch 72/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 26.8509 - accuracy: 0.6276 - val_loss: 62.8755 - val_accuracy: 0.6110\n",
      "Epoch 73/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 25.9486 - accuracy: 0.6406 - val_loss: 30.3580 - val_accuracy: 0.5130\n",
      "Epoch 74/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 26.6733 - accuracy: 0.6300 - val_loss: 28.0574 - val_accuracy: 0.6465\n",
      "Epoch 75/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 25.7809 - accuracy: 0.6451 - val_loss: 39.5928 - val_accuracy: 0.6388\n",
      "Epoch 76/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 26.1744 - accuracy: 0.6326 - val_loss: 54.1747 - val_accuracy: 0.6436\n",
      "Epoch 77/500\n",
      "4162/4162 [==============================] - 0s 38us/step - loss: 25.0720 - accuracy: 0.6242 - val_loss: 26.6828 - val_accuracy: 0.5994\n",
      "Epoch 78/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 24.9908 - accuracy: 0.6348 - val_loss: 36.0049 - val_accuracy: 0.6292\n",
      "Epoch 79/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 25.1977 - accuracy: 0.6295 - val_loss: 41.8750 - val_accuracy: 0.6820\n",
      "Epoch 80/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 25.3849 - accuracy: 0.6372 - val_loss: 58.6579 - val_accuracy: 0.4784\n",
      "Epoch 81/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 24.8490 - accuracy: 0.6379 - val_loss: 35.9889 - val_accuracy: 0.6254\n",
      "Epoch 82/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 24.4388 - accuracy: 0.6398 - val_loss: 24.7564 - val_accuracy: 0.6340\n",
      "Epoch 83/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 24.4346 - accuracy: 0.6379 - val_loss: 25.5100 - val_accuracy: 0.6148\n",
      "Epoch 84/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 24.2577 - accuracy: 0.6415 - val_loss: 64.2748 - val_accuracy: 0.6177\n",
      "Epoch 85/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 23.9275 - accuracy: 0.6350 - val_loss: 34.0914 - val_accuracy: 0.6494\n",
      "Epoch 86/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 24.1588 - accuracy: 0.6432 - val_loss: 62.4541 - val_accuracy: 0.6532\n",
      "Epoch 87/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 23.9920 - accuracy: 0.6283 - val_loss: 49.1575 - val_accuracy: 0.7281\n",
      "Epoch 88/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 23.1933 - accuracy: 0.6235 - val_loss: 25.2438 - val_accuracy: 0.5956\n",
      "Epoch 89/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 22.5114 - accuracy: 0.6168 - val_loss: 53.1887 - val_accuracy: 0.5725\n",
      "Epoch 90/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 23.2375 - accuracy: 0.6187 - val_loss: 30.5188 - val_accuracy: 0.5965\n",
      "Epoch 91/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 22.9954 - accuracy: 0.6199 - val_loss: 26.3800 - val_accuracy: 0.6407\n",
      "Epoch 92/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 22.1355 - accuracy: 0.6249 - val_loss: 23.4657 - val_accuracy: 0.6407\n",
      "Epoch 93/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 22.0211 - accuracy: 0.6309 - val_loss: 25.0003 - val_accuracy: 0.6465\n",
      "Epoch 94/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 22.6712 - accuracy: 0.6269 - val_loss: 28.3371 - val_accuracy: 0.6638\n",
      "Epoch 95/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 22.6076 - accuracy: 0.6319 - val_loss: 51.9780 - val_accuracy: 0.6609\n",
      "Epoch 96/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 22.2284 - accuracy: 0.6153 - val_loss: 33.2569 - val_accuracy: 0.6167\n",
      "Epoch 97/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 22.0458 - accuracy: 0.6132 - val_loss: 27.3268 - val_accuracy: 0.6177\n",
      "Epoch 98/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 22.2091 - accuracy: 0.6451 - val_loss: 50.9515 - val_accuracy: 0.7022\n",
      "Epoch 99/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 22.0468 - accuracy: 0.6168 - val_loss: 33.3478 - val_accuracy: 0.6023\n",
      "Epoch 100/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 21.1802 - accuracy: 0.6163 - val_loss: 26.2897 - val_accuracy: 0.6206\n",
      "Epoch 101/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 21.7886 - accuracy: 0.6189 - val_loss: 41.6120 - val_accuracy: 0.6311\n",
      "Epoch 102/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 20.9664 - accuracy: 0.6185 - val_loss: 43.0792 - val_accuracy: 0.6340\n",
      "Epoch 103/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 21.3352 - accuracy: 0.6038 - val_loss: 62.1747 - val_accuracy: 0.5793\n",
      "Epoch 104/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 21.4118 - accuracy: 0.5968 - val_loss: 42.6990 - val_accuracy: 0.6590\n",
      "Epoch 105/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 20.6226 - accuracy: 0.6158 - val_loss: 23.4372 - val_accuracy: 0.6148\n",
      "Epoch 106/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 21.1118 - accuracy: 0.5954 - val_loss: 24.3381 - val_accuracy: 0.6628\n",
      "Epoch 107/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 20.6902 - accuracy: 0.6252 - val_loss: 51.9708 - val_accuracy: 0.6282\n",
      "Epoch 108/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 20.9896 - accuracy: 0.6108 - val_loss: 60.7510 - val_accuracy: 0.4553\n",
      "Epoch 109/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 20.9666 - accuracy: 0.5721 - val_loss: 23.0898 - val_accuracy: 0.5927\n",
      "Epoch 110/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 20.6454 - accuracy: 0.5887 - val_loss: 44.7174 - val_accuracy: 0.6561\n",
      "Epoch 111/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 20.9068 - accuracy: 0.5887 - val_loss: 56.5392 - val_accuracy: 0.4822\n",
      "Epoch 112/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 20.4074 - accuracy: 0.5822 - val_loss: 23.9336 - val_accuracy: 0.5725\n",
      "Epoch 113/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 20.0952 - accuracy: 0.5894 - val_loss: 52.5427 - val_accuracy: 0.6071\n",
      "Epoch 114/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 19.9029 - accuracy: 0.6050 - val_loss: 23.0526 - val_accuracy: 0.6407\n",
      "Epoch 115/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 19.7394 - accuracy: 0.6007 - val_loss: 27.3520 - val_accuracy: 0.5744\n",
      "Epoch 116/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 19.8895 - accuracy: 0.6093 - val_loss: 22.6511 - val_accuracy: 0.6196\n",
      "Epoch 117/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 19.5615 - accuracy: 0.6012 - val_loss: 39.9686 - val_accuracy: 0.6110\n",
      "Epoch 118/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 19.9773 - accuracy: 0.6038 - val_loss: 29.2625 - val_accuracy: 0.5841\n",
      "Epoch 119/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 19.4448 - accuracy: 0.6009 - val_loss: 24.0971 - val_accuracy: 0.6282\n",
      "Epoch 120/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 19.0915 - accuracy: 0.6194 - val_loss: 30.2438 - val_accuracy: 0.6282\n",
      "Epoch 121/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 19.3107 - accuracy: 0.6326 - val_loss: 28.8819 - val_accuracy: 0.5091\n",
      "Epoch 122/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 19.5642 - accuracy: 0.6021 - val_loss: 35.8277 - val_accuracy: 0.5552\n",
      "Epoch 123/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 19.6416 - accuracy: 0.6074 - val_loss: 36.1719 - val_accuracy: 0.6378\n",
      "Epoch 124/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 18.8803 - accuracy: 0.6072 - val_loss: 45.3698 - val_accuracy: 0.6417\n",
      "Epoch 125/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 19.0931 - accuracy: 0.6105 - val_loss: 31.9009 - val_accuracy: 0.6206\n",
      "Epoch 126/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 19.0986 - accuracy: 0.6028 - val_loss: 43.5843 - val_accuracy: 0.6302\n",
      "Epoch 127/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 18.3779 - accuracy: 0.6055 - val_loss: 30.6048 - val_accuracy: 0.5610\n",
      "Epoch 128/500\n",
      "4162/4162 [==============================] - 0s 39us/step - loss: 18.7542 - accuracy: 0.6002 - val_loss: 26.5504 - val_accuracy: 0.6244\n",
      "Epoch 129/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 18.6755 - accuracy: 0.6305 - val_loss: 25.1884 - val_accuracy: 0.5677\n",
      "Epoch 130/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 18.7204 - accuracy: 0.6182 - val_loss: 43.3813 - val_accuracy: 0.6340\n",
      "Epoch 131/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 18.6798 - accuracy: 0.6048 - val_loss: 24.5887 - val_accuracy: 0.6609\n",
      "Epoch 132/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 18.5447 - accuracy: 0.6168 - val_loss: 44.0053 - val_accuracy: 0.6359\n",
      "Epoch 133/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 18.6921 - accuracy: 0.6108 - val_loss: 53.0494 - val_accuracy: 0.6321\n",
      "Epoch 134/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 18.3513 - accuracy: 0.6302 - val_loss: 36.2975 - val_accuracy: 0.6206\n",
      "Epoch 135/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 18.1476 - accuracy: 0.6233 - val_loss: 22.6361 - val_accuracy: 0.6158\n",
      "Epoch 136/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 18.1811 - accuracy: 0.6093 - val_loss: 26.5214 - val_accuracy: 0.6369\n",
      "Epoch 137/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 18.3819 - accuracy: 0.6245 - val_loss: 24.1663 - val_accuracy: 0.6523\n",
      "Epoch 138/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 18.2805 - accuracy: 0.5954 - val_loss: 33.9462 - val_accuracy: 0.6503\n",
      "Epoch 139/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 18.2797 - accuracy: 0.5817 - val_loss: 23.9057 - val_accuracy: 0.5841\n",
      "Epoch 140/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 18.0562 - accuracy: 0.6117 - val_loss: 26.1338 - val_accuracy: 0.6186\n",
      "Epoch 141/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 17.8470 - accuracy: 0.6007 - val_loss: 45.2850 - val_accuracy: 0.6177\n",
      "Epoch 142/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 17.8226 - accuracy: 0.6204 - val_loss: 23.1810 - val_accuracy: 0.6263\n",
      "Epoch 143/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 17.3466 - accuracy: 0.6221 - val_loss: 57.4871 - val_accuracy: 0.6513\n",
      "Epoch 144/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 17.9957 - accuracy: 0.6163 - val_loss: 24.1370 - val_accuracy: 0.6350\n",
      "Epoch 145/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 17.6852 - accuracy: 0.6206 - val_loss: 23.3044 - val_accuracy: 0.6484\n",
      "Epoch 146/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 17.4026 - accuracy: 0.6168 - val_loss: 29.2501 - val_accuracy: 0.6311\n",
      "Epoch 147/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 17.7020 - accuracy: 0.6100 - val_loss: 30.1589 - val_accuracy: 0.6974\n",
      "Epoch 148/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 17.2258 - accuracy: 0.6261 - val_loss: 22.7065 - val_accuracy: 0.6551\n",
      "Epoch 149/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 17.5210 - accuracy: 0.6105 - val_loss: 38.6196 - val_accuracy: 0.5802\n",
      "Epoch 150/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 17.5436 - accuracy: 0.6105 - val_loss: 21.9481 - val_accuracy: 0.6100\n",
      "Epoch 151/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 17.2934 - accuracy: 0.6148 - val_loss: 33.8121 - val_accuracy: 0.6571\n",
      "Epoch 152/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 17.0166 - accuracy: 0.6290 - val_loss: 24.5972 - val_accuracy: 0.6407\n",
      "Epoch 153/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 17.2391 - accuracy: 0.6463 - val_loss: 44.3413 - val_accuracy: 0.5879\n",
      "Epoch 154/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 17.2262 - accuracy: 0.6353 - val_loss: 24.9884 - val_accuracy: 0.6446\n",
      "Epoch 155/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 17.3376 - accuracy: 0.6348 - val_loss: 29.3245 - val_accuracy: 0.6177\n",
      "Epoch 156/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 17.0038 - accuracy: 0.6437 - val_loss: 26.2042 - val_accuracy: 0.6494\n",
      "Epoch 157/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 16.8339 - accuracy: 0.6213 - val_loss: 27.8393 - val_accuracy: 0.6446\n",
      "Epoch 158/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 17.0354 - accuracy: 0.6341 - val_loss: 63.3693 - val_accuracy: 0.6436\n",
      "Epoch 159/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 17.2299 - accuracy: 0.6358 - val_loss: 57.6875 - val_accuracy: 0.6513\n",
      "Epoch 160/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 17.1189 - accuracy: 0.6439 - val_loss: 32.0614 - val_accuracy: 0.6378\n",
      "Epoch 161/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.8277 - accuracy: 0.6343 - val_loss: 24.6814 - val_accuracy: 0.6455\n",
      "Epoch 162/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.6095 - accuracy: 0.6468 - val_loss: 24.1452 - val_accuracy: 0.6455\n",
      "Epoch 163/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 16.4595 - accuracy: 0.6446 - val_loss: 26.3197 - val_accuracy: 0.6042\n",
      "Epoch 164/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.7292 - accuracy: 0.6490 - val_loss: 27.7697 - val_accuracy: 0.6503\n",
      "Epoch 165/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 16.6375 - accuracy: 0.6309 - val_loss: 31.8356 - val_accuracy: 0.6350\n",
      "Epoch 166/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 16.3313 - accuracy: 0.6338 - val_loss: 39.2309 - val_accuracy: 0.6398\n",
      "Epoch 167/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 16.6879 - accuracy: 0.6446 - val_loss: 29.7601 - val_accuracy: 0.6599\n",
      "Epoch 168/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.2628 - accuracy: 0.6499 - val_loss: 35.4680 - val_accuracy: 0.6340\n",
      "Epoch 169/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 16.2857 - accuracy: 0.6660 - val_loss: 30.3520 - val_accuracy: 0.6407\n",
      "Epoch 170/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 16.9172 - accuracy: 0.6377 - val_loss: 30.8527 - val_accuracy: 0.6225\n",
      "Epoch 171/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 16.4812 - accuracy: 0.6519 - val_loss: 25.1681 - val_accuracy: 0.6311\n",
      "Epoch 172/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.3888 - accuracy: 0.6600 - val_loss: 55.4241 - val_accuracy: 0.7329\n",
      "Epoch 173/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 16.3570 - accuracy: 0.6434 - val_loss: 27.9953 - val_accuracy: 0.6398\n",
      "Epoch 174/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.5911 - accuracy: 0.6391 - val_loss: 22.5599 - val_accuracy: 0.6436\n",
      "Epoch 175/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.3704 - accuracy: 0.6547 - val_loss: 29.9187 - val_accuracy: 0.6282\n",
      "Epoch 176/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.1765 - accuracy: 0.6600 - val_loss: 21.9484 - val_accuracy: 0.6868\n",
      "Epoch 177/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.2982 - accuracy: 0.6531 - val_loss: 41.7573 - val_accuracy: 0.6561\n",
      "Epoch 178/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 16.4792 - accuracy: 0.6586 - val_loss: 31.8838 - val_accuracy: 0.6340\n",
      "Epoch 179/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.0500 - accuracy: 0.6591 - val_loss: 41.1729 - val_accuracy: 0.7157\n",
      "Epoch 180/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.2119 - accuracy: 0.6728 - val_loss: 30.3861 - val_accuracy: 0.6263\n",
      "Epoch 181/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 15.8416 - accuracy: 0.6665 - val_loss: 37.8807 - val_accuracy: 0.6446\n",
      "Epoch 182/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.9342 - accuracy: 0.6728 - val_loss: 28.0719 - val_accuracy: 0.6311\n",
      "Epoch 183/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 15.9907 - accuracy: 0.6795 - val_loss: 28.7462 - val_accuracy: 0.6436\n",
      "Epoch 184/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 15.7260 - accuracy: 0.6639 - val_loss: 22.8937 - val_accuracy: 0.6378\n",
      "Epoch 185/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 16.1778 - accuracy: 0.6720 - val_loss: 31.4909 - val_accuracy: 0.6503\n",
      "Epoch 186/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 16.0318 - accuracy: 0.6569 - val_loss: 21.8478 - val_accuracy: 0.6273\n",
      "Epoch 187/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.8755 - accuracy: 0.6747 - val_loss: 28.1393 - val_accuracy: 0.6388\n",
      "Epoch 188/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.8765 - accuracy: 0.6819 - val_loss: 57.4070 - val_accuracy: 0.6378\n",
      "Epoch 189/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 16.0486 - accuracy: 0.6643 - val_loss: 41.7407 - val_accuracy: 0.6494\n",
      "Epoch 190/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 15.7897 - accuracy: 0.6860 - val_loss: 23.2852 - val_accuracy: 0.7781\n",
      "Epoch 191/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.8495 - accuracy: 0.6843 - val_loss: 48.1827 - val_accuracy: 0.6523\n",
      "Epoch 192/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.7940 - accuracy: 0.6877 - val_loss: 49.7036 - val_accuracy: 0.8463\n",
      "Epoch 193/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.9804 - accuracy: 0.6985 - val_loss: 31.0677 - val_accuracy: 0.6330\n",
      "Epoch 194/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.7651 - accuracy: 0.6845 - val_loss: 21.7408 - val_accuracy: 0.7061\n",
      "Epoch 195/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.5162 - accuracy: 0.6852 - val_loss: 29.4852 - val_accuracy: 0.6446\n",
      "Epoch 196/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.7198 - accuracy: 0.6901 - val_loss: 22.7958 - val_accuracy: 0.6436\n",
      "Epoch 197/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.6602 - accuracy: 0.6893 - val_loss: 29.9324 - val_accuracy: 0.6061\n",
      "Epoch 198/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 15.5432 - accuracy: 0.6901 - val_loss: 21.7739 - val_accuracy: 0.6369\n",
      "Epoch 199/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.5014 - accuracy: 0.7093 - val_loss: 31.0812 - val_accuracy: 0.6436\n",
      "Epoch 200/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 16.0227 - accuracy: 0.6872 - val_loss: 22.2922 - val_accuracy: 0.7714\n",
      "Epoch 201/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.7452 - accuracy: 0.6977 - val_loss: 32.8948 - val_accuracy: 0.7454\n",
      "Epoch 202/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.4160 - accuracy: 0.6944 - val_loss: 24.9793 - val_accuracy: 0.6350\n",
      "Epoch 203/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.8015 - accuracy: 0.6953 - val_loss: 34.1426 - val_accuracy: 0.7032\n",
      "Epoch 204/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 15.7009 - accuracy: 0.6927 - val_loss: 29.7783 - val_accuracy: 0.6330\n",
      "Epoch 205/500\n",
      "4162/4162 [==============================] - ETA: 0s - loss: 15.6310 - accuracy: 0.706 - 0s 35us/step - loss: 15.4212 - accuracy: 0.7062 - val_loss: 32.7194 - val_accuracy: 0.6647\n",
      "Epoch 206/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.2249 - accuracy: 0.6941 - val_loss: 28.1792 - val_accuracy: 0.6801\n",
      "Epoch 207/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.3205 - accuracy: 0.7148 - val_loss: 53.7841 - val_accuracy: 0.7426\n",
      "Epoch 208/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 16.3188 - accuracy: 0.6720 - val_loss: 36.8694 - val_accuracy: 0.7291\n",
      "Epoch 209/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.6658 - accuracy: 0.6855 - val_loss: 23.7326 - val_accuracy: 0.6167\n",
      "Epoch 210/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 15.2118 - accuracy: 0.6764 - val_loss: 24.7599 - val_accuracy: 0.6292\n",
      "Epoch 211/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.2951 - accuracy: 0.6766 - val_loss: 32.0021 - val_accuracy: 0.6503\n",
      "Epoch 212/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.6386 - accuracy: 0.6718 - val_loss: 48.6189 - val_accuracy: 0.6695\n",
      "Epoch 213/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.4069 - accuracy: 0.6780 - val_loss: 21.4015 - val_accuracy: 0.6455\n",
      "Epoch 214/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.2524 - accuracy: 0.6855 - val_loss: 53.1997 - val_accuracy: 0.6455\n",
      "Epoch 215/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 15.3957 - accuracy: 0.6864 - val_loss: 21.5712 - val_accuracy: 0.6484\n",
      "Epoch 216/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 15.4000 - accuracy: 0.6956 - val_loss: 21.8704 - val_accuracy: 0.6475\n",
      "Epoch 217/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.2306 - accuracy: 0.6780 - val_loss: 35.5699 - val_accuracy: 0.6667\n",
      "Epoch 218/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.3654 - accuracy: 0.7028 - val_loss: 29.7349 - val_accuracy: 0.6455\n",
      "Epoch 219/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.1762 - accuracy: 0.6949 - val_loss: 32.9492 - val_accuracy: 0.6330\n",
      "Epoch 220/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.4231 - accuracy: 0.7013 - val_loss: 24.9020 - val_accuracy: 0.6263\n",
      "Epoch 221/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.3669 - accuracy: 0.6963 - val_loss: 30.4343 - val_accuracy: 0.6436\n",
      "Epoch 222/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.5242 - accuracy: 0.7040 - val_loss: 32.1972 - val_accuracy: 0.6158\n",
      "Epoch 223/500\n",
      "4162/4162 [==============================] - 0s 40us/step - loss: 15.4430 - accuracy: 0.7268 - val_loss: 31.9703 - val_accuracy: 0.6532\n",
      "Epoch 224/500\n",
      "4162/4162 [==============================] - 0s 42us/step - loss: 15.4069 - accuracy: 0.7119 - val_loss: 25.5507 - val_accuracy: 0.6686\n",
      "Epoch 225/500\n",
      "4162/4162 [==============================] - 0s 40us/step - loss: 14.9724 - accuracy: 0.7347 - val_loss: 22.6845 - val_accuracy: 0.6225\n",
      "Epoch 226/500\n",
      "4162/4162 [==============================] - 0s 41us/step - loss: 15.2355 - accuracy: 0.7393 - val_loss: 25.2556 - val_accuracy: 0.7531\n",
      "Epoch 227/500\n",
      "4162/4162 [==============================] - 0s 40us/step - loss: 15.5607 - accuracy: 0.7235 - val_loss: 22.5794 - val_accuracy: 0.6599\n",
      "Epoch 228/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 15.1306 - accuracy: 0.7244 - val_loss: 22.6236 - val_accuracy: 0.6340\n",
      "Epoch 229/500\n",
      "4162/4162 [==============================] - 0s 38us/step - loss: 15.2380 - accuracy: 0.7345 - val_loss: 22.9065 - val_accuracy: 0.6475\n",
      "Epoch 230/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.2696 - accuracy: 0.7369 - val_loss: 31.1465 - val_accuracy: 0.7858\n",
      "Epoch 231/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 15.6239 - accuracy: 0.7494 - val_loss: 44.6666 - val_accuracy: 0.6330\n",
      "Epoch 232/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 15.1711 - accuracy: 0.7268 - val_loss: 47.0221 - val_accuracy: 0.6427\n",
      "Epoch 233/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 15.4579 - accuracy: 0.7520 - val_loss: 28.5050 - val_accuracy: 0.6513\n",
      "Epoch 234/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 15.2408 - accuracy: 0.7578 - val_loss: 53.4298 - val_accuracy: 0.6388\n",
      "Epoch 235/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 15.6452 - accuracy: 0.7446 - val_loss: 21.4770 - val_accuracy: 0.6494\n",
      "Epoch 236/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.2337 - accuracy: 0.7511 - val_loss: 37.0112 - val_accuracy: 0.6475\n",
      "Epoch 237/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.7875 - accuracy: 0.7451 - val_loss: 32.4098 - val_accuracy: 0.6571\n",
      "Epoch 238/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 15.4497 - accuracy: 0.7600 - val_loss: 21.9252 - val_accuracy: 0.6484\n",
      "Epoch 239/500\n",
      "4162/4162 [==============================] - 0s 38us/step - loss: 14.5809 - accuracy: 0.7530 - val_loss: 43.7450 - val_accuracy: 0.6705\n",
      "Epoch 240/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 15.0532 - accuracy: 0.7631 - val_loss: 42.2167 - val_accuracy: 0.6551\n",
      "Epoch 241/500\n",
      "4162/4162 [==============================] - 0s 38us/step - loss: 15.4877 - accuracy: 0.7547 - val_loss: 51.7671 - val_accuracy: 0.7666\n",
      "Epoch 242/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.3193 - accuracy: 0.7576 - val_loss: 61.8831 - val_accuracy: 0.7819\n",
      "Epoch 243/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 15.8048 - accuracy: 0.7561 - val_loss: 56.0884 - val_accuracy: 0.6503\n",
      "Epoch 244/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 15.6600 - accuracy: 0.7475 - val_loss: 22.8036 - val_accuracy: 0.7733\n",
      "Epoch 245/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 14.8387 - accuracy: 0.7629 - val_loss: 22.4735 - val_accuracy: 0.8002\n",
      "Epoch 246/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 14.8120 - accuracy: 0.7633 - val_loss: 31.0362 - val_accuracy: 0.6244\n",
      "Epoch 247/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.1487 - accuracy: 0.7679 - val_loss: 21.4649 - val_accuracy: 0.8021\n",
      "Epoch 248/500\n",
      "4162/4162 [==============================] - 0s 39us/step - loss: 14.6901 - accuracy: 0.7595 - val_loss: 22.9350 - val_accuracy: 0.7426\n",
      "Epoch 249/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.8704 - accuracy: 0.7698 - val_loss: 26.8838 - val_accuracy: 0.7646\n",
      "Epoch 250/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.9259 - accuracy: 0.7838 - val_loss: 34.2839 - val_accuracy: 0.6350\n",
      "Epoch 251/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 15.0101 - accuracy: 0.7573 - val_loss: 22.4671 - val_accuracy: 0.6427\n",
      "Epoch 252/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.8101 - accuracy: 0.7722 - val_loss: 38.3716 - val_accuracy: 0.7637\n",
      "Epoch 253/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.7106 - accuracy: 0.7765 - val_loss: 22.2717 - val_accuracy: 0.8261\n",
      "Epoch 254/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.8092 - accuracy: 0.7790 - val_loss: 22.6307 - val_accuracy: 0.6753\n",
      "Epoch 255/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.9336 - accuracy: 0.7571 - val_loss: 21.6281 - val_accuracy: 0.7666\n",
      "Epoch 256/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 14.9531 - accuracy: 0.7703 - val_loss: 24.5828 - val_accuracy: 0.7983\n",
      "Epoch 257/500\n",
      "4162/4162 [==============================] - 0s 39us/step - loss: 14.9317 - accuracy: 0.7626 - val_loss: 29.4144 - val_accuracy: 0.7118\n",
      "Epoch 258/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 14.8811 - accuracy: 0.7607 - val_loss: 27.9400 - val_accuracy: 0.6494\n",
      "Epoch 259/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.5159 - accuracy: 0.7746 - val_loss: 30.5634 - val_accuracy: 0.7906\n",
      "Epoch 260/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.7808 - accuracy: 0.7883 - val_loss: 22.0121 - val_accuracy: 0.7714\n",
      "Epoch 261/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 14.8409 - accuracy: 0.7833 - val_loss: 21.7821 - val_accuracy: 0.6638\n",
      "Epoch 262/500\n",
      "4162/4162 [==============================] - 0s 39us/step - loss: 14.6812 - accuracy: 0.7818 - val_loss: 38.3337 - val_accuracy: 0.7061\n",
      "Epoch 263/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.7573 - accuracy: 0.7845 - val_loss: 25.1665 - val_accuracy: 0.7166\n",
      "Epoch 264/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 15.0402 - accuracy: 0.7842 - val_loss: 27.9881 - val_accuracy: 0.7627\n",
      "Epoch 265/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.9254 - accuracy: 0.7938 - val_loss: 24.2398 - val_accuracy: 0.6484\n",
      "Epoch 266/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.7833 - accuracy: 0.7763 - val_loss: 41.2712 - val_accuracy: 0.7954\n",
      "Epoch 267/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.7520 - accuracy: 0.7850 - val_loss: 21.8958 - val_accuracy: 0.6311\n",
      "Epoch 268/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.6515 - accuracy: 0.7914 - val_loss: 34.6092 - val_accuracy: 0.6820\n",
      "Epoch 269/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.7684 - accuracy: 0.7732 - val_loss: 28.9482 - val_accuracy: 0.7752\n",
      "Epoch 270/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.7331 - accuracy: 0.7778 - val_loss: 24.6259 - val_accuracy: 0.7800\n",
      "Epoch 271/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.6767 - accuracy: 0.7912 - val_loss: 28.6291 - val_accuracy: 0.8040\n",
      "Epoch 272/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.8386 - accuracy: 0.7710 - val_loss: 23.1216 - val_accuracy: 0.7608\n",
      "Epoch 273/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.2722 - accuracy: 0.7929 - val_loss: 28.3544 - val_accuracy: 0.7791\n",
      "Epoch 274/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.6810 - accuracy: 0.7773 - val_loss: 32.8179 - val_accuracy: 0.7637\n",
      "Epoch 275/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.9094 - accuracy: 0.7828 - val_loss: 26.6294 - val_accuracy: 0.6609\n",
      "Epoch 276/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.5405 - accuracy: 0.7854 - val_loss: 40.0665 - val_accuracy: 0.6532\n",
      "Epoch 277/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.4280 - accuracy: 0.8001 - val_loss: 30.5289 - val_accuracy: 0.6705\n",
      "Epoch 278/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.9415 - accuracy: 0.7948 - val_loss: 24.5048 - val_accuracy: 0.6609\n",
      "Epoch 279/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.9131 - accuracy: 0.7806 - val_loss: 35.5058 - val_accuracy: 0.7531\n",
      "Epoch 280/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.2394 - accuracy: 0.7828 - val_loss: 33.7858 - val_accuracy: 0.6369\n",
      "Epoch 281/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.4126 - accuracy: 0.7689 - val_loss: 26.4123 - val_accuracy: 0.6993\n",
      "Epoch 282/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.8835 - accuracy: 0.7638 - val_loss: 24.4095 - val_accuracy: 0.7963\n",
      "Epoch 283/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.5993 - accuracy: 0.8006 - val_loss: 24.2928 - val_accuracy: 0.8280\n",
      "Epoch 284/500\n",
      "4162/4162 [==============================] - 0s 30us/step - loss: 14.2585 - accuracy: 0.8078 - val_loss: 34.7122 - val_accuracy: 0.8521\n",
      "Epoch 285/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 14.5398 - accuracy: 0.7938 - val_loss: 22.8944 - val_accuracy: 0.8127\n",
      "Epoch 286/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.3935 - accuracy: 0.8020 - val_loss: 34.7401 - val_accuracy: 0.6494\n",
      "Epoch 287/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.4743 - accuracy: 0.7979 - val_loss: 25.1206 - val_accuracy: 0.7185\n",
      "Epoch 288/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.4911 - accuracy: 0.7898 - val_loss: 31.4894 - val_accuracy: 0.8492\n",
      "Epoch 289/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.6479 - accuracy: 0.8027 - val_loss: 41.0310 - val_accuracy: 0.6571\n",
      "Epoch 290/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.6851 - accuracy: 0.7955 - val_loss: 24.4274 - val_accuracy: 0.7435\n",
      "Epoch 291/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.5164 - accuracy: 0.8032 - val_loss: 25.8621 - val_accuracy: 0.7570\n",
      "Epoch 292/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.3909 - accuracy: 0.8073 - val_loss: 25.5566 - val_accuracy: 0.8136\n",
      "Epoch 293/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.3677 - accuracy: 0.8023 - val_loss: 52.8689 - val_accuracy: 0.6772\n",
      "Epoch 294/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 14.8114 - accuracy: 0.7835 - val_loss: 39.0185 - val_accuracy: 0.8012\n",
      "Epoch 295/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.3889 - accuracy: 0.7996 - val_loss: 56.7843 - val_accuracy: 0.8492\n",
      "Epoch 296/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.8605 - accuracy: 0.7898 - val_loss: 37.1652 - val_accuracy: 0.8108\n",
      "Epoch 297/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.2402 - accuracy: 0.8073 - val_loss: 26.5308 - val_accuracy: 0.7281\n",
      "Epoch 298/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.3314 - accuracy: 0.8075 - val_loss: 23.9378 - val_accuracy: 0.7166\n",
      "Epoch 299/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.3940 - accuracy: 0.7948 - val_loss: 21.8488 - val_accuracy: 0.7896\n",
      "Epoch 300/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.0688 - accuracy: 0.7785 - val_loss: 55.3989 - val_accuracy: 0.6724\n",
      "Epoch 301/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.3943 - accuracy: 0.7977 - val_loss: 22.8476 - val_accuracy: 0.6599\n",
      "Epoch 302/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.4811 - accuracy: 0.8035 - val_loss: 36.3035 - val_accuracy: 0.7963\n",
      "Epoch 303/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.3243 - accuracy: 0.7991 - val_loss: 22.9881 - val_accuracy: 0.8012\n",
      "Epoch 304/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.4672 - accuracy: 0.8020 - val_loss: 21.3795 - val_accuracy: 0.7416\n",
      "Epoch 305/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.0898 - accuracy: 0.8097 - val_loss: 44.4567 - val_accuracy: 0.7166\n",
      "Epoch 306/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 14.3512 - accuracy: 0.7900 - val_loss: 38.0952 - val_accuracy: 0.8127\n",
      "Epoch 307/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.0553 - accuracy: 0.8085 - val_loss: 33.9594 - val_accuracy: 0.8319\n",
      "Epoch 308/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.3494 - accuracy: 0.7984 - val_loss: 31.3898 - val_accuracy: 0.8300\n",
      "Epoch 309/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.0238 - accuracy: 0.8116 - val_loss: 24.1796 - val_accuracy: 0.8184\n",
      "Epoch 310/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.1801 - accuracy: 0.7924 - val_loss: 25.5895 - val_accuracy: 0.8396\n",
      "Epoch 311/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.0513 - accuracy: 0.8035 - val_loss: 23.1676 - val_accuracy: 0.7080\n",
      "Epoch 312/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.2524 - accuracy: 0.8020 - val_loss: 25.3787 - val_accuracy: 0.8021\n",
      "Epoch 313/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.1873 - accuracy: 0.8001 - val_loss: 26.6674 - val_accuracy: 0.7723\n",
      "Epoch 314/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.2072 - accuracy: 0.7989 - val_loss: 20.6896 - val_accuracy: 0.7118\n",
      "Epoch 315/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.2287 - accuracy: 0.8148 - val_loss: 23.2689 - val_accuracy: 0.6974\n",
      "Epoch 316/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.9620 - accuracy: 0.8083 - val_loss: 21.9088 - val_accuracy: 0.7925\n",
      "Epoch 317/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 14.2936 - accuracy: 0.8196 - val_loss: 25.4437 - val_accuracy: 0.7464\n",
      "Epoch 318/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.1050 - accuracy: 0.8136 - val_loss: 21.1676 - val_accuracy: 0.7771\n",
      "Epoch 319/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.9597 - accuracy: 0.8215 - val_loss: 34.1315 - val_accuracy: 0.6724\n",
      "Epoch 320/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.3933 - accuracy: 0.8037 - val_loss: 20.0342 - val_accuracy: 0.7224\n",
      "Epoch 321/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.0087 - accuracy: 0.8191 - val_loss: 22.4251 - val_accuracy: 0.6427\n",
      "Epoch 322/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.9031 - accuracy: 0.8155 - val_loss: 36.7726 - val_accuracy: 0.6244\n",
      "Epoch 323/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.2267 - accuracy: 0.8097 - val_loss: 36.9291 - val_accuracy: 0.7887\n",
      "Epoch 324/500\n",
      "4162/4162 [==============================] - ETA: 0s - loss: 15.0573 - accuracy: 0.817 - 0s 38us/step - loss: 13.8353 - accuracy: 0.8179 - val_loss: 36.1203 - val_accuracy: 0.8598\n",
      "Epoch 325/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.1681 - accuracy: 0.8186 - val_loss: 21.1567 - val_accuracy: 0.8751\n",
      "Epoch 326/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.8817 - accuracy: 0.8071 - val_loss: 31.7516 - val_accuracy: 0.7426\n",
      "Epoch 327/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.2010 - accuracy: 0.8181 - val_loss: 32.9452 - val_accuracy: 0.8588\n",
      "Epoch 328/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.1452 - accuracy: 0.8116 - val_loss: 26.6543 - val_accuracy: 0.7887\n",
      "Epoch 329/500\n",
      "4162/4162 [==============================] - 0s 39us/step - loss: 13.9308 - accuracy: 0.8162 - val_loss: 21.4742 - val_accuracy: 0.8501\n",
      "Epoch 330/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.0159 - accuracy: 0.8114 - val_loss: 25.7460 - val_accuracy: 0.7522\n",
      "Epoch 331/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.8986 - accuracy: 0.8164 - val_loss: 21.4827 - val_accuracy: 0.8060\n",
      "Epoch 332/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.9044 - accuracy: 0.8143 - val_loss: 32.6887 - val_accuracy: 0.8050\n",
      "Epoch 333/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.7988 - accuracy: 0.8109 - val_loss: 24.2409 - val_accuracy: 0.8655\n",
      "Epoch 334/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.0764 - accuracy: 0.8208 - val_loss: 39.0688 - val_accuracy: 0.6302\n",
      "Epoch 335/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 14.1037 - accuracy: 0.8126 - val_loss: 24.6174 - val_accuracy: 0.7262\n",
      "Epoch 336/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.0153 - accuracy: 0.8198 - val_loss: 26.4368 - val_accuracy: 0.8511\n",
      "Epoch 337/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.7669 - accuracy: 0.8296 - val_loss: 26.2636 - val_accuracy: 0.8453\n",
      "Epoch 338/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.8200 - accuracy: 0.8244 - val_loss: 34.5852 - val_accuracy: 0.8742\n",
      "Epoch 339/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.8714 - accuracy: 0.8272 - val_loss: 22.4761 - val_accuracy: 0.6580\n",
      "Epoch 340/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.0309 - accuracy: 0.8095 - val_loss: 41.1288 - val_accuracy: 0.6628\n",
      "Epoch 341/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.9852 - accuracy: 0.8239 - val_loss: 20.5760 - val_accuracy: 0.8396\n",
      "Epoch 342/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.0669 - accuracy: 0.8299 - val_loss: 41.3408 - val_accuracy: 0.7214\n",
      "Epoch 343/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.3027 - accuracy: 0.8198 - val_loss: 22.9837 - val_accuracy: 0.8079\n",
      "Epoch 344/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.7619 - accuracy: 0.8191 - val_loss: 38.6671 - val_accuracy: 0.8194\n",
      "Epoch 345/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.0345 - accuracy: 0.8205 - val_loss: 26.0313 - val_accuracy: 0.8367\n",
      "Epoch 346/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.7650 - accuracy: 0.8268 - val_loss: 30.6363 - val_accuracy: 0.8098\n",
      "Epoch 347/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.0256 - accuracy: 0.8193 - val_loss: 24.4425 - val_accuracy: 0.7378\n",
      "Epoch 348/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 14.1222 - accuracy: 0.8258 - val_loss: 21.2151 - val_accuracy: 0.6888\n",
      "Epoch 349/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.9206 - accuracy: 0.8364 - val_loss: 30.9467 - val_accuracy: 0.6446\n",
      "Epoch 350/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.9420 - accuracy: 0.8167 - val_loss: 23.7610 - val_accuracy: 0.7877\n",
      "Epoch 351/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.8191 - accuracy: 0.8462 - val_loss: 24.0775 - val_accuracy: 0.7627\n",
      "Epoch 352/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.8764 - accuracy: 0.8083 - val_loss: 28.7185 - val_accuracy: 0.8329\n",
      "Epoch 353/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.9850 - accuracy: 0.8253 - val_loss: 22.1957 - val_accuracy: 0.8223\n",
      "Epoch 354/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.7495 - accuracy: 0.8296 - val_loss: 32.1349 - val_accuracy: 0.7224\n",
      "Epoch 355/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.7031 - accuracy: 0.8198 - val_loss: 30.3406 - val_accuracy: 0.7320\n",
      "Epoch 356/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 14.0609 - accuracy: 0.8224 - val_loss: 21.4719 - val_accuracy: 0.8194\n",
      "Epoch 357/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.8014 - accuracy: 0.8407 - val_loss: 22.5940 - val_accuracy: 0.8117\n",
      "Epoch 358/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.7846 - accuracy: 0.8337 - val_loss: 22.5411 - val_accuracy: 0.8425\n",
      "Epoch 359/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.5948 - accuracy: 0.8299 - val_loss: 21.6043 - val_accuracy: 0.8943\n",
      "Epoch 360/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.8772 - accuracy: 0.8388 - val_loss: 32.1377 - val_accuracy: 0.6897\n",
      "Epoch 361/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.7434 - accuracy: 0.8316 - val_loss: 28.4742 - val_accuracy: 0.8415\n",
      "Epoch 362/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 14.0982 - accuracy: 0.8284 - val_loss: 20.7153 - val_accuracy: 0.8194\n",
      "Epoch 363/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 13.7880 - accuracy: 0.8359 - val_loss: 30.6591 - val_accuracy: 0.8021\n",
      "Epoch 364/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.6901 - accuracy: 0.8433 - val_loss: 28.2951 - val_accuracy: 0.8213\n",
      "Epoch 365/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.8166 - accuracy: 0.8369 - val_loss: 21.4290 - val_accuracy: 0.8684\n",
      "Epoch 366/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.6981 - accuracy: 0.8429 - val_loss: 44.7349 - val_accuracy: 0.6427\n",
      "Epoch 367/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 14.1147 - accuracy: 0.8102 - val_loss: 29.4989 - val_accuracy: 0.8444\n",
      "Epoch 368/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.6307 - accuracy: 0.8393 - val_loss: 24.8313 - val_accuracy: 0.8367\n",
      "Epoch 369/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 13.8259 - accuracy: 0.8349 - val_loss: 26.5354 - val_accuracy: 0.6926\n",
      "Epoch 370/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 13.8004 - accuracy: 0.8349 - val_loss: 21.9872 - val_accuracy: 0.7723\n",
      "Epoch 371/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.5880 - accuracy: 0.8388 - val_loss: 24.1688 - val_accuracy: 0.7550\n",
      "Epoch 372/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 13.5607 - accuracy: 0.8316 - val_loss: 21.3558 - val_accuracy: 0.8665\n",
      "Epoch 373/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.5786 - accuracy: 0.8417 - val_loss: 20.5843 - val_accuracy: 0.8809\n",
      "Epoch 374/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.6246 - accuracy: 0.8313 - val_loss: 20.8275 - val_accuracy: 0.8674\n",
      "Epoch 375/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.4753 - accuracy: 0.8397 - val_loss: 20.2342 - val_accuracy: 0.8636\n",
      "Epoch 376/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.7439 - accuracy: 0.8474 - val_loss: 33.0243 - val_accuracy: 0.8809\n",
      "Epoch 377/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.7691 - accuracy: 0.8400 - val_loss: 40.8563 - val_accuracy: 0.7839\n",
      "Epoch 378/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.8143 - accuracy: 0.8417 - val_loss: 32.4371 - val_accuracy: 0.7166\n",
      "Epoch 379/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.7132 - accuracy: 0.8244 - val_loss: 27.0206 - val_accuracy: 0.7819\n",
      "Epoch 380/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.8644 - accuracy: 0.8486 - val_loss: 27.5710 - val_accuracy: 0.7810\n",
      "Epoch 381/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.7740 - accuracy: 0.8301 - val_loss: 30.8527 - val_accuracy: 0.8040\n",
      "Epoch 382/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.8309 - accuracy: 0.8400 - val_loss: 26.1292 - val_accuracy: 0.8598\n",
      "Epoch 383/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 13.7142 - accuracy: 0.8532 - val_loss: 28.1996 - val_accuracy: 0.8713\n",
      "Epoch 384/500\n",
      "4162/4162 [==============================] - 0s 40us/step - loss: 13.8439 - accuracy: 0.8381 - val_loss: 33.1809 - val_accuracy: 0.7733\n",
      "Epoch 385/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.4236 - accuracy: 0.8395 - val_loss: 21.9723 - val_accuracy: 0.8636\n",
      "Epoch 386/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.7617 - accuracy: 0.8417 - val_loss: 24.4263 - val_accuracy: 0.8770\n",
      "Epoch 387/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.7100 - accuracy: 0.8479 - val_loss: 25.4141 - val_accuracy: 0.6417\n",
      "Epoch 388/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.8045 - accuracy: 0.8508 - val_loss: 22.0556 - val_accuracy: 0.8847\n",
      "Epoch 389/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 13.8055 - accuracy: 0.8450 - val_loss: 36.7936 - val_accuracy: 0.8473\n",
      "Epoch 390/500\n",
      "4162/4162 [==============================] - 0s 37us/step - loss: 13.5140 - accuracy: 0.8486 - val_loss: 30.4762 - val_accuracy: 0.7771\n",
      "Epoch 391/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.7778 - accuracy: 0.8400 - val_loss: 28.6851 - val_accuracy: 0.8838\n",
      "Epoch 392/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.6807 - accuracy: 0.8421 - val_loss: 20.5886 - val_accuracy: 0.8636\n",
      "Epoch 393/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.5050 - accuracy: 0.8357 - val_loss: 34.7476 - val_accuracy: 0.7887\n",
      "Epoch 394/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.7083 - accuracy: 0.8426 - val_loss: 22.4349 - val_accuracy: 0.7656\n",
      "Epoch 395/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.5367 - accuracy: 0.8537 - val_loss: 27.1855 - val_accuracy: 0.7781\n",
      "Epoch 396/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.5604 - accuracy: 0.8467 - val_loss: 23.4322 - val_accuracy: 0.8069\n",
      "Epoch 397/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.7351 - accuracy: 0.8441 - val_loss: 28.3876 - val_accuracy: 0.6359\n",
      "Epoch 398/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.6964 - accuracy: 0.8364 - val_loss: 21.9092 - val_accuracy: 0.8357\n",
      "Epoch 399/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.6423 - accuracy: 0.8376 - val_loss: 23.9702 - val_accuracy: 0.7378\n",
      "Epoch 400/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.5102 - accuracy: 0.8532 - val_loss: 36.2704 - val_accuracy: 0.7983\n",
      "Epoch 401/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.6064 - accuracy: 0.8462 - val_loss: 27.9128 - val_accuracy: 0.6811\n",
      "Epoch 402/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.8225 - accuracy: 0.8349 - val_loss: 25.4613 - val_accuracy: 0.7214\n",
      "Epoch 403/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.6696 - accuracy: 0.8469 - val_loss: 21.9181 - val_accuracy: 0.7426\n",
      "Epoch 404/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.5825 - accuracy: 0.8357 - val_loss: 26.1249 - val_accuracy: 0.7243\n",
      "Epoch 405/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.4502 - accuracy: 0.8554 - val_loss: 26.7183 - val_accuracy: 0.7089\n",
      "Epoch 406/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.6809 - accuracy: 0.8479 - val_loss: 44.8634 - val_accuracy: 0.7512\n",
      "Epoch 407/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.9161 - accuracy: 0.8445 - val_loss: 26.0846 - val_accuracy: 0.7858\n",
      "Epoch 408/500\n",
      "4162/4162 [==============================] - 0s 36us/step - loss: 13.7453 - accuracy: 0.8513 - val_loss: 51.8271 - val_accuracy: 0.8559\n",
      "Epoch 409/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 14.0656 - accuracy: 0.8450 - val_loss: 38.7408 - val_accuracy: 0.8482\n",
      "Epoch 410/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.6052 - accuracy: 0.8381 - val_loss: 26.4580 - val_accuracy: 0.8290\n",
      "Epoch 411/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.4743 - accuracy: 0.8443 - val_loss: 24.9592 - val_accuracy: 0.8847\n",
      "Epoch 412/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.4724 - accuracy: 0.8409 - val_loss: 25.2401 - val_accuracy: 0.7810\n",
      "Epoch 413/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.2571 - accuracy: 0.8460 - val_loss: 22.6646 - val_accuracy: 0.7483\n",
      "Epoch 414/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.5955 - accuracy: 0.8510 - val_loss: 46.4999 - val_accuracy: 0.8463\n",
      "Epoch 415/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.7826 - accuracy: 0.8361 - val_loss: 26.2442 - val_accuracy: 0.8309\n",
      "Epoch 416/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.4377 - accuracy: 0.8429 - val_loss: 23.0042 - val_accuracy: 0.7810\n",
      "Epoch 417/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.3530 - accuracy: 0.8494 - val_loss: 43.3888 - val_accuracy: 0.8761\n",
      "Epoch 418/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.7972 - accuracy: 0.8455 - val_loss: 21.9022 - val_accuracy: 0.8770\n",
      "Epoch 419/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.5534 - accuracy: 0.8479 - val_loss: 32.0257 - val_accuracy: 0.7733\n",
      "Epoch 420/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.5131 - accuracy: 0.8433 - val_loss: 21.2584 - val_accuracy: 0.8309\n",
      "Epoch 421/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.4181 - accuracy: 0.8457 - val_loss: 20.3084 - val_accuracy: 0.8578\n",
      "Epoch 422/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.4873 - accuracy: 0.8311 - val_loss: 23.4114 - val_accuracy: 0.7800\n",
      "Epoch 423/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.4727 - accuracy: 0.8465 - val_loss: 26.7342 - val_accuracy: 0.8549\n",
      "Epoch 424/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.4690 - accuracy: 0.8431 - val_loss: 20.6947 - val_accuracy: 0.8396\n",
      "Epoch 425/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.2556 - accuracy: 0.8474 - val_loss: 27.1773 - val_accuracy: 0.8703\n",
      "Epoch 426/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.4625 - accuracy: 0.8503 - val_loss: 36.3650 - val_accuracy: 0.7992\n",
      "Epoch 427/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.4695 - accuracy: 0.8453 - val_loss: 40.8125 - val_accuracy: 0.8098\n",
      "Epoch 428/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.4720 - accuracy: 0.8431 - val_loss: 33.7581 - val_accuracy: 0.6532\n",
      "Epoch 429/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.3484 - accuracy: 0.8409 - val_loss: 23.0373 - val_accuracy: 0.7627\n",
      "Epoch 430/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.2573 - accuracy: 0.8424 - val_loss: 25.8631 - val_accuracy: 0.8521\n",
      "Epoch 431/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.4973 - accuracy: 0.8554 - val_loss: 22.1833 - val_accuracy: 0.8300\n",
      "Epoch 432/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.4283 - accuracy: 0.8522 - val_loss: 22.5136 - val_accuracy: 0.8598\n",
      "Epoch 433/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.4383 - accuracy: 0.8513 - val_loss: 22.4378 - val_accuracy: 0.8069\n",
      "Epoch 434/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.3508 - accuracy: 0.8460 - val_loss: 29.2081 - val_accuracy: 0.8127\n",
      "Epoch 435/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.4507 - accuracy: 0.8546 - val_loss: 27.2648 - val_accuracy: 0.8300\n",
      "Epoch 436/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.3891 - accuracy: 0.8462 - val_loss: 25.4003 - val_accuracy: 0.8194\n",
      "Epoch 437/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.6671 - accuracy: 0.8457 - val_loss: 29.6241 - val_accuracy: 0.8530\n",
      "Epoch 438/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.6149 - accuracy: 0.8510 - val_loss: 45.3699 - val_accuracy: 0.7426\n",
      "Epoch 439/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.3182 - accuracy: 0.8412 - val_loss: 21.4810 - val_accuracy: 0.7954\n",
      "Epoch 440/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.2319 - accuracy: 0.8501 - val_loss: 47.9274 - val_accuracy: 0.7118\n",
      "Epoch 441/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.6273 - accuracy: 0.8412 - val_loss: 25.9831 - val_accuracy: 0.7627\n",
      "Epoch 442/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.5762 - accuracy: 0.8395 - val_loss: 32.4944 - val_accuracy: 0.8684\n",
      "Epoch 443/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.6317 - accuracy: 0.8522 - val_loss: 48.6564 - val_accuracy: 0.8213\n",
      "Epoch 444/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.6220 - accuracy: 0.8450 - val_loss: 23.4925 - val_accuracy: 0.8751\n",
      "Epoch 445/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.3595 - accuracy: 0.8515 - val_loss: 33.8944 - val_accuracy: 0.8473\n",
      "Epoch 446/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.3477 - accuracy: 0.8522 - val_loss: 23.1879 - val_accuracy: 0.8751\n",
      "Epoch 447/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.4154 - accuracy: 0.8426 - val_loss: 24.5568 - val_accuracy: 0.8453\n",
      "Epoch 448/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.2555 - accuracy: 0.8563 - val_loss: 31.3661 - val_accuracy: 0.7858\n",
      "Epoch 449/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.1976 - accuracy: 0.8419 - val_loss: 26.7603 - val_accuracy: 0.8319\n",
      "Epoch 450/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.2559 - accuracy: 0.8436 - val_loss: 21.5604 - val_accuracy: 0.8809\n",
      "Epoch 451/500\n",
      "4162/4162 [==============================] - 0s 30us/step - loss: 13.3413 - accuracy: 0.8518 - val_loss: 30.9410 - val_accuracy: 0.8703\n",
      "Epoch 452/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.3003 - accuracy: 0.8469 - val_loss: 27.3218 - val_accuracy: 0.7022\n",
      "Epoch 453/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.1310 - accuracy: 0.8366 - val_loss: 20.7485 - val_accuracy: 0.6964\n",
      "Epoch 454/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.4860 - accuracy: 0.8457 - val_loss: 34.1681 - val_accuracy: 0.7560\n",
      "Epoch 455/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.3663 - accuracy: 0.8491 - val_loss: 35.8707 - val_accuracy: 0.7714\n",
      "Epoch 456/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.4197 - accuracy: 0.8477 - val_loss: 27.7678 - val_accuracy: 0.8636\n",
      "Epoch 457/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.2220 - accuracy: 0.8407 - val_loss: 21.0731 - val_accuracy: 0.8098\n",
      "Epoch 458/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.1946 - accuracy: 0.8462 - val_loss: 42.4658 - val_accuracy: 0.7771\n",
      "Epoch 459/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.4354 - accuracy: 0.8467 - val_loss: 28.0778 - val_accuracy: 0.6417\n",
      "Epoch 460/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.2716 - accuracy: 0.8426 - val_loss: 24.7748 - val_accuracy: 0.7867\n",
      "Epoch 461/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.2672 - accuracy: 0.8433 - val_loss: 38.6573 - val_accuracy: 0.6282\n",
      "Epoch 462/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.5764 - accuracy: 0.8282 - val_loss: 35.8961 - val_accuracy: 0.8722\n",
      "Epoch 463/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.2611 - accuracy: 0.8539 - val_loss: 22.5388 - val_accuracy: 0.8261\n",
      "Epoch 464/500\n",
      "4162/4162 [==============================] - 0s 30us/step - loss: 13.2059 - accuracy: 0.8438 - val_loss: 28.5621 - val_accuracy: 0.8079\n",
      "Epoch 465/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.2885 - accuracy: 0.8510 - val_loss: 30.0878 - val_accuracy: 0.8242\n",
      "Epoch 466/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.5007 - accuracy: 0.8489 - val_loss: 24.6408 - val_accuracy: 0.8492\n",
      "Epoch 467/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.1444 - accuracy: 0.8510 - val_loss: 27.0163 - val_accuracy: 0.7397\n",
      "Epoch 468/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.2334 - accuracy: 0.8537 - val_loss: 27.6821 - val_accuracy: 0.7061\n",
      "Epoch 469/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.3480 - accuracy: 0.8431 - val_loss: 21.1861 - val_accuracy: 0.7848\n",
      "Epoch 470/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.2660 - accuracy: 0.8381 - val_loss: 24.1120 - val_accuracy: 0.9001\n",
      "Epoch 471/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 12.9876 - accuracy: 0.8570 - val_loss: 25.3653 - val_accuracy: 0.8271\n",
      "Epoch 472/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.4524 - accuracy: 0.8494 - val_loss: 34.8419 - val_accuracy: 0.8905\n",
      "Epoch 473/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.2949 - accuracy: 0.8474 - val_loss: 21.0765 - val_accuracy: 0.7570\n",
      "Epoch 474/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.4072 - accuracy: 0.8513 - val_loss: 26.6642 - val_accuracy: 0.7329\n",
      "Epoch 475/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.3527 - accuracy: 0.8381 - val_loss: 27.7308 - val_accuracy: 0.8108\n",
      "Epoch 476/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.2953 - accuracy: 0.8474 - val_loss: 30.0528 - val_accuracy: 0.7137\n",
      "Epoch 477/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.0286 - accuracy: 0.8455 - val_loss: 40.0559 - val_accuracy: 0.8549\n",
      "Epoch 478/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.5147 - accuracy: 0.8393 - val_loss: 39.4678 - val_accuracy: 0.6350\n",
      "Epoch 479/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.5957 - accuracy: 0.8436 - val_loss: 29.1016 - val_accuracy: 0.8492\n",
      "Epoch 480/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.3951 - accuracy: 0.8520 - val_loss: 20.4494 - val_accuracy: 0.8540\n",
      "Epoch 481/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 12.9390 - accuracy: 0.8546 - val_loss: 40.9806 - val_accuracy: 0.7791\n",
      "Epoch 482/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.0889 - accuracy: 0.8491 - val_loss: 38.5002 - val_accuracy: 0.8761\n",
      "Epoch 483/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.3502 - accuracy: 0.8436 - val_loss: 33.4483 - val_accuracy: 0.8127\n",
      "Epoch 484/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.1052 - accuracy: 0.8383 - val_loss: 25.9486 - val_accuracy: 0.8540\n",
      "Epoch 485/500\n",
      "4162/4162 [==============================] - 0s 30us/step - loss: 13.1828 - accuracy: 0.8465 - val_loss: 19.8865 - val_accuracy: 0.8674\n",
      "Epoch 486/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.2672 - accuracy: 0.8424 - val_loss: 21.0829 - val_accuracy: 0.8252\n",
      "Epoch 487/500\n",
      "4162/4162 [==============================] - 0s 30us/step - loss: 13.0427 - accuracy: 0.8491 - val_loss: 45.7887 - val_accuracy: 0.7733\n",
      "Epoch 488/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.2604 - accuracy: 0.8436 - val_loss: 27.1594 - val_accuracy: 0.6340\n",
      "Epoch 489/500\n",
      "4162/4162 [==============================] - 0s 30us/step - loss: 13.1519 - accuracy: 0.8486 - val_loss: 22.8524 - val_accuracy: 0.8117\n",
      "Epoch 490/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.1924 - accuracy: 0.8530 - val_loss: 23.5490 - val_accuracy: 0.8136\n",
      "Epoch 491/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.1739 - accuracy: 0.8453 - val_loss: 31.0465 - val_accuracy: 0.8357\n",
      "Epoch 492/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.2036 - accuracy: 0.8465 - val_loss: 24.8703 - val_accuracy: 0.8722\n",
      "Epoch 493/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.1712 - accuracy: 0.8510 - val_loss: 20.6472 - val_accuracy: 0.7550\n",
      "Epoch 494/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 13.3170 - accuracy: 0.8457 - val_loss: 23.7300 - val_accuracy: 0.6494\n",
      "Epoch 495/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.3658 - accuracy: 0.8496 - val_loss: 28.4497 - val_accuracy: 0.7281\n",
      "Epoch 496/500\n",
      "4162/4162 [==============================] - 0s 35us/step - loss: 13.3541 - accuracy: 0.8477 - val_loss: 26.3257 - val_accuracy: 0.8578\n",
      "Epoch 497/500\n",
      "4162/4162 [==============================] - 0s 34us/step - loss: 13.2929 - accuracy: 0.8472 - val_loss: 25.2409 - val_accuracy: 0.8473\n",
      "Epoch 498/500\n",
      "4162/4162 [==============================] - 0s 31us/step - loss: 13.1466 - accuracy: 0.8498 - val_loss: 26.7509 - val_accuracy: 0.8953\n",
      "Epoch 499/500\n",
      "4162/4162 [==============================] - 0s 33us/step - loss: 12.9528 - accuracy: 0.8510 - val_loss: 19.9232 - val_accuracy: 0.8607\n",
      "Epoch 500/500\n",
      "4162/4162 [==============================] - 0s 32us/step - loss: 13.2612 - accuracy: 0.8472 - val_loss: 23.7557 - val_accuracy: 0.8146\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_test,y_test), epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7099.35379909  152.8009391  7055.49912764   94.17810036 6869.53299969\n",
      "   21.49383797 7024.63037398  137.45235772 7112.42106543   32.43401849\n",
      " 6777.40779964  170.6940966  6945.17644215   67.42483081 6861.49185377\n",
      "  142.30558483 7169.39054552  112.56683038 6882.42292769  103.79689594\n",
      " 7151.45255428   62.20181047 6990.43381748   49.68959532 6924.88548973\n",
      "  162.55666357 6703.23842446  154.60617785 6810.46279301  124.42329158]\n",
      "[7109.2163    170.8465   7048.865     112.136795 6862.1895      9.686163\n",
      " 7017.297     149.08269  7098.982      16.141312 6779.196     185.49872\n",
      " 6927.95       71.17219  6855.3545    169.88216  7173.2886     92.18815\n",
      " 6877.538     115.31802  7170.343      76.9228   6980.4956     47.90226\n",
      " 6943.186     132.50587  6691.6274    167.81882  6801.498     138.68045 ]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict of test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accurcy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two imges input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples are ((frame, frame), next_frame)\n",
    "\n",
    "X = None\n",
    "\n",
    "for i in range(len(frames) - 2):\n",
    "    X = np.append(X, np.append(frames[i], frames[i+1])) if X is not None else np.append(frames[i], frames[i+1])\n",
    "X = X.reshape(-1, 4 * no_skyrmions)\n",
    "y = frames[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4161, 60)\n",
      "y_train shape: (4161, 30)\n",
      "X_test shape: (1041, 60)\n",
      "y_test shape: (1041, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"y_train shape: \" + str(y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "\n",
    "optimizer = 'NAdam'\n",
    "loss = 'mae'\n",
    "metrics = ['accuracy']\n",
    "training_epochs = 250\n",
    "batch_size = 128\n",
    "\n",
    "n_input = 4 * no_skyrmions\n",
    "n_hidden_1 = 512\n",
    "n_hidden_2 = 256\n",
    "n_hidden_3 = 128\n",
    "n_output = 2 * no_skyrmions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_1, input_dim=n_input, activation=activation))\n",
    "model.add(Dense(n_hidden_2, activation=activation))\n",
    "model.add(Dense(n_hidden_3, activation=activation))\n",
    "model.add(Dense(n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2881 samples, validate on 721 samples\n",
      "Epoch 1/250\n",
      "2881/2881 [==============================] - 0s 71us/step - loss: 858.1790 - accuracy: 0.0656 - val_loss: 427.5368 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/250\n",
      "2881/2881 [==============================] - 0s 28us/step - loss: 381.3737 - accuracy: 0.1454 - val_loss: 251.7748 - val_accuracy: 0.3079\n",
      "Epoch 3/250\n",
      "2881/2881 [==============================] - 0s 28us/step - loss: 335.5894 - accuracy: 0.0312 - val_loss: 191.0637 - val_accuracy: 0.0236\n",
      "Epoch 4/250\n",
      "2881/2881 [==============================] - 0s 32us/step - loss: 284.6623 - accuracy: 0.1978 - val_loss: 315.5264 - val_accuracy: 0.0194\n",
      "Epoch 5/250\n",
      "2881/2881 [==============================] - 0s 29us/step - loss: 276.1798 - accuracy: 0.2326 - val_loss: 383.0871 - val_accuracy: 0.3384\n",
      "Epoch 6/250\n",
      "2881/2881 [==============================] - 0s 27us/step - loss: 258.2085 - accuracy: 0.2548 - val_loss: 127.9705 - val_accuracy: 0.0763\n",
      "Epoch 7/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 260.3006 - accuracy: 0.2114 - val_loss: 359.4155 - val_accuracy: 0.4230\n",
      "Epoch 8/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 229.1632 - accuracy: 0.2614 - val_loss: 331.0459 - val_accuracy: 0.4064\n",
      "Epoch 9/250\n",
      "2881/2881 [==============================] - 0s 28us/step - loss: 244.9590 - accuracy: 0.1635 - val_loss: 92.1000 - val_accuracy: 0.1262\n",
      "Epoch 10/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 211.1317 - accuracy: 0.1663 - val_loss: 246.7202 - val_accuracy: 0.1165\n",
      "Epoch 11/250\n",
      "2881/2881 [==============================] - 0s 27us/step - loss: 218.1707 - accuracy: 0.2544 - val_loss: 286.5659 - val_accuracy: 0.3606\n",
      "Epoch 12/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 213.5647 - accuracy: 0.2287 - val_loss: 257.9117 - val_accuracy: 0.1761\n",
      "Epoch 13/250\n",
      "2881/2881 [==============================] - 0s 27us/step - loss: 209.3285 - accuracy: 0.3537 - val_loss: 201.7985 - val_accuracy: 0.1734\n",
      "Epoch 14/250\n",
      "2881/2881 [==============================] - 0s 29us/step - loss: 206.6308 - accuracy: 0.3016 - val_loss: 95.8260 - val_accuracy: 0.1290\n",
      "Epoch 15/250\n",
      "2881/2881 [==============================] - 0s 27us/step - loss: 182.6913 - accuracy: 0.3714 - val_loss: 195.3911 - val_accuracy: 0.1290\n",
      "Epoch 16/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 191.1051 - accuracy: 0.3138 - val_loss: 153.6055 - val_accuracy: 0.4133\n",
      "Epoch 17/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 184.6838 - accuracy: 0.3127 - val_loss: 218.7738 - val_accuracy: 0.3634\n",
      "Epoch 18/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 188.5671 - accuracy: 0.3523 - val_loss: 293.2437 - val_accuracy: 0.2621\n",
      "Epoch 19/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 170.1371 - accuracy: 0.3544 - val_loss: 191.4474 - val_accuracy: 0.3648\n",
      "Epoch 20/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 179.2219 - accuracy: 0.1611 - val_loss: 58.1121 - val_accuracy: 0.3883\n",
      "Epoch 21/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 168.7768 - accuracy: 0.3901 - val_loss: 240.1343 - val_accuracy: 0.4244\n",
      "Epoch 22/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 178.5139 - accuracy: 0.3395 - val_loss: 104.1772 - val_accuracy: 0.3523\n",
      "Epoch 23/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 168.0600 - accuracy: 0.3860 - val_loss: 159.2064 - val_accuracy: 0.5257\n",
      "Epoch 24/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 170.5880 - accuracy: 0.4214 - val_loss: 76.3906 - val_accuracy: 0.3578\n",
      "Epoch 25/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 155.0484 - accuracy: 0.4419 - val_loss: 107.1045 - val_accuracy: 0.2510\n",
      "Epoch 26/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 153.3084 - accuracy: 0.3645 - val_loss: 155.6295 - val_accuracy: 0.4799\n",
      "Epoch 27/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 154.7836 - accuracy: 0.2277 - val_loss: 195.6528 - val_accuracy: 0.0666\n",
      "Epoch 28/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 152.1477 - accuracy: 0.1232 - val_loss: 62.5563 - val_accuracy: 0.0402\n",
      "Epoch 29/250\n",
      "2881/2881 [==============================] - 0s 27us/step - loss: 146.3079 - accuracy: 0.2933 - val_loss: 156.5407 - val_accuracy: 0.0374\n",
      "Epoch 30/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 148.3121 - accuracy: 0.2353 - val_loss: 182.9725 - val_accuracy: 0.6006\n",
      "Epoch 31/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 144.7085 - accuracy: 0.3846 - val_loss: 189.6757 - val_accuracy: 0.5160\n",
      "Epoch 32/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 149.2552 - accuracy: 0.1701 - val_loss: 131.2877 - val_accuracy: 0.0569\n",
      "Epoch 33/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 145.5744 - accuracy: 0.3127 - val_loss: 156.5905 - val_accuracy: 0.3564\n",
      "Epoch 34/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 127.3115 - accuracy: 0.4325 - val_loss: 202.6269 - val_accuracy: 0.4868\n",
      "Epoch 35/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 143.0183 - accuracy: 0.5030 - val_loss: 94.6376 - val_accuracy: 0.4230\n",
      "Epoch 36/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 132.8781 - accuracy: 0.4304 - val_loss: 141.1005 - val_accuracy: 0.1373\n",
      "Epoch 37/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 137.2157 - accuracy: 0.3579 - val_loss: 68.1392 - val_accuracy: 0.6103\n",
      "Epoch 38/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 132.5980 - accuracy: 0.4613 - val_loss: 112.0861 - val_accuracy: 0.3343\n",
      "Epoch 39/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 129.1804 - accuracy: 0.4964 - val_loss: 251.2392 - val_accuracy: 0.5895\n",
      "Epoch 40/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 124.6230 - accuracy: 0.4405 - val_loss: 143.2713 - val_accuracy: 0.3440\n",
      "Epoch 41/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 131.9972 - accuracy: 0.3905 - val_loss: 153.1737 - val_accuracy: 0.1817\n",
      "Epoch 42/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 130.5878 - accuracy: 0.3176 - val_loss: 164.9179 - val_accuracy: 0.3440\n",
      "Epoch 43/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 130.0226 - accuracy: 0.4443 - val_loss: 142.0690 - val_accuracy: 0.1678\n",
      "Epoch 44/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 119.1057 - accuracy: 0.2475 - val_loss: 65.8465 - val_accuracy: 0.3731\n",
      "Epoch 45/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 121.8626 - accuracy: 0.3186 - val_loss: 209.4558 - val_accuracy: 0.3564\n",
      "Epoch 46/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 128.9404 - accuracy: 0.2721 - val_loss: 68.3589 - val_accuracy: 0.1456\n",
      "Epoch 47/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 120.9446 - accuracy: 0.3266 - val_loss: 175.5593 - val_accuracy: 0.3523\n",
      "Epoch 48/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 119.4640 - accuracy: 0.3804 - val_loss: 151.9972 - val_accuracy: 0.6158\n",
      "Epoch 49/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 121.6128 - accuracy: 0.5769 - val_loss: 159.3654 - val_accuracy: 0.5700\n",
      "Epoch 50/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 118.5058 - accuracy: 0.3297 - val_loss: 89.8754 - val_accuracy: 0.4411\n",
      "Epoch 51/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 114.9795 - accuracy: 0.5255 - val_loss: 155.8375 - val_accuracy: 0.6366\n",
      "Epoch 52/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 109.0981 - accuracy: 0.5113 - val_loss: 180.2133 - val_accuracy: 0.6394\n",
      "Epoch 53/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 116.8096 - accuracy: 0.4224 - val_loss: 159.7271 - val_accuracy: 0.2760\n",
      "Epoch 54/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 111.2678 - accuracy: 0.3058 - val_loss: 63.1463 - val_accuracy: 0.6006\n",
      "Epoch 55/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 111.6967 - accuracy: 0.4870 - val_loss: 109.6078 - val_accuracy: 0.5631\n",
      "Epoch 56/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 107.5414 - accuracy: 0.6008 - val_loss: 69.7414 - val_accuracy: 0.6297\n",
      "Epoch 57/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 100.7053 - accuracy: 0.6060 - val_loss: 166.1083 - val_accuracy: 0.5548\n",
      "Epoch 58/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 106.6187 - accuracy: 0.5550 - val_loss: 67.6560 - val_accuracy: 0.3634\n",
      "Epoch 59/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 104.2076 - accuracy: 0.3558 - val_loss: 104.1105 - val_accuracy: 0.4910\n",
      "Epoch 60/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 106.9980 - accuracy: 0.4262 - val_loss: 133.6242 - val_accuracy: 0.6130\n",
      "Epoch 61/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 102.3765 - accuracy: 0.5335 - val_loss: 147.2140 - val_accuracy: 0.5257\n",
      "Epoch 62/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 105.8593 - accuracy: 0.4405 - val_loss: 149.8835 - val_accuracy: 0.4632\n",
      "Epoch 63/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 103.0178 - accuracy: 0.5130 - val_loss: 97.4345 - val_accuracy: 0.3509\n",
      "Epoch 64/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 100.9444 - accuracy: 0.4439 - val_loss: 107.4253 - val_accuracy: 0.3939\n",
      "Epoch 65/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 107.8600 - accuracy: 0.3436 - val_loss: 47.9466 - val_accuracy: 0.3190\n",
      "Epoch 66/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 95.6987 - accuracy: 0.4755 - val_loss: 90.9144 - val_accuracy: 0.1387\n",
      "Epoch 67/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 99.7459 - accuracy: 0.4016 - val_loss: 151.4429 - val_accuracy: 0.6477\n",
      "Epoch 68/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 99.5501 - accuracy: 0.5897 - val_loss: 82.2542 - val_accuracy: 0.5229\n",
      "Epoch 69/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 96.2938 - accuracy: 0.4495 - val_loss: 120.0447 - val_accuracy: 0.5728\n",
      "Epoch 70/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 99.6984 - accuracy: 0.5453 - val_loss: 66.7611 - val_accuracy: 0.4452\n",
      "Epoch 71/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 99.3633 - accuracy: 0.5599 - val_loss: 146.2716 - val_accuracy: 0.5839\n",
      "Epoch 72/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 97.1196 - accuracy: 0.5977 - val_loss: 47.1867 - val_accuracy: 0.6477\n",
      "Epoch 73/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 93.9814 - accuracy: 0.5005 - val_loss: 155.0019 - val_accuracy: 0.4050\n",
      "Epoch 74/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 84.3919 - accuracy: 0.3999 - val_loss: 145.6265 - val_accuracy: 0.3093\n",
      "Epoch 75/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 96.7299 - accuracy: 0.4689 - val_loss: 60.9583 - val_accuracy: 0.5007\n",
      "Epoch 76/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 93.4433 - accuracy: 0.5585 - val_loss: 145.6756 - val_accuracy: 0.5784\n",
      "Epoch 77/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 95.2174 - accuracy: 0.6289 - val_loss: 50.1788 - val_accuracy: 0.6879\n",
      "Epoch 78/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 91.0893 - accuracy: 0.5574 - val_loss: 132.1199 - val_accuracy: 0.5978\n",
      "Epoch 79/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 93.6304 - accuracy: 0.5758 - val_loss: 72.3732 - val_accuracy: 0.6033\n",
      "Epoch 80/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 89.5777 - accuracy: 0.4308 - val_loss: 104.8488 - val_accuracy: 0.4591\n",
      "Epoch 81/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 90.0359 - accuracy: 0.5852 - val_loss: 33.1980 - val_accuracy: 0.6477\n",
      "Epoch 82/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 85.7929 - accuracy: 0.5856 - val_loss: 42.0038 - val_accuracy: 0.5284\n",
      "Epoch 83/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 86.7732 - accuracy: 0.4651 - val_loss: 143.7971 - val_accuracy: 0.5895\n",
      "Epoch 84/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 88.4011 - accuracy: 0.5814 - val_loss: 83.5554 - val_accuracy: 0.5118\n",
      "Epoch 85/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 86.1327 - accuracy: 0.4179 - val_loss: 98.3841 - val_accuracy: 0.3620\n",
      "Epoch 86/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 86.5609 - accuracy: 0.5255 - val_loss: 79.2624 - val_accuracy: 0.6255\n",
      "Epoch 87/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 86.8646 - accuracy: 0.5616 - val_loss: 104.4384 - val_accuracy: 0.6200\n",
      "Epoch 88/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 85.5207 - accuracy: 0.5731 - val_loss: 39.0333 - val_accuracy: 0.5340\n",
      "Epoch 89/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 84.1235 - accuracy: 0.5908 - val_loss: 130.0271 - val_accuracy: 0.6810\n",
      "Epoch 90/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 84.1675 - accuracy: 0.6050 - val_loss: 88.0091 - val_accuracy: 0.6560\n",
      "Epoch 91/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 81.6601 - accuracy: 0.4068 - val_loss: 134.0802 - val_accuracy: 0.5187\n",
      "Epoch 92/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 86.9870 - accuracy: 0.5686 - val_loss: 76.6658 - val_accuracy: 0.6297\n",
      "Epoch 93/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 85.0451 - accuracy: 0.5727 - val_loss: 150.3334 - val_accuracy: 0.5728\n",
      "Epoch 94/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 87.4546 - accuracy: 0.5790 - val_loss: 101.0160 - val_accuracy: 0.6671\n",
      "Epoch 95/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 78.5408 - accuracy: 0.5269 - val_loss: 103.9447 - val_accuracy: 0.3440\n",
      "Epoch 96/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 81.3540 - accuracy: 0.5967 - val_loss: 104.3316 - val_accuracy: 0.6921\n",
      "Epoch 97/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 83.0715 - accuracy: 0.6418 - val_loss: 72.3006 - val_accuracy: 0.6033\n",
      "Epoch 98/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 82.1357 - accuracy: 0.5595 - val_loss: 96.5883 - val_accuracy: 0.5687\n",
      "Epoch 99/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 78.9883 - accuracy: 0.5692 - val_loss: 80.3769 - val_accuracy: 0.3495\n",
      "Epoch 100/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 80.4357 - accuracy: 0.5651 - val_loss: 94.2945 - val_accuracy: 0.6019\n",
      "Epoch 101/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 78.4656 - accuracy: 0.6116 - val_loss: 95.1606 - val_accuracy: 0.5368\n",
      "Epoch 102/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 80.2575 - accuracy: 0.5137 - val_loss: 52.8072 - val_accuracy: 0.3537\n",
      "Epoch 103/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 75.8045 - accuracy: 0.5727 - val_loss: 81.6772 - val_accuracy: 0.5326\n",
      "Epoch 104/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 81.9984 - accuracy: 0.5960 - val_loss: 90.5209 - val_accuracy: 0.6103\n",
      "Epoch 105/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 84.0652 - accuracy: 0.6033 - val_loss: 30.2352 - val_accuracy: 0.6283\n",
      "Epoch 106/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 76.8615 - accuracy: 0.4891 - val_loss: 80.2668 - val_accuracy: 0.6644\n",
      "Epoch 107/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 75.2904 - accuracy: 0.6383 - val_loss: 69.5043 - val_accuracy: 0.4411\n",
      "Epoch 108/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 75.3960 - accuracy: 0.5397 - val_loss: 107.3681 - val_accuracy: 0.6449\n",
      "Epoch 109/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 79.9440 - accuracy: 0.5932 - val_loss: 83.0174 - val_accuracy: 0.5395\n",
      "Epoch 110/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 74.5938 - accuracy: 0.5595 - val_loss: 33.0421 - val_accuracy: 0.5936\n",
      "Epoch 111/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 76.1931 - accuracy: 0.5901 - val_loss: 86.1571 - val_accuracy: 0.6047\n",
      "Epoch 112/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 74.8887 - accuracy: 0.6220 - val_loss: 24.4808 - val_accuracy: 0.6061\n",
      "Epoch 113/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 70.8664 - accuracy: 0.5890 - val_loss: 50.4387 - val_accuracy: 0.6103\n",
      "Epoch 114/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 68.8420 - accuracy: 0.6102 - val_loss: 67.6866 - val_accuracy: 0.6338\n",
      "Epoch 115/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 74.2590 - accuracy: 0.6074 - val_loss: 99.5823 - val_accuracy: 0.6103\n",
      "Epoch 116/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 73.5587 - accuracy: 0.5779 - val_loss: 49.2266 - val_accuracy: 0.6852\n",
      "Epoch 117/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 75.0548 - accuracy: 0.5269 - val_loss: 41.1000 - val_accuracy: 0.7323\n",
      "Epoch 118/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 74.4061 - accuracy: 0.3929 - val_loss: 81.9222 - val_accuracy: 0.2926\n",
      "Epoch 119/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 72.3694 - accuracy: 0.4995 - val_loss: 49.1782 - val_accuracy: 0.6144\n",
      "Epoch 120/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 71.1889 - accuracy: 0.6234 - val_loss: 74.4498 - val_accuracy: 0.6352\n",
      "Epoch 121/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 75.2427 - accuracy: 0.5599 - val_loss: 59.3547 - val_accuracy: 0.4813\n",
      "Epoch 122/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 72.3201 - accuracy: 0.5911 - val_loss: 72.3340 - val_accuracy: 0.6144\n",
      "Epoch 123/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 73.5317 - accuracy: 0.6012 - val_loss: 45.9649 - val_accuracy: 0.5451\n",
      "Epoch 124/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 70.1667 - accuracy: 0.6237 - val_loss: 87.8525 - val_accuracy: 0.5326\n",
      "Epoch 125/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 72.9658 - accuracy: 0.5505 - val_loss: 93.0891 - val_accuracy: 0.5714\n",
      "Epoch 126/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 70.8605 - accuracy: 0.6262 - val_loss: 103.9961 - val_accuracy: 0.6241\n",
      "Epoch 127/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 69.3665 - accuracy: 0.6335 - val_loss: 67.2695 - val_accuracy: 0.5534\n",
      "Epoch 128/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 68.3432 - accuracy: 0.5925 - val_loss: 85.9468 - val_accuracy: 0.5700\n",
      "Epoch 129/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 69.8852 - accuracy: 0.5519 - val_loss: 38.9359 - val_accuracy: 0.5520\n",
      "Epoch 130/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 67.2474 - accuracy: 0.5932 - val_loss: 59.7939 - val_accuracy: 0.5784\n",
      "Epoch 131/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 70.6332 - accuracy: 0.5672 - val_loss: 72.9903 - val_accuracy: 0.5714\n",
      "Epoch 132/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 70.3767 - accuracy: 0.5745 - val_loss: 77.7747 - val_accuracy: 0.5645\n",
      "Epoch 133/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 68.1733 - accuracy: 0.5974 - val_loss: 51.6348 - val_accuracy: 0.5839\n",
      "Epoch 134/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 67.4410 - accuracy: 0.5463 - val_loss: 95.3192 - val_accuracy: 0.3620\n",
      "Epoch 135/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 67.2369 - accuracy: 0.6053 - val_loss: 26.9869 - val_accuracy: 0.7337\n",
      "Epoch 136/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 63.6578 - accuracy: 0.5911 - val_loss: 58.9583 - val_accuracy: 0.5187\n",
      "Epoch 137/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 65.8557 - accuracy: 0.6099 - val_loss: 82.5316 - val_accuracy: 0.6311\n",
      "Epoch 138/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 66.6477 - accuracy: 0.6473 - val_loss: 57.3079 - val_accuracy: 0.5950\n",
      "Epoch 139/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 66.2099 - accuracy: 0.6116 - val_loss: 59.2266 - val_accuracy: 0.5659\n",
      "Epoch 140/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 64.3567 - accuracy: 0.6230 - val_loss: 77.6224 - val_accuracy: 0.5922\n",
      "Epoch 141/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 65.5555 - accuracy: 0.6043 - val_loss: 37.7770 - val_accuracy: 0.6533\n",
      "Epoch 142/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 63.6666 - accuracy: 0.5949 - val_loss: 50.9691 - val_accuracy: 0.3592\n",
      "Epoch 143/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 66.0030 - accuracy: 0.3377 - val_loss: 48.1190 - val_accuracy: 0.3259\n",
      "Epoch 144/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 64.6425 - accuracy: 0.3877 - val_loss: 81.6007 - val_accuracy: 0.6130\n",
      "Epoch 145/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 64.8774 - accuracy: 0.6526 - val_loss: 54.4430 - val_accuracy: 0.7268\n",
      "Epoch 146/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 60.5429 - accuracy: 0.6258 - val_loss: 48.4605 - val_accuracy: 0.5728\n",
      "Epoch 147/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 62.2160 - accuracy: 0.6269 - val_loss: 72.3373 - val_accuracy: 0.6047\n",
      "Epoch 148/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 64.5290 - accuracy: 0.5984 - val_loss: 53.9588 - val_accuracy: 0.5936\n",
      "Epoch 149/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 60.9277 - accuracy: 0.6067 - val_loss: 87.1959 - val_accuracy: 0.6394\n",
      "Epoch 150/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 58.8190 - accuracy: 0.6206 - val_loss: 67.4103 - val_accuracy: 0.5756\n",
      "Epoch 151/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 63.4495 - accuracy: 0.5210 - val_loss: 77.4627 - val_accuracy: 0.6006\n",
      "Epoch 152/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 62.4877 - accuracy: 0.6432 - val_loss: 36.2201 - val_accuracy: 0.6089\n",
      "Epoch 153/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 60.9742 - accuracy: 0.6713 - val_loss: 60.8739 - val_accuracy: 0.5936\n",
      "Epoch 154/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 62.3520 - accuracy: 0.6293 - val_loss: 42.1545 - val_accuracy: 0.6533\n",
      "Epoch 155/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 59.6825 - accuracy: 0.5783 - val_loss: 70.5357 - val_accuracy: 0.5673\n",
      "Epoch 156/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 61.5561 - accuracy: 0.5981 - val_loss: 56.8769 - val_accuracy: 0.5492\n",
      "Epoch 157/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 62.4230 - accuracy: 0.6255 - val_loss: 74.5285 - val_accuracy: 0.6061\n",
      "Epoch 158/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 60.3215 - accuracy: 0.6456 - val_loss: 34.1115 - val_accuracy: 0.6227\n",
      "Epoch 159/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 57.7632 - accuracy: 0.6074 - val_loss: 76.3842 - val_accuracy: 0.6033\n",
      "Epoch 160/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 59.3534 - accuracy: 0.6071 - val_loss: 28.8820 - val_accuracy: 0.5936\n",
      "Epoch 161/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 57.2533 - accuracy: 0.6401 - val_loss: 99.3339 - val_accuracy: 0.6422\n",
      "Epoch 162/250\n",
      "2881/2881 [==============================] - 0s 28us/step - loss: 61.1201 - accuracy: 0.6092 - val_loss: 46.0222 - val_accuracy: 0.6366\n",
      "Epoch 163/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 59.2779 - accuracy: 0.6019 - val_loss: 98.9210 - val_accuracy: 0.6006\n",
      "Epoch 164/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 58.0026 - accuracy: 0.6428 - val_loss: 39.2426 - val_accuracy: 0.6449\n",
      "Epoch 165/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 56.7835 - accuracy: 0.5738 - val_loss: 69.9950 - val_accuracy: 0.6824\n",
      "Epoch 166/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 58.2354 - accuracy: 0.5974 - val_loss: 29.2805 - val_accuracy: 0.5576\n",
      "Epoch 167/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 56.9993 - accuracy: 0.5984 - val_loss: 81.6630 - val_accuracy: 0.5867\n",
      "Epoch 168/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 56.2033 - accuracy: 0.5533 - val_loss: 62.3318 - val_accuracy: 0.5215\n",
      "Epoch 169/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 57.1700 - accuracy: 0.6067 - val_loss: 57.5628 - val_accuracy: 0.6491\n",
      "Epoch 170/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 58.6370 - accuracy: 0.5734 - val_loss: 53.3254 - val_accuracy: 0.4008\n",
      "Epoch 171/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 57.9207 - accuracy: 0.3815 - val_loss: 73.4051 - val_accuracy: 0.3675\n",
      "Epoch 172/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 55.1873 - accuracy: 0.5293 - val_loss: 35.2193 - val_accuracy: 0.6366\n",
      "Epoch 173/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 56.4173 - accuracy: 0.6015 - val_loss: 60.2900 - val_accuracy: 0.5659\n",
      "Epoch 174/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 58.5708 - accuracy: 0.5856 - val_loss: 32.6595 - val_accuracy: 0.5673\n",
      "Epoch 175/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 54.8978 - accuracy: 0.6230 - val_loss: 62.8415 - val_accuracy: 0.6075\n",
      "Epoch 176/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 57.0165 - accuracy: 0.5731 - val_loss: 69.0080 - val_accuracy: 0.5548\n",
      "Epoch 177/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 57.7586 - accuracy: 0.6099 - val_loss: 78.7346 - val_accuracy: 0.6103\n",
      "Epoch 178/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 57.4146 - accuracy: 0.6189 - val_loss: 38.5428 - val_accuracy: 0.6144\n",
      "Epoch 179/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 54.7727 - accuracy: 0.5953 - val_loss: 52.1518 - val_accuracy: 0.5853\n",
      "Epoch 180/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 56.2598 - accuracy: 0.6165 - val_loss: 37.9538 - val_accuracy: 0.6144\n",
      "Epoch 181/250\n",
      "2881/2881 [==============================] - 0s 27us/step - loss: 53.8211 - accuracy: 0.5915 - val_loss: 77.4563 - val_accuracy: 0.5742\n",
      "Epoch 182/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 56.9211 - accuracy: 0.6012 - val_loss: 38.3824 - val_accuracy: 0.5673\n",
      "Epoch 183/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 53.9667 - accuracy: 0.6473 - val_loss: 79.2220 - val_accuracy: 0.6616\n",
      "Epoch 184/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 53.4806 - accuracy: 0.6182 - val_loss: 42.6275 - val_accuracy: 0.5520\n",
      "Epoch 185/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 53.6243 - accuracy: 0.5849 - val_loss: 69.5950 - val_accuracy: 0.5964\n",
      "Epoch 186/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 58.8674 - accuracy: 0.6293 - val_loss: 91.9107 - val_accuracy: 0.6338\n",
      "Epoch 187/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 68.4386 - accuracy: 0.5824 - val_loss: 75.9855 - val_accuracy: 0.6990\n",
      "Epoch 188/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 69.3049 - accuracy: 0.6022 - val_loss: 50.0575 - val_accuracy: 0.6602\n",
      "Epoch 189/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 54.1215 - accuracy: 0.6064 - val_loss: 52.4157 - val_accuracy: 0.5950\n",
      "Epoch 190/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 53.8881 - accuracy: 0.6119 - val_loss: 59.3157 - val_accuracy: 0.6214\n",
      "Epoch 191/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 52.7859 - accuracy: 0.6265 - val_loss: 49.2419 - val_accuracy: 0.5756\n",
      "Epoch 192/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 53.1167 - accuracy: 0.6251 - val_loss: 37.9970 - val_accuracy: 0.7115\n",
      "Epoch 193/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 50.1954 - accuracy: 0.6109 - val_loss: 82.6006 - val_accuracy: 0.5908\n",
      "Epoch 194/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 51.8321 - accuracy: 0.6175 - val_loss: 51.4387 - val_accuracy: 0.5798\n",
      "Epoch 195/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 51.7957 - accuracy: 0.6175 - val_loss: 58.9988 - val_accuracy: 0.6283\n",
      "Epoch 196/250\n",
      "2881/2881 [==============================] - 0s 20us/step - loss: 64.1133 - accuracy: 0.6015 - val_loss: 68.8628 - val_accuracy: 0.5673\n",
      "Epoch 197/250\n",
      "2881/2881 [==============================] - 0s 26us/step - loss: 52.0864 - accuracy: 0.6199 - val_loss: 68.2235 - val_accuracy: 0.5936\n",
      "Epoch 198/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 53.2338 - accuracy: 0.5845 - val_loss: 50.6323 - val_accuracy: 0.6685\n",
      "Epoch 199/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 51.8617 - accuracy: 0.6043 - val_loss: 39.8458 - val_accuracy: 0.6158\n",
      "Epoch 200/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 51.4911 - accuracy: 0.6296 - val_loss: 54.6412 - val_accuracy: 0.5506\n",
      "Epoch 201/250\n",
      "2881/2881 [==============================] - 0s 20us/step - loss: 52.0748 - accuracy: 0.6012 - val_loss: 66.4121 - val_accuracy: 0.5978\n",
      "Epoch 202/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 51.1028 - accuracy: 0.6359 - val_loss: 32.4637 - val_accuracy: 0.6463\n",
      "Epoch 203/250\n",
      "2881/2881 [==============================] - 0s 20us/step - loss: 50.7353 - accuracy: 0.5935 - val_loss: 60.6766 - val_accuracy: 0.5908\n",
      "Epoch 204/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 51.8417 - accuracy: 0.6644 - val_loss: 45.3960 - val_accuracy: 0.5950\n",
      "Epoch 205/250\n",
      "2881/2881 [==============================] - 0s 20us/step - loss: 50.4261 - accuracy: 0.6324 - val_loss: 68.4867 - val_accuracy: 0.6200\n",
      "Epoch 206/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 50.8010 - accuracy: 0.6085 - val_loss: 67.1073 - val_accuracy: 0.5770\n",
      "Epoch 207/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 50.5119 - accuracy: 0.5956 - val_loss: 59.3176 - val_accuracy: 0.6200\n",
      "Epoch 208/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 49.5285 - accuracy: 0.6189 - val_loss: 55.4809 - val_accuracy: 0.6685\n",
      "Epoch 209/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 48.7362 - accuracy: 0.6224 - val_loss: 40.9892 - val_accuracy: 0.6297\n",
      "Epoch 210/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 48.9219 - accuracy: 0.5974 - val_loss: 26.8657 - val_accuracy: 0.5811\n",
      "Epoch 211/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 48.0353 - accuracy: 0.5804 - val_loss: 67.1649 - val_accuracy: 0.6408\n",
      "Epoch 212/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 59.7923 - accuracy: 0.6175 - val_loss: 53.7713 - val_accuracy: 0.5437\n",
      "Epoch 213/250\n",
      "2881/2881 [==============================] - 0s 24us/step - loss: 49.5267 - accuracy: 0.6428 - val_loss: 56.1195 - val_accuracy: 0.6893\n",
      "Epoch 214/250\n",
      "2881/2881 [==============================] - 0s 27us/step - loss: 47.6131 - accuracy: 0.6251 - val_loss: 64.6537 - val_accuracy: 0.5908\n",
      "Epoch 215/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 48.3750 - accuracy: 0.6328 - val_loss: 46.0847 - val_accuracy: 0.6491\n",
      "Epoch 216/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 49.4931 - accuracy: 0.6352 - val_loss: 36.7542 - val_accuracy: 0.6463\n",
      "Epoch 217/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 48.6890 - accuracy: 0.6460 - val_loss: 51.6832 - val_accuracy: 0.6338\n",
      "Epoch 218/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 48.4137 - accuracy: 0.6727 - val_loss: 59.1794 - val_accuracy: 0.6935\n",
      "Epoch 219/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 47.8790 - accuracy: 0.6473 - val_loss: 63.3547 - val_accuracy: 0.5756\n",
      "Epoch 220/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 47.8930 - accuracy: 0.6088 - val_loss: 58.1341 - val_accuracy: 0.6325\n",
      "Epoch 221/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 48.0124 - accuracy: 0.6276 - val_loss: 54.0112 - val_accuracy: 0.6644\n",
      "Epoch 222/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 62.2779 - accuracy: 0.6484 - val_loss: 49.9013 - val_accuracy: 0.5576\n",
      "Epoch 223/250\n",
      "2881/2881 [==============================] - 0s 27us/step - loss: 45.6552 - accuracy: 0.5272 - val_loss: 29.8060 - val_accuracy: 0.6546\n",
      "Epoch 224/250\n",
      "2881/2881 [==============================] - 0s 25us/step - loss: 47.2890 - accuracy: 0.6328 - val_loss: 37.0327 - val_accuracy: 0.6907\n",
      "Epoch 225/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 46.0888 - accuracy: 0.6591 - val_loss: 73.6869 - val_accuracy: 0.6436\n",
      "Epoch 226/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 48.0117 - accuracy: 0.6109 - val_loss: 34.6944 - val_accuracy: 0.6449\n",
      "Epoch 227/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 46.3523 - accuracy: 0.6352 - val_loss: 47.4288 - val_accuracy: 0.5992\n",
      "Epoch 228/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 46.4132 - accuracy: 0.6470 - val_loss: 47.3505 - val_accuracy: 0.6408\n",
      "Epoch 229/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 46.4663 - accuracy: 0.6283 - val_loss: 83.2633 - val_accuracy: 0.6408\n",
      "Epoch 230/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 46.3180 - accuracy: 0.6397 - val_loss: 23.8322 - val_accuracy: 0.6311\n",
      "Epoch 231/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 45.3659 - accuracy: 0.6470 - val_loss: 68.7379 - val_accuracy: 0.6879\n",
      "Epoch 232/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 45.6114 - accuracy: 0.6414 - val_loss: 32.2865 - val_accuracy: 0.7018\n",
      "Epoch 233/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 45.8801 - accuracy: 0.6460 - val_loss: 59.1230 - val_accuracy: 0.6380\n",
      "Epoch 234/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 45.7412 - accuracy: 0.6317 - val_loss: 39.1706 - val_accuracy: 0.6519\n",
      "Epoch 235/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 45.1700 - accuracy: 0.6373 - val_loss: 47.1543 - val_accuracy: 0.5784\n",
      "Epoch 236/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 45.4359 - accuracy: 0.6359 - val_loss: 52.8828 - val_accuracy: 0.7032\n",
      "Epoch 237/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 43.9389 - accuracy: 0.6244 - val_loss: 36.3789 - val_accuracy: 0.6172\n",
      "Epoch 238/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 43.7264 - accuracy: 0.6387 - val_loss: 59.2437 - val_accuracy: 0.6408\n",
      "Epoch 239/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 44.1353 - accuracy: 0.6407 - val_loss: 26.0253 - val_accuracy: 0.6949\n",
      "Epoch 240/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 44.4210 - accuracy: 0.6036 - val_loss: 57.8913 - val_accuracy: 0.6269\n",
      "Epoch 241/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 45.2930 - accuracy: 0.6380 - val_loss: 23.0504 - val_accuracy: 0.6449\n",
      "Epoch 242/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 44.0001 - accuracy: 0.6473 - val_loss: 53.1447 - val_accuracy: 0.6006\n",
      "Epoch 243/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 45.0196 - accuracy: 0.6085 - val_loss: 44.1531 - val_accuracy: 0.5520\n",
      "Epoch 244/250\n",
      "2881/2881 [==============================] - 0s 21us/step - loss: 45.5650 - accuracy: 0.6133 - val_loss: 46.1920 - val_accuracy: 0.6297\n",
      "Epoch 245/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 42.4399 - accuracy: 0.6345 - val_loss: 47.9754 - val_accuracy: 0.6602\n",
      "Epoch 246/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 42.7893 - accuracy: 0.6279 - val_loss: 35.1605 - val_accuracy: 0.6602\n",
      "Epoch 247/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 42.6669 - accuracy: 0.6133 - val_loss: 43.4554 - val_accuracy: 0.6283\n",
      "Epoch 248/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 42.5809 - accuracy: 0.6401 - val_loss: 56.6079 - val_accuracy: 0.6671\n",
      "Epoch 249/250\n",
      "2881/2881 [==============================] - 0s 22us/step - loss: 43.4247 - accuracy: 0.6435 - val_loss: 28.3191 - val_accuracy: 0.6283\n",
      "Epoch 250/250\n",
      "2881/2881 [==============================] - 0s 23us/step - loss: 42.7486 - accuracy: 0.6407 - val_loss: 35.3523 - val_accuracy: 0.6227\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_test,y_test), epochs=training_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8307.65818998  138.5996842  8215.5533698    58.79842978 8070.34314634\n",
      "   55.55791575 8201.52035824  137.48486608 8286.44003785   64.81245699\n",
      " 7947.61965135  175.39406315 8098.42546584   34.35981712 8050.50941845\n",
      "  130.20741147 8374.50593301  135.6862201  7984.31161601  110.82733975\n",
      " 8327.14487126   22.41812534 8167.65327501   35.70916312 8072.02552079\n",
      "  156.94057174 7884.72049854  151.11977371 7944.2419176   105.50729335]\n",
      "[8226.056     155.9529   8133.201      66.39265  7971.0044     33.816166\n",
      " 8164.476     103.960144 8213.773      21.572456 7851.5767    138.4213\n",
      " 8031.546      38.639545 7970.9243    128.02925  8294.385     107.067085\n",
      " 7943.5537     98.74298  8282.372      20.356298 8093.6333     34.8546\n",
      " 7990.798     161.96658  7821.744     148.9835   7877.813     103.53112 ]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are the results affected if I try to predict on using my prediction as input data? For how many rounds can this be accurate enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>...</th>\n",
       "      <th>y_41</th>\n",
       "      <th>y_42</th>\n",
       "      <th>y_43</th>\n",
       "      <th>y_44</th>\n",
       "      <th>y_45</th>\n",
       "      <th>y_46</th>\n",
       "      <th>y_47</th>\n",
       "      <th>y_48</th>\n",
       "      <th>y_49</th>\n",
       "      <th>y_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[61.80999150562753, 24.420046719048628, 109.00...</td>\n",
       "      <td>[70.80009877085162, 22.786106233538195, 115.03...</td>\n",
       "      <td>[78.53846153846153, 23.79722075869336, 130.692...</td>\n",
       "      <td>[92.43681939593179, 22.50037668652832, 141.306...</td>\n",
       "      <td>[104.59782115297321, 22.04513325984048, 153.67...</td>\n",
       "      <td>[114.654700661428, 17.817739838317603, 167.487...</td>\n",
       "      <td>[130.2578821609651, 15.584474619733086, 177.42...</td>\n",
       "      <td>[137.88253604193972, 15.713794233289649, 183.3...</td>\n",
       "      <td>[151.1877135081929, 20.428405998494586, 191.79...</td>\n",
       "      <td>[165.68593072270755, 20.306249618180708, 203.6...</td>\n",
       "      <td>...</td>\n",
       "      <td>[548.3095747526077, 55.4499866274405, 542.7064...</td>\n",
       "      <td>[559.3591679425583, 54.50747056649596, 551.733...</td>\n",
       "      <td>[571.6816533108394, 56.70940531421341, 561.582...</td>\n",
       "      <td>[579.4599029964786, 54.63856222177928, 574.765...</td>\n",
       "      <td>[595.5333143912487, 52.484301747407294, 584.49...</td>\n",
       "      <td>[608.6178598298512, 54.07367324497946, 596.594...</td>\n",
       "      <td>[616.5485332302082, 54.14087619468538, 610.544...</td>\n",
       "      <td>[630.1560680698611, 48.47305567995223, 624.534...</td>\n",
       "      <td>[645.4160783268949, 54.60836552550953, 632.508...</td>\n",
       "      <td>[655.4035507361932, 59.76984000425239, 648.778...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[70.80009877085162, 22.786106233538195, 115.03...</td>\n",
       "      <td>[78.53846153846153, 23.79722075869336, 130.692...</td>\n",
       "      <td>[92.43681939593179, 22.50037668652832, 141.306...</td>\n",
       "      <td>[104.59782115297321, 22.04513325984048, 153.67...</td>\n",
       "      <td>[114.654700661428, 17.817739838317603, 167.487...</td>\n",
       "      <td>[130.2578821609651, 15.584474619733086, 177.42...</td>\n",
       "      <td>[137.88253604193972, 15.713794233289649, 183.3...</td>\n",
       "      <td>[151.1877135081929, 20.428405998494586, 191.79...</td>\n",
       "      <td>[165.68593072270755, 20.306249618180708, 203.6...</td>\n",
       "      <td>[175.51762512381282, 22.851074986890406, 214.4...</td>\n",
       "      <td>...</td>\n",
       "      <td>[559.3591679425583, 54.50747056649596, 551.733...</td>\n",
       "      <td>[571.6816533108394, 56.70940531421341, 561.582...</td>\n",
       "      <td>[579.4599029964786, 54.63856222177928, 574.765...</td>\n",
       "      <td>[595.5333143912487, 52.484301747407294, 584.49...</td>\n",
       "      <td>[608.6178598298512, 54.07367324497946, 596.594...</td>\n",
       "      <td>[616.5485332302082, 54.14087619468538, 610.544...</td>\n",
       "      <td>[630.1560680698611, 48.47305567995223, 624.534...</td>\n",
       "      <td>[645.4160783268949, 54.60836552550953, 632.508...</td>\n",
       "      <td>[655.4035507361932, 59.76984000425239, 648.778...</td>\n",
       "      <td>[664.2836707746479, 64.61612382629107, 654.376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[78.53846153846153, 23.79722075869336, 130.692...</td>\n",
       "      <td>[92.43681939593179, 22.50037668652832, 141.306...</td>\n",
       "      <td>[104.59782115297321, 22.04513325984048, 153.67...</td>\n",
       "      <td>[114.654700661428, 17.817739838317603, 167.487...</td>\n",
       "      <td>[130.2578821609651, 15.584474619733086, 177.42...</td>\n",
       "      <td>[137.88253604193972, 15.713794233289649, 183.3...</td>\n",
       "      <td>[151.1877135081929, 20.428405998494586, 191.79...</td>\n",
       "      <td>[165.68593072270755, 20.306249618180708, 203.6...</td>\n",
       "      <td>[175.51762512381282, 22.851074986890406, 214.4...</td>\n",
       "      <td>[187.1709068399876, 20.589291241101826, 222.27...</td>\n",
       "      <td>...</td>\n",
       "      <td>[571.6816533108394, 56.70940531421341, 561.582...</td>\n",
       "      <td>[579.4599029964786, 54.63856222177928, 574.765...</td>\n",
       "      <td>[595.5333143912487, 52.484301747407294, 584.49...</td>\n",
       "      <td>[608.6178598298512, 54.07367324497946, 596.594...</td>\n",
       "      <td>[616.5485332302082, 54.14087619468538, 610.544...</td>\n",
       "      <td>[630.1560680698611, 48.47305567995223, 624.534...</td>\n",
       "      <td>[645.4160783268949, 54.60836552550953, 632.508...</td>\n",
       "      <td>[655.4035507361932, 59.76984000425239, 648.778...</td>\n",
       "      <td>[664.2836707746479, 64.61612382629107, 654.376...</td>\n",
       "      <td>[681.5213026017112, 66.98795180722891, 667.341...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[92.43681939593179, 22.50037668652832, 141.306...</td>\n",
       "      <td>[104.59782115297321, 22.04513325984048, 153.67...</td>\n",
       "      <td>[114.654700661428, 17.817739838317603, 167.487...</td>\n",
       "      <td>[130.2578821609651, 15.584474619733086, 177.42...</td>\n",
       "      <td>[137.88253604193972, 15.713794233289649, 183.3...</td>\n",
       "      <td>[151.1877135081929, 20.428405998494586, 191.79...</td>\n",
       "      <td>[165.68593072270755, 20.306249618180708, 203.6...</td>\n",
       "      <td>[175.51762512381282, 22.851074986890406, 214.4...</td>\n",
       "      <td>[187.1709068399876, 20.589291241101826, 222.27...</td>\n",
       "      <td>[204.5807988024767, 16.58671837790025, 232.493...</td>\n",
       "      <td>...</td>\n",
       "      <td>[579.4599029964786, 54.63856222177928, 574.765...</td>\n",
       "      <td>[595.5333143912487, 52.484301747407294, 584.49...</td>\n",
       "      <td>[608.6178598298512, 54.07367324497946, 596.594...</td>\n",
       "      <td>[616.5485332302082, 54.14087619468538, 610.544...</td>\n",
       "      <td>[630.1560680698611, 48.47305567995223, 624.534...</td>\n",
       "      <td>[645.4160783268949, 54.60836552550953, 632.508...</td>\n",
       "      <td>[655.4035507361932, 59.76984000425239, 648.778...</td>\n",
       "      <td>[664.2836707746479, 64.61612382629107, 654.376...</td>\n",
       "      <td>[681.5213026017112, 66.98795180722891, 667.341...</td>\n",
       "      <td>[688.0223759593558, 65.73148848773107, 682.724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[104.59782115297321, 22.04513325984048, 153.67...</td>\n",
       "      <td>[114.654700661428, 17.817739838317603, 167.487...</td>\n",
       "      <td>[130.2578821609651, 15.584474619733086, 177.42...</td>\n",
       "      <td>[137.88253604193972, 15.713794233289649, 183.3...</td>\n",
       "      <td>[151.1877135081929, 20.428405998494586, 191.79...</td>\n",
       "      <td>[165.68593072270755, 20.306249618180708, 203.6...</td>\n",
       "      <td>[175.51762512381282, 22.851074986890406, 214.4...</td>\n",
       "      <td>[187.1709068399876, 20.589291241101826, 222.27...</td>\n",
       "      <td>[204.5807988024767, 16.58671837790025, 232.493...</td>\n",
       "      <td>[209.63801231212915, 22.24546614164495, 243.42...</td>\n",
       "      <td>...</td>\n",
       "      <td>[595.5333143912487, 52.484301747407294, 584.49...</td>\n",
       "      <td>[608.6178598298512, 54.07367324497946, 596.594...</td>\n",
       "      <td>[616.5485332302082, 54.14087619468538, 610.544...</td>\n",
       "      <td>[630.1560680698611, 48.47305567995223, 624.534...</td>\n",
       "      <td>[645.4160783268949, 54.60836552550953, 632.508...</td>\n",
       "      <td>[655.4035507361932, 59.76984000425239, 648.778...</td>\n",
       "      <td>[664.2836707746479, 64.61612382629107, 654.376...</td>\n",
       "      <td>[681.5213026017112, 66.98795180722891, 667.341...</td>\n",
       "      <td>[688.0223759593558, 65.73148848773107, 682.724...</td>\n",
       "      <td>[700.2392071106094, 66.80523419864559, 692.610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>[8437.670223857713, 135.98620055197793, 8354.1...</td>\n",
       "      <td>[8446.438829999202, 139.95640392125608, 8373.5...</td>\n",
       "      <td>[8466.83463489252, 134.7544481120683, 8386.770...</td>\n",
       "      <td>[8469.190992493744, 138.5072679613964, 8395.26...</td>\n",
       "      <td>[8482.545345967035, 138.31156939246756, 8406.1...</td>\n",
       "      <td>[8492.787600980304, 137.14967777071794, 8418.2...</td>\n",
       "      <td>[8506.449072044425, 145.54815139558673, 8428.5...</td>\n",
       "      <td>[8510.666243413116, 139.60396165322837, 8440.1...</td>\n",
       "      <td>[8522.268657609671, 140.52361003052246, 8452.9...</td>\n",
       "      <td>[8535.609989238463, 139.60087358359183, 8459.2...</td>\n",
       "      <td>...</td>\n",
       "      <td>[8883.88434368326, 159.93483379880618, 8802.23...</td>\n",
       "      <td>[8897.635639854818, 161.3784685634001, 8813.47...</td>\n",
       "      <td>[8910.625345877144, 159.51474424855718, 8821.4...</td>\n",
       "      <td>[8923.702892001807, 159.2881834613647, 8836.41...</td>\n",
       "      <td>[8935.34010033835, 157.95111422237778, 8847.53...</td>\n",
       "      <td>[8940.46656641604, 155.12932330827067, 8861.91...</td>\n",
       "      <td>[8954.623459439574, 159.4531853577779, 8867.34...</td>\n",
       "      <td>[8963.531319216798, 166.59466643040668, 8880.4...</td>\n",
       "      <td>[8971.234802590348, 161.42225471763803, 8889.3...</td>\n",
       "      <td>[8981.526291116494, 162.7594343308071, 8905.46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>[8446.438829999202, 139.95640392125608, 8373.5...</td>\n",
       "      <td>[8466.83463489252, 134.7544481120683, 8386.770...</td>\n",
       "      <td>[8469.190992493744, 138.5072679613964, 8395.26...</td>\n",
       "      <td>[8482.545345967035, 138.31156939246756, 8406.1...</td>\n",
       "      <td>[8492.787600980304, 137.14967777071794, 8418.2...</td>\n",
       "      <td>[8506.449072044425, 145.54815139558673, 8428.5...</td>\n",
       "      <td>[8510.666243413116, 139.60396165322837, 8440.1...</td>\n",
       "      <td>[8522.268657609671, 140.52361003052246, 8452.9...</td>\n",
       "      <td>[8535.609989238463, 139.60087358359183, 8459.2...</td>\n",
       "      <td>[8543.693538597363, 136.3635159741765, 8465.12...</td>\n",
       "      <td>...</td>\n",
       "      <td>[8897.635639854818, 161.3784685634001, 8813.47...</td>\n",
       "      <td>[8910.625345877144, 159.51474424855718, 8821.4...</td>\n",
       "      <td>[8923.702892001807, 159.2881834613647, 8836.41...</td>\n",
       "      <td>[8935.34010033835, 157.95111422237778, 8847.53...</td>\n",
       "      <td>[8940.46656641604, 155.12932330827067, 8861.91...</td>\n",
       "      <td>[8954.623459439574, 159.4531853577779, 8867.34...</td>\n",
       "      <td>[8963.531319216798, 166.59466643040668, 8880.4...</td>\n",
       "      <td>[8971.234802590348, 161.42225471763803, 8889.3...</td>\n",
       "      <td>[8981.526291116494, 162.7594343308071, 8905.46...</td>\n",
       "      <td>[8990.157367074604, 162.0370600843532, 8920.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5151</th>\n",
       "      <td>[8466.83463489252, 134.7544481120683, 8386.770...</td>\n",
       "      <td>[8469.190992493744, 138.5072679613964, 8395.26...</td>\n",
       "      <td>[8482.545345967035, 138.31156939246756, 8406.1...</td>\n",
       "      <td>[8492.787600980304, 137.14967777071794, 8418.2...</td>\n",
       "      <td>[8506.449072044425, 145.54815139558673, 8428.5...</td>\n",
       "      <td>[8510.666243413116, 139.60396165322837, 8440.1...</td>\n",
       "      <td>[8522.268657609671, 140.52361003052246, 8452.9...</td>\n",
       "      <td>[8535.609989238463, 139.60087358359183, 8459.2...</td>\n",
       "      <td>[8543.693538597363, 136.3635159741765, 8465.12...</td>\n",
       "      <td>[8555.416489178977, 138.29708004122296, 8474.3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[8910.625345877144, 159.51474424855718, 8821.4...</td>\n",
       "      <td>[8923.702892001807, 159.2881834613647, 8836.41...</td>\n",
       "      <td>[8935.34010033835, 157.95111422237778, 8847.53...</td>\n",
       "      <td>[8940.46656641604, 155.12932330827067, 8861.91...</td>\n",
       "      <td>[8954.623459439574, 159.4531853577779, 8867.34...</td>\n",
       "      <td>[8963.531319216798, 166.59466643040668, 8880.4...</td>\n",
       "      <td>[8971.234802590348, 161.42225471763803, 8889.3...</td>\n",
       "      <td>[8981.526291116494, 162.7594343308071, 8905.46...</td>\n",
       "      <td>[8990.157367074604, 162.0370600843532, 8920.93...</td>\n",
       "      <td>[9007.540353356892, 162.55978798586568, 8926.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5152</th>\n",
       "      <td>[8469.190992493744, 138.5072679613964, 8395.26...</td>\n",
       "      <td>[8482.545345967035, 138.31156939246756, 8406.1...</td>\n",
       "      <td>[8492.787600980304, 137.14967777071794, 8418.2...</td>\n",
       "      <td>[8506.449072044425, 145.54815139558673, 8428.5...</td>\n",
       "      <td>[8510.666243413116, 139.60396165322837, 8440.1...</td>\n",
       "      <td>[8522.268657609671, 140.52361003052246, 8452.9...</td>\n",
       "      <td>[8535.609989238463, 139.60087358359183, 8459.2...</td>\n",
       "      <td>[8543.693538597363, 136.3635159741765, 8465.12...</td>\n",
       "      <td>[8555.416489178977, 138.29708004122296, 8474.3...</td>\n",
       "      <td>[8569.926518992972, 139.0579129970643, 8482.14...</td>\n",
       "      <td>...</td>\n",
       "      <td>[8923.702892001807, 159.2881834613647, 8836.41...</td>\n",
       "      <td>[8935.34010033835, 157.95111422237778, 8847.53...</td>\n",
       "      <td>[8940.46656641604, 155.12932330827067, 8861.91...</td>\n",
       "      <td>[8954.623459439574, 159.4531853577779, 8867.34...</td>\n",
       "      <td>[8963.531319216798, 166.59466643040668, 8880.4...</td>\n",
       "      <td>[8971.234802590348, 161.42225471763803, 8889.3...</td>\n",
       "      <td>[8981.526291116494, 162.7594343308071, 8905.46...</td>\n",
       "      <td>[8990.157367074604, 162.0370600843532, 8920.93...</td>\n",
       "      <td>[9007.540353356892, 162.55978798586568, 8926.0...</td>\n",
       "      <td>[9017.586395147311, 165.976863084922, 8941.781...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>[8482.545345967035, 138.31156939246756, 8406.1...</td>\n",
       "      <td>[8492.787600980304, 137.14967777071794, 8418.2...</td>\n",
       "      <td>[8506.449072044425, 145.54815139558673, 8428.5...</td>\n",
       "      <td>[8510.666243413116, 139.60396165322837, 8440.1...</td>\n",
       "      <td>[8522.268657609671, 140.52361003052246, 8452.9...</td>\n",
       "      <td>[8535.609989238463, 139.60087358359183, 8459.2...</td>\n",
       "      <td>[8543.693538597363, 136.3635159741765, 8465.12...</td>\n",
       "      <td>[8555.416489178977, 138.29708004122296, 8474.3...</td>\n",
       "      <td>[8569.926518992972, 139.0579129970643, 8482.14...</td>\n",
       "      <td>[8576.6442358155, 137.6659863548895, 8495.5077...</td>\n",
       "      <td>...</td>\n",
       "      <td>[8935.34010033835, 157.95111422237778, 8847.53...</td>\n",
       "      <td>[8940.46656641604, 155.12932330827067, 8861.91...</td>\n",
       "      <td>[8954.623459439574, 159.4531853577779, 8867.34...</td>\n",
       "      <td>[8963.531319216798, 166.59466643040668, 8880.4...</td>\n",
       "      <td>[8971.234802590348, 161.42225471763803, 8889.3...</td>\n",
       "      <td>[8981.526291116494, 162.7594343308071, 8905.46...</td>\n",
       "      <td>[8990.157367074604, 162.0370600843532, 8920.93...</td>\n",
       "      <td>[9007.540353356892, 162.55978798586568, 8926.0...</td>\n",
       "      <td>[9017.586395147311, 165.976863084922, 8941.781...</td>\n",
       "      <td>[9030.630412102242, 161.97515649452268, 8950.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5154 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      X  \\\n",
       "0     [61.80999150562753, 24.420046719048628, 109.00...   \n",
       "1     [70.80009877085162, 22.786106233538195, 115.03...   \n",
       "2     [78.53846153846153, 23.79722075869336, 130.692...   \n",
       "3     [92.43681939593179, 22.50037668652832, 141.306...   \n",
       "4     [104.59782115297321, 22.04513325984048, 153.67...   \n",
       "...                                                 ...   \n",
       "5149  [8437.670223857713, 135.98620055197793, 8354.1...   \n",
       "5150  [8446.438829999202, 139.95640392125608, 8373.5...   \n",
       "5151  [8466.83463489252, 134.7544481120683, 8386.770...   \n",
       "5152  [8469.190992493744, 138.5072679613964, 8395.26...   \n",
       "5153  [8482.545345967035, 138.31156939246756, 8406.1...   \n",
       "\n",
       "                                                    y_1  \\\n",
       "0     [70.80009877085162, 22.786106233538195, 115.03...   \n",
       "1     [78.53846153846153, 23.79722075869336, 130.692...   \n",
       "2     [92.43681939593179, 22.50037668652832, 141.306...   \n",
       "3     [104.59782115297321, 22.04513325984048, 153.67...   \n",
       "4     [114.654700661428, 17.817739838317603, 167.487...   \n",
       "...                                                 ...   \n",
       "5149  [8446.438829999202, 139.95640392125608, 8373.5...   \n",
       "5150  [8466.83463489252, 134.7544481120683, 8386.770...   \n",
       "5151  [8469.190992493744, 138.5072679613964, 8395.26...   \n",
       "5152  [8482.545345967035, 138.31156939246756, 8406.1...   \n",
       "5153  [8492.787600980304, 137.14967777071794, 8418.2...   \n",
       "\n",
       "                                                    y_2  \\\n",
       "0     [78.53846153846153, 23.79722075869336, 130.692...   \n",
       "1     [92.43681939593179, 22.50037668652832, 141.306...   \n",
       "2     [104.59782115297321, 22.04513325984048, 153.67...   \n",
       "3     [114.654700661428, 17.817739838317603, 167.487...   \n",
       "4     [130.2578821609651, 15.584474619733086, 177.42...   \n",
       "...                                                 ...   \n",
       "5149  [8466.83463489252, 134.7544481120683, 8386.770...   \n",
       "5150  [8469.190992493744, 138.5072679613964, 8395.26...   \n",
       "5151  [8482.545345967035, 138.31156939246756, 8406.1...   \n",
       "5152  [8492.787600980304, 137.14967777071794, 8418.2...   \n",
       "5153  [8506.449072044425, 145.54815139558673, 8428.5...   \n",
       "\n",
       "                                                    y_3  \\\n",
       "0     [92.43681939593179, 22.50037668652832, 141.306...   \n",
       "1     [104.59782115297321, 22.04513325984048, 153.67...   \n",
       "2     [114.654700661428, 17.817739838317603, 167.487...   \n",
       "3     [130.2578821609651, 15.584474619733086, 177.42...   \n",
       "4     [137.88253604193972, 15.713794233289649, 183.3...   \n",
       "...                                                 ...   \n",
       "5149  [8469.190992493744, 138.5072679613964, 8395.26...   \n",
       "5150  [8482.545345967035, 138.31156939246756, 8406.1...   \n",
       "5151  [8492.787600980304, 137.14967777071794, 8418.2...   \n",
       "5152  [8506.449072044425, 145.54815139558673, 8428.5...   \n",
       "5153  [8510.666243413116, 139.60396165322837, 8440.1...   \n",
       "\n",
       "                                                    y_4  \\\n",
       "0     [104.59782115297321, 22.04513325984048, 153.67...   \n",
       "1     [114.654700661428, 17.817739838317603, 167.487...   \n",
       "2     [130.2578821609651, 15.584474619733086, 177.42...   \n",
       "3     [137.88253604193972, 15.713794233289649, 183.3...   \n",
       "4     [151.1877135081929, 20.428405998494586, 191.79...   \n",
       "...                                                 ...   \n",
       "5149  [8482.545345967035, 138.31156939246756, 8406.1...   \n",
       "5150  [8492.787600980304, 137.14967777071794, 8418.2...   \n",
       "5151  [8506.449072044425, 145.54815139558673, 8428.5...   \n",
       "5152  [8510.666243413116, 139.60396165322837, 8440.1...   \n",
       "5153  [8522.268657609671, 140.52361003052246, 8452.9...   \n",
       "\n",
       "                                                    y_5  \\\n",
       "0     [114.654700661428, 17.817739838317603, 167.487...   \n",
       "1     [130.2578821609651, 15.584474619733086, 177.42...   \n",
       "2     [137.88253604193972, 15.713794233289649, 183.3...   \n",
       "3     [151.1877135081929, 20.428405998494586, 191.79...   \n",
       "4     [165.68593072270755, 20.306249618180708, 203.6...   \n",
       "...                                                 ...   \n",
       "5149  [8492.787600980304, 137.14967777071794, 8418.2...   \n",
       "5150  [8506.449072044425, 145.54815139558673, 8428.5...   \n",
       "5151  [8510.666243413116, 139.60396165322837, 8440.1...   \n",
       "5152  [8522.268657609671, 140.52361003052246, 8452.9...   \n",
       "5153  [8535.609989238463, 139.60087358359183, 8459.2...   \n",
       "\n",
       "                                                    y_6  \\\n",
       "0     [130.2578821609651, 15.584474619733086, 177.42...   \n",
       "1     [137.88253604193972, 15.713794233289649, 183.3...   \n",
       "2     [151.1877135081929, 20.428405998494586, 191.79...   \n",
       "3     [165.68593072270755, 20.306249618180708, 203.6...   \n",
       "4     [175.51762512381282, 22.851074986890406, 214.4...   \n",
       "...                                                 ...   \n",
       "5149  [8506.449072044425, 145.54815139558673, 8428.5...   \n",
       "5150  [8510.666243413116, 139.60396165322837, 8440.1...   \n",
       "5151  [8522.268657609671, 140.52361003052246, 8452.9...   \n",
       "5152  [8535.609989238463, 139.60087358359183, 8459.2...   \n",
       "5153  [8543.693538597363, 136.3635159741765, 8465.12...   \n",
       "\n",
       "                                                    y_7  \\\n",
       "0     [137.88253604193972, 15.713794233289649, 183.3...   \n",
       "1     [151.1877135081929, 20.428405998494586, 191.79...   \n",
       "2     [165.68593072270755, 20.306249618180708, 203.6...   \n",
       "3     [175.51762512381282, 22.851074986890406, 214.4...   \n",
       "4     [187.1709068399876, 20.589291241101826, 222.27...   \n",
       "...                                                 ...   \n",
       "5149  [8510.666243413116, 139.60396165322837, 8440.1...   \n",
       "5150  [8522.268657609671, 140.52361003052246, 8452.9...   \n",
       "5151  [8535.609989238463, 139.60087358359183, 8459.2...   \n",
       "5152  [8543.693538597363, 136.3635159741765, 8465.12...   \n",
       "5153  [8555.416489178977, 138.29708004122296, 8474.3...   \n",
       "\n",
       "                                                    y_8  \\\n",
       "0     [151.1877135081929, 20.428405998494586, 191.79...   \n",
       "1     [165.68593072270755, 20.306249618180708, 203.6...   \n",
       "2     [175.51762512381282, 22.851074986890406, 214.4...   \n",
       "3     [187.1709068399876, 20.589291241101826, 222.27...   \n",
       "4     [204.5807988024767, 16.58671837790025, 232.493...   \n",
       "...                                                 ...   \n",
       "5149  [8522.268657609671, 140.52361003052246, 8452.9...   \n",
       "5150  [8535.609989238463, 139.60087358359183, 8459.2...   \n",
       "5151  [8543.693538597363, 136.3635159741765, 8465.12...   \n",
       "5152  [8555.416489178977, 138.29708004122296, 8474.3...   \n",
       "5153  [8569.926518992972, 139.0579129970643, 8482.14...   \n",
       "\n",
       "                                                    y_9  ...  \\\n",
       "0     [165.68593072270755, 20.306249618180708, 203.6...  ...   \n",
       "1     [175.51762512381282, 22.851074986890406, 214.4...  ...   \n",
       "2     [187.1709068399876, 20.589291241101826, 222.27...  ...   \n",
       "3     [204.5807988024767, 16.58671837790025, 232.493...  ...   \n",
       "4     [209.63801231212915, 22.24546614164495, 243.42...  ...   \n",
       "...                                                 ...  ...   \n",
       "5149  [8535.609989238463, 139.60087358359183, 8459.2...  ...   \n",
       "5150  [8543.693538597363, 136.3635159741765, 8465.12...  ...   \n",
       "5151  [8555.416489178977, 138.29708004122296, 8474.3...  ...   \n",
       "5152  [8569.926518992972, 139.0579129970643, 8482.14...  ...   \n",
       "5153  [8576.6442358155, 137.6659863548895, 8495.5077...  ...   \n",
       "\n",
       "                                                   y_41  \\\n",
       "0     [548.3095747526077, 55.4499866274405, 542.7064...   \n",
       "1     [559.3591679425583, 54.50747056649596, 551.733...   \n",
       "2     [571.6816533108394, 56.70940531421341, 561.582...   \n",
       "3     [579.4599029964786, 54.63856222177928, 574.765...   \n",
       "4     [595.5333143912487, 52.484301747407294, 584.49...   \n",
       "...                                                 ...   \n",
       "5149  [8883.88434368326, 159.93483379880618, 8802.23...   \n",
       "5150  [8897.635639854818, 161.3784685634001, 8813.47...   \n",
       "5151  [8910.625345877144, 159.51474424855718, 8821.4...   \n",
       "5152  [8923.702892001807, 159.2881834613647, 8836.41...   \n",
       "5153  [8935.34010033835, 157.95111422237778, 8847.53...   \n",
       "\n",
       "                                                   y_42  \\\n",
       "0     [559.3591679425583, 54.50747056649596, 551.733...   \n",
       "1     [571.6816533108394, 56.70940531421341, 561.582...   \n",
       "2     [579.4599029964786, 54.63856222177928, 574.765...   \n",
       "3     [595.5333143912487, 52.484301747407294, 584.49...   \n",
       "4     [608.6178598298512, 54.07367324497946, 596.594...   \n",
       "...                                                 ...   \n",
       "5149  [8897.635639854818, 161.3784685634001, 8813.47...   \n",
       "5150  [8910.625345877144, 159.51474424855718, 8821.4...   \n",
       "5151  [8923.702892001807, 159.2881834613647, 8836.41...   \n",
       "5152  [8935.34010033835, 157.95111422237778, 8847.53...   \n",
       "5153  [8940.46656641604, 155.12932330827067, 8861.91...   \n",
       "\n",
       "                                                   y_43  \\\n",
       "0     [571.6816533108394, 56.70940531421341, 561.582...   \n",
       "1     [579.4599029964786, 54.63856222177928, 574.765...   \n",
       "2     [595.5333143912487, 52.484301747407294, 584.49...   \n",
       "3     [608.6178598298512, 54.07367324497946, 596.594...   \n",
       "4     [616.5485332302082, 54.14087619468538, 610.544...   \n",
       "...                                                 ...   \n",
       "5149  [8910.625345877144, 159.51474424855718, 8821.4...   \n",
       "5150  [8923.702892001807, 159.2881834613647, 8836.41...   \n",
       "5151  [8935.34010033835, 157.95111422237778, 8847.53...   \n",
       "5152  [8940.46656641604, 155.12932330827067, 8861.91...   \n",
       "5153  [8954.623459439574, 159.4531853577779, 8867.34...   \n",
       "\n",
       "                                                   y_44  \\\n",
       "0     [579.4599029964786, 54.63856222177928, 574.765...   \n",
       "1     [595.5333143912487, 52.484301747407294, 584.49...   \n",
       "2     [608.6178598298512, 54.07367324497946, 596.594...   \n",
       "3     [616.5485332302082, 54.14087619468538, 610.544...   \n",
       "4     [630.1560680698611, 48.47305567995223, 624.534...   \n",
       "...                                                 ...   \n",
       "5149  [8923.702892001807, 159.2881834613647, 8836.41...   \n",
       "5150  [8935.34010033835, 157.95111422237778, 8847.53...   \n",
       "5151  [8940.46656641604, 155.12932330827067, 8861.91...   \n",
       "5152  [8954.623459439574, 159.4531853577779, 8867.34...   \n",
       "5153  [8963.531319216798, 166.59466643040668, 8880.4...   \n",
       "\n",
       "                                                   y_45  \\\n",
       "0     [595.5333143912487, 52.484301747407294, 584.49...   \n",
       "1     [608.6178598298512, 54.07367324497946, 596.594...   \n",
       "2     [616.5485332302082, 54.14087619468538, 610.544...   \n",
       "3     [630.1560680698611, 48.47305567995223, 624.534...   \n",
       "4     [645.4160783268949, 54.60836552550953, 632.508...   \n",
       "...                                                 ...   \n",
       "5149  [8935.34010033835, 157.95111422237778, 8847.53...   \n",
       "5150  [8940.46656641604, 155.12932330827067, 8861.91...   \n",
       "5151  [8954.623459439574, 159.4531853577779, 8867.34...   \n",
       "5152  [8963.531319216798, 166.59466643040668, 8880.4...   \n",
       "5153  [8971.234802590348, 161.42225471763803, 8889.3...   \n",
       "\n",
       "                                                   y_46  \\\n",
       "0     [608.6178598298512, 54.07367324497946, 596.594...   \n",
       "1     [616.5485332302082, 54.14087619468538, 610.544...   \n",
       "2     [630.1560680698611, 48.47305567995223, 624.534...   \n",
       "3     [645.4160783268949, 54.60836552550953, 632.508...   \n",
       "4     [655.4035507361932, 59.76984000425239, 648.778...   \n",
       "...                                                 ...   \n",
       "5149  [8940.46656641604, 155.12932330827067, 8861.91...   \n",
       "5150  [8954.623459439574, 159.4531853577779, 8867.34...   \n",
       "5151  [8963.531319216798, 166.59466643040668, 8880.4...   \n",
       "5152  [8971.234802590348, 161.42225471763803, 8889.3...   \n",
       "5153  [8981.526291116494, 162.7594343308071, 8905.46...   \n",
       "\n",
       "                                                   y_47  \\\n",
       "0     [616.5485332302082, 54.14087619468538, 610.544...   \n",
       "1     [630.1560680698611, 48.47305567995223, 624.534...   \n",
       "2     [645.4160783268949, 54.60836552550953, 632.508...   \n",
       "3     [655.4035507361932, 59.76984000425239, 648.778...   \n",
       "4     [664.2836707746479, 64.61612382629107, 654.376...   \n",
       "...                                                 ...   \n",
       "5149  [8954.623459439574, 159.4531853577779, 8867.34...   \n",
       "5150  [8963.531319216798, 166.59466643040668, 8880.4...   \n",
       "5151  [8971.234802590348, 161.42225471763803, 8889.3...   \n",
       "5152  [8981.526291116494, 162.7594343308071, 8905.46...   \n",
       "5153  [8990.157367074604, 162.0370600843532, 8920.93...   \n",
       "\n",
       "                                                   y_48  \\\n",
       "0     [630.1560680698611, 48.47305567995223, 624.534...   \n",
       "1     [645.4160783268949, 54.60836552550953, 632.508...   \n",
       "2     [655.4035507361932, 59.76984000425239, 648.778...   \n",
       "3     [664.2836707746479, 64.61612382629107, 654.376...   \n",
       "4     [681.5213026017112, 66.98795180722891, 667.341...   \n",
       "...                                                 ...   \n",
       "5149  [8963.531319216798, 166.59466643040668, 8880.4...   \n",
       "5150  [8971.234802590348, 161.42225471763803, 8889.3...   \n",
       "5151  [8981.526291116494, 162.7594343308071, 8905.46...   \n",
       "5152  [8990.157367074604, 162.0370600843532, 8920.93...   \n",
       "5153  [9007.540353356892, 162.55978798586568, 8926.0...   \n",
       "\n",
       "                                                   y_49  \\\n",
       "0     [645.4160783268949, 54.60836552550953, 632.508...   \n",
       "1     [655.4035507361932, 59.76984000425239, 648.778...   \n",
       "2     [664.2836707746479, 64.61612382629107, 654.376...   \n",
       "3     [681.5213026017112, 66.98795180722891, 667.341...   \n",
       "4     [688.0223759593558, 65.73148848773107, 682.724...   \n",
       "...                                                 ...   \n",
       "5149  [8971.234802590348, 161.42225471763803, 8889.3...   \n",
       "5150  [8981.526291116494, 162.7594343308071, 8905.46...   \n",
       "5151  [8990.157367074604, 162.0370600843532, 8920.93...   \n",
       "5152  [9007.540353356892, 162.55978798586568, 8926.0...   \n",
       "5153  [9017.586395147311, 165.976863084922, 8941.781...   \n",
       "\n",
       "                                                   y_50  \n",
       "0     [655.4035507361932, 59.76984000425239, 648.778...  \n",
       "1     [664.2836707746479, 64.61612382629107, 654.376...  \n",
       "2     [681.5213026017112, 66.98795180722891, 667.341...  \n",
       "3     [688.0223759593558, 65.73148848773107, 682.724...  \n",
       "4     [700.2392071106094, 66.80523419864559, 692.610...  \n",
       "...                                                 ...  \n",
       "5149  [8981.526291116494, 162.7594343308071, 8905.46...  \n",
       "5150  [8990.157367074604, 162.0370600843532, 8920.93...  \n",
       "5151  [9007.540353356892, 162.55978798586568, 8926.0...  \n",
       "5152  [9017.586395147311, 165.976863084922, 8941.781...  \n",
       "5153  [9030.630412102242, 161.97515649452268, 8950.1...  \n",
       "\n",
       "[5154 rows x 51 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 50\n",
    "\n",
    "# data in columns format (frame, next frame, next next frame, ...)\n",
    "df_n_rounds = pd.DataFrame(columns=['X', 'y_1'])\n",
    "\n",
    "for i in range(1, n):\n",
    "    df_n_rounds['y_' + str(i+1)] = ''\n",
    "\n",
    "for i in range(n+1):\n",
    "    col = []\n",
    "    for j in range(i, len(frames)-n+i):\n",
    "        col.append(frames[j])\n",
    "    if i == 0:\n",
    "        df_n_rounds['X'] = col\n",
    "    else:\n",
    "        df_n_rounds['y_' + str(i)] = col\n",
    "\n",
    "df_n_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_n_rounds['X'].tolist()\n",
    "y = df_n_rounds['y_1'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4123, 30)\n",
      "y_train shape: (4123, 30)\n",
      "X_test shape: (1031, 30)\n",
      "y_test shape: (1031, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"y_train shape: \" + str(y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "\n",
    "optimizer = 'NAdam'\n",
    "loss = 'mae'\n",
    "metrics = ['accuracy']\n",
    "training_epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "n_input = 2 * no_skyrmions\n",
    "n_hidden_1 = 512\n",
    "n_hidden_2 = 256\n",
    "n_hidden_3 = 128\n",
    "n_output = 2 * no_skyrmions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_1, input_dim=n_input, activation=activation))\n",
    "model.add(Dense(n_hidden_2, activation=activation))\n",
    "model.add(Dense(n_hidden_3, activation=activation))\n",
    "model.add(Dense(n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4123 samples, validate on 1031 samples\n",
      "Epoch 1/2000\n",
      "4123/4123 [==============================] - 0s 56us/step - loss: 678.2435 - accuracy: 0.1227 - val_loss: 302.0640 - val_accuracy: 0.3492\n",
      "Epoch 2/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 310.8763 - accuracy: 0.1072 - val_loss: 108.1657 - val_accuracy: 0.3492\n",
      "Epoch 3/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 266.5346 - accuracy: 0.2033 - val_loss: 204.2677 - val_accuracy: 0.3463\n",
      "Epoch 4/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 250.9102 - accuracy: 0.1484 - val_loss: 424.5764 - val_accuracy: 0.3346\n",
      "Epoch 5/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 237.6068 - accuracy: 0.2008 - val_loss: 279.0913 - val_accuracy: 0.0436\n",
      "Epoch 6/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 226.5152 - accuracy: 0.1722 - val_loss: 159.8997 - val_accuracy: 0.3511\n",
      "Epoch 7/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 220.8703 - accuracy: 0.1821 - val_loss: 320.5973 - val_accuracy: 0.0175\n",
      "Epoch 8/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 218.7871 - accuracy: 0.1266 - val_loss: 146.5163 - val_accuracy: 0.0359\n",
      "Epoch 9/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 209.6514 - accuracy: 0.2644 - val_loss: 278.2391 - val_accuracy: 0.3802\n",
      "Epoch 10/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 192.7089 - accuracy: 0.1846 - val_loss: 279.0373 - val_accuracy: 0.2338\n",
      "Epoch 11/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 190.9957 - accuracy: 0.2246 - val_loss: 80.6821 - val_accuracy: 0.5189\n",
      "Epoch 12/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 185.5679 - accuracy: 0.3189 - val_loss: 94.3670 - val_accuracy: 0.0233\n",
      "Epoch 13/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 180.9027 - accuracy: 0.2100 - val_loss: 193.1106 - val_accuracy: 0.0495\n",
      "Epoch 14/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 176.0376 - accuracy: 0.2030 - val_loss: 159.9241 - val_accuracy: 0.0446\n",
      "Epoch 15/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 171.3133 - accuracy: 0.2515 - val_loss: 223.3505 - val_accuracy: 0.3695\n",
      "Epoch 16/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 156.0202 - accuracy: 0.3512 - val_loss: 241.3294 - val_accuracy: 0.2502\n",
      "Epoch 17/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 160.2129 - accuracy: 0.2632 - val_loss: 42.7723 - val_accuracy: 0.3899\n",
      "Epoch 18/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 156.6577 - accuracy: 0.2619 - val_loss: 91.1664 - val_accuracy: 0.1911\n",
      "Epoch 19/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 147.7309 - accuracy: 0.3633 - val_loss: 152.6768 - val_accuracy: 0.5616\n",
      "Epoch 20/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 151.2766 - accuracy: 0.2726 - val_loss: 46.6631 - val_accuracy: 0.3695\n",
      "Epoch 21/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 128.3504 - accuracy: 0.3466 - val_loss: 222.7109 - val_accuracy: 0.3492\n",
      "Epoch 22/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 140.7717 - accuracy: 0.2539 - val_loss: 72.5291 - val_accuracy: 0.2978\n",
      "Epoch 23/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 140.7533 - accuracy: 0.4014 - val_loss: 87.8934 - val_accuracy: 0.4268\n",
      "Epoch 24/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 134.6104 - accuracy: 0.4380 - val_loss: 182.4634 - val_accuracy: 0.3143\n",
      "Epoch 25/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 132.5893 - accuracy: 0.2920 - val_loss: 113.4000 - val_accuracy: 0.2774\n",
      "Epoch 26/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 131.1867 - accuracy: 0.3454 - val_loss: 108.8520 - val_accuracy: 0.4258\n",
      "Epoch 27/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 134.0830 - accuracy: 0.3992 - val_loss: 171.7774 - val_accuracy: 0.0475\n",
      "Epoch 28/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 132.8155 - accuracy: 0.3832 - val_loss: 88.2489 - val_accuracy: 0.4403\n",
      "Epoch 29/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 127.2846 - accuracy: 0.3633 - val_loss: 220.1443 - val_accuracy: 0.2066\n",
      "Epoch 30/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 121.7270 - accuracy: 0.3505 - val_loss: 72.8372 - val_accuracy: 0.2890\n",
      "Epoch 31/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 125.7065 - accuracy: 0.4938 - val_loss: 99.3549 - val_accuracy: 0.5150\n",
      "Epoch 32/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 119.8439 - accuracy: 0.3776 - val_loss: 93.9403 - val_accuracy: 0.2687\n",
      "Epoch 33/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 118.7981 - accuracy: 0.3447 - val_loss: 234.7851 - val_accuracy: 0.4656\n",
      "Epoch 34/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 120.7566 - accuracy: 0.5011 - val_loss: 41.1649 - val_accuracy: 0.1503\n",
      "Epoch 35/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 112.9195 - accuracy: 0.4441 - val_loss: 172.7024 - val_accuracy: 0.5965\n",
      "Epoch 36/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 112.8036 - accuracy: 0.5612 - val_loss: 168.6866 - val_accuracy: 0.4316\n",
      "Epoch 37/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 111.2185 - accuracy: 0.5642 - val_loss: 37.9732 - val_accuracy: 0.6033\n",
      "Epoch 38/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 108.6703 - accuracy: 0.5253 - val_loss: 122.5793 - val_accuracy: 0.3676\n",
      "Epoch 39/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 107.7747 - accuracy: 0.4084 - val_loss: 148.2170 - val_accuracy: 0.1222\n",
      "Epoch 40/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 114.1454 - accuracy: 0.4807 - val_loss: 36.4063 - val_accuracy: 0.5170\n",
      "Epoch 41/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 103.2168 - accuracy: 0.4759 - val_loss: 152.2323 - val_accuracy: 0.6043\n",
      "Epoch 42/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 106.4711 - accuracy: 0.3978 - val_loss: 98.4111 - val_accuracy: 0.6052\n",
      "Epoch 43/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 102.6927 - accuracy: 0.4921 - val_loss: 162.9711 - val_accuracy: 0.3453\n",
      "Epoch 44/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 102.8015 - accuracy: 0.4919 - val_loss: 39.4282 - val_accuracy: 0.6372\n",
      "Epoch 45/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 102.4459 - accuracy: 0.5110 - val_loss: 124.5720 - val_accuracy: 0.3792\n",
      "Epoch 46/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 100.3563 - accuracy: 0.5103 - val_loss: 151.0287 - val_accuracy: 0.5121\n",
      "Epoch 47/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 103.9010 - accuracy: 0.6139 - val_loss: 86.5559 - val_accuracy: 0.6411\n",
      "Epoch 48/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 98.4931 - accuracy: 0.5564 - val_loss: 113.5158 - val_accuracy: 0.5500\n",
      "Epoch 49/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 98.0172 - accuracy: 0.6119 - val_loss: 96.7317 - val_accuracy: 0.5820\n",
      "Epoch 50/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 95.5419 - accuracy: 0.6233 - val_loss: 41.0524 - val_accuracy: 0.5752\n",
      "Epoch 51/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 93.2498 - accuracy: 0.5707 - val_loss: 38.4472 - val_accuracy: 0.6654\n",
      "Epoch 52/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 91.9272 - accuracy: 0.5438 - val_loss: 71.9880 - val_accuracy: 0.6208\n",
      "Epoch 53/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 92.5027 - accuracy: 0.4625 - val_loss: 101.7765 - val_accuracy: 0.4064\n",
      "Epoch 54/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 89.2450 - accuracy: 0.4965 - val_loss: 134.6884 - val_accuracy: 0.4161\n",
      "Epoch 55/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 93.3495 - accuracy: 0.4962 - val_loss: 75.2443 - val_accuracy: 0.3288\n",
      "Epoch 56/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 89.7218 - accuracy: 0.5195 - val_loss: 137.3795 - val_accuracy: 0.5771\n",
      "Epoch 57/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 86.8105 - accuracy: 0.6134 - val_loss: 78.6233 - val_accuracy: 0.5500\n",
      "Epoch 58/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 89.6465 - accuracy: 0.6114 - val_loss: 102.4630 - val_accuracy: 0.6217\n",
      "Epoch 59/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 88.9434 - accuracy: 0.6238 - val_loss: 82.4755 - val_accuracy: 0.5839\n",
      "Epoch 60/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 90.1547 - accuracy: 0.6563 - val_loss: 124.3676 - val_accuracy: 0.6838\n",
      "Epoch 61/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 84.0600 - accuracy: 0.6039 - val_loss: 93.7337 - val_accuracy: 0.4403\n",
      "Epoch 62/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 87.1409 - accuracy: 0.5455 - val_loss: 99.9633 - val_accuracy: 0.5984\n",
      "Epoch 63/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 83.6317 - accuracy: 0.6258 - val_loss: 40.3829 - val_accuracy: 0.6266\n",
      "Epoch 64/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 85.2489 - accuracy: 0.5530 - val_loss: 130.1662 - val_accuracy: 0.5364\n",
      "Epoch 65/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 85.1203 - accuracy: 0.5535 - val_loss: 37.9226 - val_accuracy: 0.5587\n",
      "Epoch 66/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 78.5801 - accuracy: 0.5620 - val_loss: 110.8968 - val_accuracy: 0.7313\n",
      "Epoch 67/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 82.2065 - accuracy: 0.5532 - val_loss: 55.4400 - val_accuracy: 0.4985\n",
      "Epoch 68/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 80.6362 - accuracy: 0.5758 - val_loss: 98.4895 - val_accuracy: 0.5820\n",
      "Epoch 69/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 79.5760 - accuracy: 0.5821 - val_loss: 50.9779 - val_accuracy: 0.5461\n",
      "Epoch 70/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 81.0221 - accuracy: 0.6027 - val_loss: 101.3412 - val_accuracy: 0.6431\n",
      "Epoch 71/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 77.7677 - accuracy: 0.6318 - val_loss: 75.8984 - val_accuracy: 0.5480\n",
      "Epoch 72/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 76.4118 - accuracy: 0.5617 - val_loss: 106.3645 - val_accuracy: 0.5422\n",
      "Epoch 73/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 77.5199 - accuracy: 0.6105 - val_loss: 35.9562 - val_accuracy: 0.5538\n",
      "Epoch 74/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 77.6186 - accuracy: 0.5612 - val_loss: 123.9154 - val_accuracy: 0.5800\n",
      "Epoch 75/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 76.5735 - accuracy: 0.5976 - val_loss: 48.8211 - val_accuracy: 0.5112\n",
      "Epoch 76/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 74.9656 - accuracy: 0.5789 - val_loss: 51.4077 - val_accuracy: 0.5946\n",
      "Epoch 77/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 76.0100 - accuracy: 0.5578 - val_loss: 129.3443 - val_accuracy: 0.5887\n",
      "Epoch 78/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 71.7791 - accuracy: 0.5937 - val_loss: 30.4327 - val_accuracy: 0.6479\n",
      "Epoch 79/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 70.3949 - accuracy: 0.5928 - val_loss: 74.5737 - val_accuracy: 0.6343\n",
      "Epoch 80/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 72.3944 - accuracy: 0.5321 - val_loss: 107.4242 - val_accuracy: 0.5257\n",
      "Epoch 81/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 74.7430 - accuracy: 0.5758 - val_loss: 85.4169 - val_accuracy: 0.6072\n",
      "Epoch 82/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 73.2031 - accuracy: 0.6335 - val_loss: 39.8426 - val_accuracy: 0.5412\n",
      "Epoch 83/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 71.2621 - accuracy: 0.5886 - val_loss: 86.3325 - val_accuracy: 0.6120\n",
      "Epoch 84/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 72.5912 - accuracy: 0.5343 - val_loss: 32.4001 - val_accuracy: 0.4694\n",
      "Epoch 85/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 71.1752 - accuracy: 0.5108 - val_loss: 113.1911 - val_accuracy: 0.5635\n",
      "Epoch 86/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 70.4483 - accuracy: 0.6197 - val_loss: 45.9443 - val_accuracy: 0.6062\n",
      "Epoch 87/2000\n",
      "4123/4123 [==============================] - 0s 28us/step - loss: 68.8037 - accuracy: 0.6136 - val_loss: 82.0912 - val_accuracy: 0.6605\n",
      "Epoch 88/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 66.9381 - accuracy: 0.5838 - val_loss: 44.5312 - val_accuracy: 0.5296\n",
      "Epoch 89/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 70.7591 - accuracy: 0.5484 - val_loss: 83.5974 - val_accuracy: 0.6857\n",
      "Epoch 90/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 68.5874 - accuracy: 0.5401 - val_loss: 65.2302 - val_accuracy: 0.4753\n",
      "Epoch 91/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 68.1734 - accuracy: 0.5474 - val_loss: 75.4372 - val_accuracy: 0.3967\n",
      "Epoch 92/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 68.6973 - accuracy: 0.5227 - val_loss: 78.0799 - val_accuracy: 0.5480\n",
      "Epoch 93/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 69.2525 - accuracy: 0.5547 - val_loss: 90.5794 - val_accuracy: 0.5529\n",
      "Epoch 94/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 67.1607 - accuracy: 0.5874 - val_loss: 56.7314 - val_accuracy: 0.6499\n",
      "Epoch 95/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 67.2863 - accuracy: 0.6277 - val_loss: 103.3913 - val_accuracy: 0.6266\n",
      "Epoch 96/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 64.9398 - accuracy: 0.6270 - val_loss: 83.1369 - val_accuracy: 0.4772\n",
      "Epoch 97/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 66.1289 - accuracy: 0.5739 - val_loss: 66.1852 - val_accuracy: 0.6033\n",
      "Epoch 98/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 72.0288 - accuracy: 0.5622 - val_loss: 73.0476 - val_accuracy: 0.6072\n",
      "Epoch 99/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 65.0734 - accuracy: 0.5962 - val_loss: 25.9281 - val_accuracy: 0.5538\n",
      "Epoch 100/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 62.8022 - accuracy: 0.5833 - val_loss: 52.9689 - val_accuracy: 0.6353\n",
      "Epoch 101/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 61.5765 - accuracy: 0.6000 - val_loss: 69.4056 - val_accuracy: 0.5509\n",
      "Epoch 102/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 63.4509 - accuracy: 0.6003 - val_loss: 66.3553 - val_accuracy: 0.5820\n",
      "Epoch 103/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 62.1382 - accuracy: 0.5564 - val_loss: 100.2925 - val_accuracy: 0.4762\n",
      "Epoch 104/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 63.5103 - accuracy: 0.5358 - val_loss: 27.6294 - val_accuracy: 0.6324\n",
      "Epoch 105/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 59.8582 - accuracy: 0.5843 - val_loss: 65.8781 - val_accuracy: 0.6014\n",
      "Epoch 106/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 62.8526 - accuracy: 0.5751 - val_loss: 91.2217 - val_accuracy: 0.5907\n",
      "Epoch 107/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 61.8428 - accuracy: 0.5780 - val_loss: 83.2518 - val_accuracy: 0.5257\n",
      "Epoch 108/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 61.9091 - accuracy: 0.5110 - val_loss: 92.9435 - val_accuracy: 0.5276\n",
      "Epoch 109/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 61.8088 - accuracy: 0.4992 - val_loss: 41.5539 - val_accuracy: 0.3531\n",
      "Epoch 110/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 59.8642 - accuracy: 0.5479 - val_loss: 83.5610 - val_accuracy: 0.5917\n",
      "Epoch 111/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 61.1679 - accuracy: 0.5724 - val_loss: 66.3803 - val_accuracy: 0.5548\n",
      "Epoch 112/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 60.9706 - accuracy: 0.5144 - val_loss: 112.1940 - val_accuracy: 0.5393\n",
      "Epoch 113/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 57.6401 - accuracy: 0.6129 - val_loss: 62.6377 - val_accuracy: 0.5878\n",
      "Epoch 114/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 59.6341 - accuracy: 0.5472 - val_loss: 31.4194 - val_accuracy: 0.5257\n",
      "Epoch 115/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 58.5221 - accuracy: 0.5394 - val_loss: 88.5538 - val_accuracy: 0.5868\n",
      "Epoch 116/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 59.2838 - accuracy: 0.5741 - val_loss: 65.3312 - val_accuracy: 0.5674\n",
      "Epoch 117/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 58.7365 - accuracy: 0.5756 - val_loss: 74.4630 - val_accuracy: 0.5422\n",
      "Epoch 118/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 56.9198 - accuracy: 0.5603 - val_loss: 37.6420 - val_accuracy: 0.5597\n",
      "Epoch 119/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 55.8347 - accuracy: 0.5889 - val_loss: 68.1918 - val_accuracy: 0.5674\n",
      "Epoch 120/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 56.3418 - accuracy: 0.5916 - val_loss: 24.0776 - val_accuracy: 0.5228\n",
      "Epoch 121/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 56.4474 - accuracy: 0.5712 - val_loss: 41.5658 - val_accuracy: 0.5839\n",
      "Epoch 122/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 56.8745 - accuracy: 0.5692 - val_loss: 34.7986 - val_accuracy: 0.5781\n",
      "Epoch 123/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 55.6881 - accuracy: 0.5809 - val_loss: 59.4897 - val_accuracy: 0.5936\n",
      "Epoch 124/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 56.6471 - accuracy: 0.5826 - val_loss: 44.0447 - val_accuracy: 0.6596\n",
      "Epoch 125/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 55.6712 - accuracy: 0.5739 - val_loss: 41.8796 - val_accuracy: 0.5383\n",
      "Epoch 126/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 56.5029 - accuracy: 0.5811 - val_loss: 36.2933 - val_accuracy: 0.5441\n",
      "Epoch 127/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 53.4320 - accuracy: 0.5726 - val_loss: 86.8571 - val_accuracy: 0.6324\n",
      "Epoch 128/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 54.8027 - accuracy: 0.5489 - val_loss: 81.5970 - val_accuracy: 0.5839\n",
      "Epoch 129/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 56.2669 - accuracy: 0.5709 - val_loss: 60.2626 - val_accuracy: 0.5306\n",
      "Epoch 130/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 54.9964 - accuracy: 0.5617 - val_loss: 33.2060 - val_accuracy: 0.5868\n",
      "Epoch 131/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 54.3893 - accuracy: 0.5661 - val_loss: 52.2503 - val_accuracy: 0.5674\n",
      "Epoch 132/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 54.0134 - accuracy: 0.5799 - val_loss: 62.3273 - val_accuracy: 0.5713\n",
      "Epoch 133/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 53.5097 - accuracy: 0.5583 - val_loss: 54.8126 - val_accuracy: 0.5490\n",
      "Epoch 134/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 52.3280 - accuracy: 0.5794 - val_loss: 43.0730 - val_accuracy: 0.3909\n",
      "Epoch 135/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 52.5465 - accuracy: 0.5712 - val_loss: 83.0477 - val_accuracy: 0.6043\n",
      "Epoch 136/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 51.0382 - accuracy: 0.5489 - val_loss: 80.1681 - val_accuracy: 0.5441\n",
      "Epoch 137/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 53.1269 - accuracy: 0.5520 - val_loss: 65.8208 - val_accuracy: 0.5849\n",
      "Epoch 138/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 53.5940 - accuracy: 0.5811 - val_loss: 59.0898 - val_accuracy: 0.5703\n",
      "Epoch 139/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 52.5008 - accuracy: 0.5806 - val_loss: 74.9793 - val_accuracy: 0.6062\n",
      "Epoch 140/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 52.4775 - accuracy: 0.5729 - val_loss: 89.1435 - val_accuracy: 0.5500\n",
      "Epoch 141/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 52.0989 - accuracy: 0.5481 - val_loss: 61.9221 - val_accuracy: 0.5422\n",
      "Epoch 142/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 51.1925 - accuracy: 0.5639 - val_loss: 44.0671 - val_accuracy: 0.5073\n",
      "Epoch 143/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 52.1014 - accuracy: 0.5804 - val_loss: 57.1711 - val_accuracy: 0.6741\n",
      "Epoch 144/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 49.6989 - accuracy: 0.6000 - val_loss: 55.6431 - val_accuracy: 0.5529\n",
      "Epoch 145/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 50.1321 - accuracy: 0.5625 - val_loss: 66.3645 - val_accuracy: 0.5946\n",
      "Epoch 146/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 48.1797 - accuracy: 0.5433 - val_loss: 35.8831 - val_accuracy: 0.4520\n",
      "Epoch 147/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 48.6871 - accuracy: 0.5246 - val_loss: 67.1508 - val_accuracy: 0.5461\n",
      "Epoch 148/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 49.6406 - accuracy: 0.5363 - val_loss: 73.8056 - val_accuracy: 0.5238\n",
      "Epoch 149/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 50.5690 - accuracy: 0.5266 - val_loss: 65.6207 - val_accuracy: 0.4947\n",
      "Epoch 150/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 49.6664 - accuracy: 0.4958 - val_loss: 51.1599 - val_accuracy: 0.5053\n",
      "Epoch 151/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 50.2974 - accuracy: 0.4979 - val_loss: 51.5815 - val_accuracy: 0.4840\n",
      "Epoch 152/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 48.9208 - accuracy: 0.4926 - val_loss: 69.0441 - val_accuracy: 0.5354\n",
      "Epoch 153/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 48.7380 - accuracy: 0.5355 - val_loss: 37.6348 - val_accuracy: 0.7119\n",
      "Epoch 154/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 48.9902 - accuracy: 0.5069 - val_loss: 34.4005 - val_accuracy: 0.6178\n",
      "Epoch 155/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 47.1687 - accuracy: 0.5896 - val_loss: 62.0677 - val_accuracy: 0.5752\n",
      "Epoch 156/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 48.9752 - accuracy: 0.5787 - val_loss: 47.6273 - val_accuracy: 0.5606\n",
      "Epoch 157/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 47.7225 - accuracy: 0.5642 - val_loss: 62.8879 - val_accuracy: 0.5189\n",
      "Epoch 158/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 48.9147 - accuracy: 0.5814 - val_loss: 80.8910 - val_accuracy: 0.4918\n",
      "Epoch 159/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 47.7196 - accuracy: 0.6061 - val_loss: 53.3958 - val_accuracy: 0.5917\n",
      "Epoch 160/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 47.7889 - accuracy: 0.5937 - val_loss: 22.9562 - val_accuracy: 0.5577\n",
      "Epoch 161/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 46.2714 - accuracy: 0.5739 - val_loss: 61.8223 - val_accuracy: 0.5975\n",
      "Epoch 162/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 47.7047 - accuracy: 0.5564 - val_loss: 59.8327 - val_accuracy: 0.5742\n",
      "Epoch 163/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 45.2091 - accuracy: 0.5615 - val_loss: 52.4990 - val_accuracy: 0.6043\n",
      "Epoch 164/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 46.2337 - accuracy: 0.4996 - val_loss: 55.0813 - val_accuracy: 0.4704\n",
      "Epoch 165/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 45.5831 - accuracy: 0.5806 - val_loss: 73.2279 - val_accuracy: 0.4869\n",
      "Epoch 166/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 47.1700 - accuracy: 0.5234 - val_loss: 59.3941 - val_accuracy: 0.5878\n",
      "Epoch 167/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 46.6341 - accuracy: 0.5603 - val_loss: 71.0572 - val_accuracy: 0.5926\n",
      "Epoch 168/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 46.3398 - accuracy: 0.5137 - val_loss: 28.5376 - val_accuracy: 0.5752\n",
      "Epoch 169/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 44.9706 - accuracy: 0.5523 - val_loss: 47.2400 - val_accuracy: 0.4908\n",
      "Epoch 170/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 43.6176 - accuracy: 0.5777 - val_loss: 28.5932 - val_accuracy: 0.5732\n",
      "Epoch 171/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 45.3867 - accuracy: 0.5411 - val_loss: 62.3499 - val_accuracy: 0.4656\n",
      "Epoch 172/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 44.9825 - accuracy: 0.5406 - val_loss: 50.5514 - val_accuracy: 0.5984\n",
      "Epoch 173/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 44.3368 - accuracy: 0.5377 - val_loss: 61.9926 - val_accuracy: 0.5170\n",
      "Epoch 174/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 44.0952 - accuracy: 0.5464 - val_loss: 30.0209 - val_accuracy: 0.4782\n",
      "Epoch 175/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 43.8038 - accuracy: 0.5210 - val_loss: 63.3498 - val_accuracy: 0.5761\n",
      "Epoch 176/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 42.6477 - accuracy: 0.5292 - val_loss: 23.3144 - val_accuracy: 0.5917\n",
      "Epoch 177/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 43.8556 - accuracy: 0.5304 - val_loss: 35.8944 - val_accuracy: 0.4549\n",
      "Epoch 178/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 43.6807 - accuracy: 0.5110 - val_loss: 37.2592 - val_accuracy: 0.4908\n",
      "Epoch 179/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 43.7144 - accuracy: 0.4907 - val_loss: 23.9939 - val_accuracy: 0.5761\n",
      "Epoch 180/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 44.0482 - accuracy: 0.5865 - val_loss: 43.1730 - val_accuracy: 0.6101\n",
      "Epoch 181/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 43.9730 - accuracy: 0.5739 - val_loss: 61.5910 - val_accuracy: 0.5858\n",
      "Epoch 182/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 43.5761 - accuracy: 0.5033 - val_loss: 41.4543 - val_accuracy: 0.5412\n",
      "Epoch 183/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 43.7935 - accuracy: 0.5756 - val_loss: 59.3542 - val_accuracy: 0.6353\n",
      "Epoch 184/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 43.3857 - accuracy: 0.5348 - val_loss: 38.5653 - val_accuracy: 0.4491\n",
      "Epoch 185/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 43.3190 - accuracy: 0.5528 - val_loss: 50.0841 - val_accuracy: 0.6586\n",
      "Epoch 186/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 41.7614 - accuracy: 0.5840 - val_loss: 29.4290 - val_accuracy: 0.4898\n",
      "Epoch 187/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 42.3081 - accuracy: 0.5084 - val_loss: 58.7012 - val_accuracy: 0.5936\n",
      "Epoch 188/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 40.8526 - accuracy: 0.5249 - val_loss: 68.1180 - val_accuracy: 0.6402\n",
      "Epoch 189/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 40.4619 - accuracy: 0.5697 - val_loss: 43.8657 - val_accuracy: 0.5955\n",
      "Epoch 190/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 42.1173 - accuracy: 0.6093 - val_loss: 62.9704 - val_accuracy: 0.5315\n",
      "Epoch 191/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 42.6426 - accuracy: 0.5496 - val_loss: 21.9018 - val_accuracy: 0.6537\n",
      "Epoch 192/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 41.4315 - accuracy: 0.5416 - val_loss: 44.2072 - val_accuracy: 0.5005\n",
      "Epoch 193/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 42.3592 - accuracy: 0.5394 - val_loss: 54.2815 - val_accuracy: 0.6256\n",
      "Epoch 194/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 42.4408 - accuracy: 0.5574 - val_loss: 49.2729 - val_accuracy: 0.4985\n",
      "Epoch 195/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 41.8246 - accuracy: 0.5321 - val_loss: 39.8808 - val_accuracy: 0.4840\n",
      "Epoch 196/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 40.8888 - accuracy: 0.5542 - val_loss: 45.9887 - val_accuracy: 0.6033\n",
      "Epoch 197/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 41.2616 - accuracy: 0.5627 - val_loss: 25.1030 - val_accuracy: 0.5839\n",
      "Epoch 198/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 39.8964 - accuracy: 0.5552 - val_loss: 49.7010 - val_accuracy: 0.5887\n",
      "Epoch 199/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 40.7095 - accuracy: 0.5891 - val_loss: 42.3750 - val_accuracy: 0.5364\n",
      "Epoch 200/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 40.7587 - accuracy: 0.5654 - val_loss: 33.7153 - val_accuracy: 0.6402\n",
      "Epoch 201/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 40.0900 - accuracy: 0.5215 - val_loss: 48.9162 - val_accuracy: 0.5558\n",
      "Epoch 202/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 40.5095 - accuracy: 0.5414 - val_loss: 51.6478 - val_accuracy: 0.6314\n",
      "Epoch 203/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 40.1397 - accuracy: 0.6008 - val_loss: 32.2297 - val_accuracy: 0.5490\n",
      "Epoch 204/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 40.4206 - accuracy: 0.5731 - val_loss: 47.3895 - val_accuracy: 0.5451\n",
      "Epoch 205/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 39.5589 - accuracy: 0.5661 - val_loss: 37.7248 - val_accuracy: 0.5994\n",
      "Epoch 206/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 39.2807 - accuracy: 0.5409 - val_loss: 59.7619 - val_accuracy: 0.5102\n",
      "Epoch 207/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 39.7379 - accuracy: 0.4727 - val_loss: 44.3235 - val_accuracy: 0.4743\n",
      "Epoch 208/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 39.3404 - accuracy: 0.5947 - val_loss: 33.7067 - val_accuracy: 0.4423\n",
      "Epoch 209/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 40.0046 - accuracy: 0.5816 - val_loss: 41.4165 - val_accuracy: 0.6062\n",
      "Epoch 210/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 39.9822 - accuracy: 0.5729 - val_loss: 58.3200 - val_accuracy: 0.6305\n",
      "Epoch 211/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 39.5880 - accuracy: 0.6231 - val_loss: 43.6299 - val_accuracy: 0.6052\n",
      "Epoch 212/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 39.1095 - accuracy: 0.5879 - val_loss: 24.8940 - val_accuracy: 0.6178\n",
      "Epoch 213/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 39.2013 - accuracy: 0.5200 - val_loss: 40.3974 - val_accuracy: 0.5373\n",
      "Epoch 214/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 38.7610 - accuracy: 0.5867 - val_loss: 42.0628 - val_accuracy: 0.6217\n",
      "Epoch 215/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 39.2350 - accuracy: 0.6131 - val_loss: 59.9131 - val_accuracy: 0.6140\n",
      "Epoch 216/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 37.7889 - accuracy: 0.5496 - val_loss: 36.1680 - val_accuracy: 0.5858\n",
      "Epoch 217/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 38.1914 - accuracy: 0.5673 - val_loss: 57.4010 - val_accuracy: 0.6159\n",
      "Epoch 218/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 38.8939 - accuracy: 0.5644 - val_loss: 60.0756 - val_accuracy: 0.6334\n",
      "Epoch 219/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 39.1511 - accuracy: 0.6107 - val_loss: 59.7861 - val_accuracy: 0.6324\n",
      "Epoch 220/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 39.0690 - accuracy: 0.5651 - val_loss: 68.4072 - val_accuracy: 0.6188\n",
      "Epoch 221/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 37.8832 - accuracy: 0.5387 - val_loss: 50.1648 - val_accuracy: 0.6091\n",
      "Epoch 222/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 36.7442 - accuracy: 0.5418 - val_loss: 25.0301 - val_accuracy: 0.4985\n",
      "Epoch 223/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 36.4746 - accuracy: 0.5821 - val_loss: 44.8581 - val_accuracy: 0.6421\n",
      "Epoch 224/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 38.7169 - accuracy: 0.5426 - val_loss: 47.4864 - val_accuracy: 0.5160\n",
      "Epoch 225/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 38.0374 - accuracy: 0.5200 - val_loss: 29.7542 - val_accuracy: 0.4762\n",
      "Epoch 226/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 36.8564 - accuracy: 0.5838 - val_loss: 47.5381 - val_accuracy: 0.6421\n",
      "Epoch 227/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 37.8152 - accuracy: 0.6122 - val_loss: 58.7475 - val_accuracy: 0.6033\n",
      "Epoch 228/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 37.3811 - accuracy: 0.5460 - val_loss: 45.5447 - val_accuracy: 0.5500\n",
      "Epoch 229/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 37.1496 - accuracy: 0.5132 - val_loss: 56.4384 - val_accuracy: 0.6014\n",
      "Epoch 230/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 37.1857 - accuracy: 0.5663 - val_loss: 33.2623 - val_accuracy: 0.5839\n",
      "Epoch 231/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 36.5011 - accuracy: 0.5702 - val_loss: 56.4814 - val_accuracy: 0.5878\n",
      "Epoch 232/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.4801 - accuracy: 0.5535 - val_loss: 46.4379 - val_accuracy: 0.6237\n",
      "Epoch 233/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 36.9171 - accuracy: 0.5996 - val_loss: 31.4789 - val_accuracy: 0.5567\n",
      "Epoch 234/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.3708 - accuracy: 0.5697 - val_loss: 46.8382 - val_accuracy: 0.6508\n",
      "Epoch 235/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 36.9118 - accuracy: 0.5683 - val_loss: 52.4512 - val_accuracy: 0.5713\n",
      "Epoch 236/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 36.5565 - accuracy: 0.5712 - val_loss: 22.2767 - val_accuracy: 0.6169\n",
      "Epoch 237/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.8534 - accuracy: 0.5896 - val_loss: 32.6272 - val_accuracy: 0.6178\n",
      "Epoch 238/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 36.1726 - accuracy: 0.5874 - val_loss: 42.7962 - val_accuracy: 0.4753\n",
      "Epoch 239/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.6631 - accuracy: 0.5399 - val_loss: 39.5886 - val_accuracy: 0.5732\n",
      "Epoch 240/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.6746 - accuracy: 0.6081 - val_loss: 64.4927 - val_accuracy: 0.6547\n",
      "Epoch 241/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 37.0837 - accuracy: 0.5777 - val_loss: 30.9139 - val_accuracy: 0.6305\n",
      "Epoch 242/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.7745 - accuracy: 0.5649 - val_loss: 21.6752 - val_accuracy: 0.6149\n",
      "Epoch 243/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.4579 - accuracy: 0.5501 - val_loss: 61.3503 - val_accuracy: 0.5286\n",
      "Epoch 244/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.6614 - accuracy: 0.5908 - val_loss: 36.8306 - val_accuracy: 0.6382\n",
      "Epoch 245/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.2384 - accuracy: 0.5588 - val_loss: 45.2246 - val_accuracy: 0.4908\n",
      "Epoch 246/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.0943 - accuracy: 0.5578 - val_loss: 30.3744 - val_accuracy: 0.5306\n",
      "Epoch 247/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.8526 - accuracy: 0.5426 - val_loss: 38.5983 - val_accuracy: 0.5771\n",
      "Epoch 248/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 34.7437 - accuracy: 0.5853 - val_loss: 37.1836 - val_accuracy: 0.4714\n",
      "Epoch 249/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.3324 - accuracy: 0.5380 - val_loss: 59.3271 - val_accuracy: 0.5044\n",
      "Epoch 250/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 35.3144 - accuracy: 0.6117 - val_loss: 23.8713 - val_accuracy: 0.6237\n",
      "Epoch 251/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 34.1184 - accuracy: 0.5981 - val_loss: 46.3578 - val_accuracy: 0.5364\n",
      "Epoch 252/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.7873 - accuracy: 0.5229 - val_loss: 20.8272 - val_accuracy: 0.5955\n",
      "Epoch 253/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 33.3978 - accuracy: 0.5903 - val_loss: 47.8422 - val_accuracy: 0.5868\n",
      "Epoch 254/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.8217 - accuracy: 0.6000 - val_loss: 42.8173 - val_accuracy: 0.6489\n",
      "Epoch 255/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.2860 - accuracy: 0.5867 - val_loss: 37.0544 - val_accuracy: 0.5781\n",
      "Epoch 256/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.8748 - accuracy: 0.5513 - val_loss: 31.3088 - val_accuracy: 0.5975\n",
      "Epoch 257/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 33.3329 - accuracy: 0.5848 - val_loss: 31.6481 - val_accuracy: 0.5383\n",
      "Epoch 258/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 33.3105 - accuracy: 0.5741 - val_loss: 40.9978 - val_accuracy: 0.5839\n",
      "Epoch 259/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.7677 - accuracy: 0.5637 - val_loss: 58.2707 - val_accuracy: 0.5344\n",
      "Epoch 260/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 33.9800 - accuracy: 0.5515 - val_loss: 35.3347 - val_accuracy: 0.5597\n",
      "Epoch 261/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.3341 - accuracy: 0.5860 - val_loss: 30.4964 - val_accuracy: 0.6178\n",
      "Epoch 262/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 33.5498 - accuracy: 0.6282 - val_loss: 35.5898 - val_accuracy: 0.6101\n",
      "Epoch 263/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.3297 - accuracy: 0.5661 - val_loss: 39.1577 - val_accuracy: 0.5820\n",
      "Epoch 264/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 32.8704 - accuracy: 0.5559 - val_loss: 31.5450 - val_accuracy: 0.6091\n",
      "Epoch 265/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 33.2484 - accuracy: 0.5780 - val_loss: 39.7909 - val_accuracy: 0.5674\n",
      "Epoch 266/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.5612 - accuracy: 0.5741 - val_loss: 38.0791 - val_accuracy: 0.6072\n",
      "Epoch 267/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.0214 - accuracy: 0.5479 - val_loss: 50.8615 - val_accuracy: 0.5247\n",
      "Epoch 268/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.0218 - accuracy: 0.5700 - val_loss: 34.7360 - val_accuracy: 0.5577\n",
      "Epoch 269/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 34.4053 - accuracy: 0.5719 - val_loss: 40.5081 - val_accuracy: 0.5121\n",
      "Epoch 270/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.3374 - accuracy: 0.5307 - val_loss: 21.5307 - val_accuracy: 0.4704\n",
      "Epoch 271/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.2014 - accuracy: 0.5443 - val_loss: 39.5557 - val_accuracy: 0.5170\n",
      "Epoch 272/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.9407 - accuracy: 0.5877 - val_loss: 19.9912 - val_accuracy: 0.5276\n",
      "Epoch 273/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.0271 - accuracy: 0.5571 - val_loss: 37.6079 - val_accuracy: 0.6101\n",
      "Epoch 274/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.9120 - accuracy: 0.6197 - val_loss: 49.8928 - val_accuracy: 0.6014\n",
      "Epoch 275/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 33.9787 - accuracy: 0.6134 - val_loss: 39.8000 - val_accuracy: 0.6169\n",
      "Epoch 276/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 33.3438 - accuracy: 0.5266 - val_loss: 37.0708 - val_accuracy: 0.5858\n",
      "Epoch 277/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 33.1704 - accuracy: 0.5501 - val_loss: 38.1001 - val_accuracy: 0.6363\n",
      "Epoch 278/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.4036 - accuracy: 0.5748 - val_loss: 28.5507 - val_accuracy: 0.6149\n",
      "Epoch 279/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.5212 - accuracy: 0.5809 - val_loss: 37.2251 - val_accuracy: 0.6237\n",
      "Epoch 280/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.2176 - accuracy: 0.6226 - val_loss: 31.8928 - val_accuracy: 0.5694\n",
      "Epoch 281/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.0139 - accuracy: 0.6141 - val_loss: 43.9731 - val_accuracy: 0.6421\n",
      "Epoch 282/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.3395 - accuracy: 0.6406 - val_loss: 31.6388 - val_accuracy: 0.6275\n",
      "Epoch 283/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.9561 - accuracy: 0.6199 - val_loss: 40.1678 - val_accuracy: 0.5626\n",
      "Epoch 284/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.1695 - accuracy: 0.5569 - val_loss: 30.1402 - val_accuracy: 0.5112\n",
      "Epoch 285/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.9590 - accuracy: 0.5794 - val_loss: 45.9342 - val_accuracy: 0.5121\n",
      "Epoch 286/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.7354 - accuracy: 0.5440 - val_loss: 24.3275 - val_accuracy: 0.5887\n",
      "Epoch 287/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.9476 - accuracy: 0.5831 - val_loss: 60.7813 - val_accuracy: 0.6295\n",
      "Epoch 288/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.2944 - accuracy: 0.5627 - val_loss: 42.2311 - val_accuracy: 0.6091\n",
      "Epoch 289/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.0940 - accuracy: 0.6224 - val_loss: 34.1516 - val_accuracy: 0.5732\n",
      "Epoch 290/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.4678 - accuracy: 0.6236 - val_loss: 42.1037 - val_accuracy: 0.6402\n",
      "Epoch 291/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.0046 - accuracy: 0.6066 - val_loss: 43.9886 - val_accuracy: 0.5858\n",
      "Epoch 292/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 32.2964 - accuracy: 0.6093 - val_loss: 47.9208 - val_accuracy: 0.6372\n",
      "Epoch 293/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.7910 - accuracy: 0.5974 - val_loss: 30.9158 - val_accuracy: 0.6528\n",
      "Epoch 294/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.4674 - accuracy: 0.6039 - val_loss: 48.0730 - val_accuracy: 0.5228\n",
      "Epoch 295/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.1443 - accuracy: 0.5891 - val_loss: 50.0184 - val_accuracy: 0.6809\n",
      "Epoch 296/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.7296 - accuracy: 0.5940 - val_loss: 29.8030 - val_accuracy: 0.6314\n",
      "Epoch 297/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.5131 - accuracy: 0.5911 - val_loss: 28.8189 - val_accuracy: 0.5044\n",
      "Epoch 298/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 31.4592 - accuracy: 0.6117 - val_loss: 32.0417 - val_accuracy: 0.5732\n",
      "Epoch 299/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.9701 - accuracy: 0.6141 - val_loss: 24.1427 - val_accuracy: 0.5383\n",
      "Epoch 300/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.7122 - accuracy: 0.6258 - val_loss: 34.8601 - val_accuracy: 0.6305\n",
      "Epoch 301/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.0932 - accuracy: 0.6047 - val_loss: 38.2466 - val_accuracy: 0.6324\n",
      "Epoch 302/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.8770 - accuracy: 0.6158 - val_loss: 22.6300 - val_accuracy: 0.6654\n",
      "Epoch 303/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.3445 - accuracy: 0.6318 - val_loss: 33.2832 - val_accuracy: 0.5567\n",
      "Epoch 304/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.5436 - accuracy: 0.6119 - val_loss: 20.7989 - val_accuracy: 0.6382\n",
      "Epoch 305/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 28.8878 - accuracy: 0.5918 - val_loss: 48.1613 - val_accuracy: 0.5703\n",
      "Epoch 306/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.2553 - accuracy: 0.5913 - val_loss: 37.9392 - val_accuracy: 0.6188\n",
      "Epoch 307/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.7701 - accuracy: 0.5782 - val_loss: 40.0482 - val_accuracy: 0.5441\n",
      "Epoch 308/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.7663 - accuracy: 0.6095 - val_loss: 32.2520 - val_accuracy: 0.6178\n",
      "Epoch 309/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.4400 - accuracy: 0.6258 - val_loss: 35.6493 - val_accuracy: 0.6014\n",
      "Epoch 310/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.8495 - accuracy: 0.6187 - val_loss: 19.0929 - val_accuracy: 0.6392\n",
      "Epoch 311/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.8204 - accuracy: 0.6141 - val_loss: 37.6368 - val_accuracy: 0.6033\n",
      "Epoch 312/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 30.2389 - accuracy: 0.6211 - val_loss: 37.1842 - val_accuracy: 0.5946\n",
      "Epoch 313/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.8156 - accuracy: 0.6129 - val_loss: 36.2664 - val_accuracy: 0.6460\n",
      "Epoch 314/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.7839 - accuracy: 0.6260 - val_loss: 44.4807 - val_accuracy: 0.6256\n",
      "Epoch 315/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 31.1838 - accuracy: 0.6182 - val_loss: 51.4448 - val_accuracy: 0.6275\n",
      "Epoch 316/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.6914 - accuracy: 0.6236 - val_loss: 46.4139 - val_accuracy: 0.6440\n",
      "Epoch 317/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.7065 - accuracy: 0.6379 - val_loss: 26.7301 - val_accuracy: 0.6537\n",
      "Epoch 318/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.0138 - accuracy: 0.6107 - val_loss: 40.4753 - val_accuracy: 0.5597\n",
      "Epoch 319/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.6156 - accuracy: 0.6073 - val_loss: 39.4702 - val_accuracy: 0.5626\n",
      "Epoch 320/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.1234 - accuracy: 0.5722 - val_loss: 33.7758 - val_accuracy: 0.6149\n",
      "Epoch 321/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.9955 - accuracy: 0.6005 - val_loss: 31.2058 - val_accuracy: 0.5810\n",
      "Epoch 322/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.8860 - accuracy: 0.5940 - val_loss: 44.7911 - val_accuracy: 0.5946\n",
      "Epoch 323/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.5339 - accuracy: 0.6064 - val_loss: 34.0373 - val_accuracy: 0.6169\n",
      "Epoch 324/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.7416 - accuracy: 0.6013 - val_loss: 46.6228 - val_accuracy: 0.6101\n",
      "Epoch 325/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.5357 - accuracy: 0.6161 - val_loss: 21.0589 - val_accuracy: 0.6402\n",
      "Epoch 326/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.0656 - accuracy: 0.6088 - val_loss: 34.5582 - val_accuracy: 0.6402\n",
      "Epoch 327/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.8267 - accuracy: 0.6403 - val_loss: 23.1131 - val_accuracy: 0.6353\n",
      "Epoch 328/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.9219 - accuracy: 0.6442 - val_loss: 34.4030 - val_accuracy: 0.6382\n",
      "Epoch 329/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.5511 - accuracy: 0.6575 - val_loss: 32.5341 - val_accuracy: 0.6363\n",
      "Epoch 330/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 29.1303 - accuracy: 0.6064 - val_loss: 22.9217 - val_accuracy: 0.5907\n",
      "Epoch 331/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.7230 - accuracy: 0.6030 - val_loss: 32.1838 - val_accuracy: 0.6014\n",
      "Epoch 332/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 28.3298 - accuracy: 0.5828 - val_loss: 32.0343 - val_accuracy: 0.6004\n",
      "Epoch 333/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.0800 - accuracy: 0.6216 - val_loss: 28.7963 - val_accuracy: 0.6392\n",
      "Epoch 334/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 29.1087 - accuracy: 0.5976 - val_loss: 37.2766 - val_accuracy: 0.6208\n",
      "Epoch 335/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.4613 - accuracy: 0.6078 - val_loss: 22.5594 - val_accuracy: 0.6120\n",
      "Epoch 336/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.6382 - accuracy: 0.5870 - val_loss: 41.4501 - val_accuracy: 0.5917\n",
      "Epoch 337/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.9723 - accuracy: 0.6190 - val_loss: 27.9260 - val_accuracy: 0.6392\n",
      "Epoch 338/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.4255 - accuracy: 0.6226 - val_loss: 36.7442 - val_accuracy: 0.6450\n",
      "Epoch 339/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.7238 - accuracy: 0.5947 - val_loss: 26.7829 - val_accuracy: 0.6896\n",
      "Epoch 340/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.8833 - accuracy: 0.5971 - val_loss: 19.0624 - val_accuracy: 0.5645\n",
      "Epoch 341/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.9253 - accuracy: 0.5819 - val_loss: 32.7904 - val_accuracy: 0.6256\n",
      "Epoch 342/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.5675 - accuracy: 0.6168 - val_loss: 38.6353 - val_accuracy: 0.6198\n",
      "Epoch 343/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.3670 - accuracy: 0.6083 - val_loss: 25.1759 - val_accuracy: 0.6334\n",
      "Epoch 344/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.1959 - accuracy: 0.6161 - val_loss: 32.0324 - val_accuracy: 0.5965\n",
      "Epoch 345/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.3701 - accuracy: 0.6042 - val_loss: 43.8115 - val_accuracy: 0.5820\n",
      "Epoch 346/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.2412 - accuracy: 0.6180 - val_loss: 23.8026 - val_accuracy: 0.6382\n",
      "Epoch 347/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.5802 - accuracy: 0.6134 - val_loss: 20.3205 - val_accuracy: 0.6877\n",
      "Epoch 348/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 28.1546 - accuracy: 0.5819 - val_loss: 32.0464 - val_accuracy: 0.5655\n",
      "Epoch 349/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.7352 - accuracy: 0.6219 - val_loss: 19.9891 - val_accuracy: 0.6469\n",
      "Epoch 350/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.9070 - accuracy: 0.6122 - val_loss: 27.3863 - val_accuracy: 0.5723\n",
      "Epoch 351/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.7648 - accuracy: 0.6049 - val_loss: 35.9472 - val_accuracy: 0.6111\n",
      "Epoch 352/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.6164 - accuracy: 0.6403 - val_loss: 24.1729 - val_accuracy: 0.6208\n",
      "Epoch 353/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.2080 - accuracy: 0.6117 - val_loss: 18.5599 - val_accuracy: 0.6576\n",
      "Epoch 354/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.5593 - accuracy: 0.6250 - val_loss: 26.1103 - val_accuracy: 0.6557\n",
      "Epoch 355/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.7555 - accuracy: 0.6372 - val_loss: 24.9370 - val_accuracy: 0.5955\n",
      "Epoch 356/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.5901 - accuracy: 0.6027 - val_loss: 42.8091 - val_accuracy: 0.5752\n",
      "Epoch 357/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.4894 - accuracy: 0.6095 - val_loss: 34.9992 - val_accuracy: 0.6460\n",
      "Epoch 358/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.0393 - accuracy: 0.5947 - val_loss: 19.3256 - val_accuracy: 0.5897\n",
      "Epoch 359/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.0308 - accuracy: 0.5945 - val_loss: 26.7770 - val_accuracy: 0.5820\n",
      "Epoch 360/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.8920 - accuracy: 0.6313 - val_loss: 31.4831 - val_accuracy: 0.6450\n",
      "Epoch 361/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.2978 - accuracy: 0.6362 - val_loss: 40.3361 - val_accuracy: 0.6149\n",
      "Epoch 362/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.8083 - accuracy: 0.6486 - val_loss: 38.8254 - val_accuracy: 0.6372\n",
      "Epoch 363/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.7328 - accuracy: 0.6262 - val_loss: 30.0127 - val_accuracy: 0.6440\n",
      "Epoch 364/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.4210 - accuracy: 0.6389 - val_loss: 20.8365 - val_accuracy: 0.5723\n",
      "Epoch 365/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.5028 - accuracy: 0.5979 - val_loss: 41.0462 - val_accuracy: 0.5703\n",
      "Epoch 366/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 27.5428 - accuracy: 0.5586 - val_loss: 20.5769 - val_accuracy: 0.4888\n",
      "Epoch 367/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.4400 - accuracy: 0.6093 - val_loss: 27.9729 - val_accuracy: 0.6402\n",
      "Epoch 368/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.7744 - accuracy: 0.6114 - val_loss: 27.5905 - val_accuracy: 0.5597\n",
      "Epoch 369/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.3738 - accuracy: 0.5823 - val_loss: 35.6748 - val_accuracy: 0.4956\n",
      "Epoch 370/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.8822 - accuracy: 0.6267 - val_loss: 18.2868 - val_accuracy: 0.6101\n",
      "Epoch 371/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 26.2529 - accuracy: 0.5996 - val_loss: 37.3264 - val_accuracy: 0.5849\n",
      "Epoch 372/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.2346 - accuracy: 0.5843 - val_loss: 36.9775 - val_accuracy: 0.5955\n",
      "Epoch 373/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.6789 - accuracy: 0.5382 - val_loss: 34.0115 - val_accuracy: 0.5209\n",
      "Epoch 374/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.4473 - accuracy: 0.5763 - val_loss: 34.9722 - val_accuracy: 0.5441\n",
      "Epoch 375/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.5136 - accuracy: 0.5654 - val_loss: 29.1850 - val_accuracy: 0.6402\n",
      "Epoch 376/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.4051 - accuracy: 0.5634 - val_loss: 43.9252 - val_accuracy: 0.6295\n",
      "Epoch 377/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 27.1230 - accuracy: 0.6389 - val_loss: 26.0044 - val_accuracy: 0.6188\n",
      "Epoch 378/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.6839 - accuracy: 0.5644 - val_loss: 40.8177 - val_accuracy: 0.5451\n",
      "Epoch 379/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.7281 - accuracy: 0.6367 - val_loss: 39.1880 - val_accuracy: 0.6004\n",
      "Epoch 380/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.6995 - accuracy: 0.6282 - val_loss: 30.8218 - val_accuracy: 0.6440\n",
      "Epoch 381/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.0364 - accuracy: 0.5967 - val_loss: 32.2372 - val_accuracy: 0.6014\n",
      "Epoch 382/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.5123 - accuracy: 0.5758 - val_loss: 34.4890 - val_accuracy: 0.5655\n",
      "Epoch 383/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.8923 - accuracy: 0.6066 - val_loss: 19.7961 - val_accuracy: 0.5868\n",
      "Epoch 384/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 26.0243 - accuracy: 0.5967 - val_loss: 34.5535 - val_accuracy: 0.5694\n",
      "Epoch 385/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.2318 - accuracy: 0.6025 - val_loss: 21.8444 - val_accuracy: 0.6557\n",
      "Epoch 386/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.2173 - accuracy: 0.6180 - val_loss: 33.9718 - val_accuracy: 0.6140\n",
      "Epoch 387/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 26.1371 - accuracy: 0.6321 - val_loss: 34.7298 - val_accuracy: 0.6285\n",
      "Epoch 388/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 25.1123 - accuracy: 0.6282 - val_loss: 27.0055 - val_accuracy: 0.6440\n",
      "Epoch 389/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.4527 - accuracy: 0.6439 - val_loss: 20.0736 - val_accuracy: 0.5732\n",
      "Epoch 390/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.5120 - accuracy: 0.6228 - val_loss: 27.0827 - val_accuracy: 0.6246\n",
      "Epoch 391/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.7282 - accuracy: 0.6260 - val_loss: 40.7927 - val_accuracy: 0.6751\n",
      "Epoch 392/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.7940 - accuracy: 0.6292 - val_loss: 22.1783 - val_accuracy: 0.6402\n",
      "Epoch 393/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.7546 - accuracy: 0.6391 - val_loss: 35.7659 - val_accuracy: 0.6334\n",
      "Epoch 394/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.9215 - accuracy: 0.6335 - val_loss: 44.5345 - val_accuracy: 0.6111\n",
      "Epoch 395/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.8279 - accuracy: 0.6231 - val_loss: 30.8761 - val_accuracy: 0.6411\n",
      "Epoch 396/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 25.5863 - accuracy: 0.5935 - val_loss: 32.9112 - val_accuracy: 0.6460\n",
      "Epoch 397/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.1604 - accuracy: 0.6185 - val_loss: 24.6983 - val_accuracy: 0.6489\n",
      "Epoch 398/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.2052 - accuracy: 0.6258 - val_loss: 32.3843 - val_accuracy: 0.5868\n",
      "Epoch 399/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.6009 - accuracy: 0.6367 - val_loss: 29.1609 - val_accuracy: 0.6208\n",
      "Epoch 400/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.8725 - accuracy: 0.6444 - val_loss: 24.6507 - val_accuracy: 0.6663\n",
      "Epoch 401/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.9268 - accuracy: 0.6406 - val_loss: 41.3470 - val_accuracy: 0.6644\n",
      "Epoch 402/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.3525 - accuracy: 0.6425 - val_loss: 36.5564 - val_accuracy: 0.6654\n",
      "Epoch 403/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.2912 - accuracy: 0.6680 - val_loss: 36.6167 - val_accuracy: 0.6188\n",
      "Epoch 404/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.1675 - accuracy: 0.6478 - val_loss: 34.1699 - val_accuracy: 0.6334\n",
      "Epoch 405/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.1513 - accuracy: 0.6524 - val_loss: 19.4836 - val_accuracy: 0.6275\n",
      "Epoch 406/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 24.9442 - accuracy: 0.6551 - val_loss: 19.2821 - val_accuracy: 0.5975\n",
      "Epoch 407/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.9449 - accuracy: 0.6558 - val_loss: 20.2073 - val_accuracy: 0.6431\n",
      "Epoch 408/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.5776 - accuracy: 0.6427 - val_loss: 29.8875 - val_accuracy: 0.6343\n",
      "Epoch 409/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.2480 - accuracy: 0.6570 - val_loss: 30.5259 - val_accuracy: 0.6450\n",
      "Epoch 410/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.7511 - accuracy: 0.6578 - val_loss: 36.2264 - val_accuracy: 0.6751\n",
      "Epoch 411/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.9719 - accuracy: 0.6449 - val_loss: 28.6402 - val_accuracy: 0.7051\n",
      "Epoch 412/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.8247 - accuracy: 0.6612 - val_loss: 38.4753 - val_accuracy: 0.6431\n",
      "Epoch 413/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 25.4358 - accuracy: 0.6442 - val_loss: 20.6137 - val_accuracy: 0.6489\n",
      "Epoch 414/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.9684 - accuracy: 0.6558 - val_loss: 20.4263 - val_accuracy: 0.6081\n",
      "Epoch 415/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.9097 - accuracy: 0.6517 - val_loss: 32.9272 - val_accuracy: 0.6887\n",
      "Epoch 416/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 25.2885 - accuracy: 0.6420 - val_loss: 34.3401 - val_accuracy: 0.6576\n",
      "Epoch 417/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.6601 - accuracy: 0.6580 - val_loss: 25.5302 - val_accuracy: 0.6508\n",
      "Epoch 418/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.6297 - accuracy: 0.6466 - val_loss: 27.6115 - val_accuracy: 0.6819\n",
      "Epoch 419/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.5519 - accuracy: 0.6384 - val_loss: 33.3160 - val_accuracy: 0.6896\n",
      "Epoch 420/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.4615 - accuracy: 0.6425 - val_loss: 28.0796 - val_accuracy: 0.6644\n",
      "Epoch 421/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.0310 - accuracy: 0.6575 - val_loss: 26.6711 - val_accuracy: 0.6731\n",
      "Epoch 422/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.6599 - accuracy: 0.6522 - val_loss: 19.5417 - val_accuracy: 0.6528\n",
      "Epoch 423/2000\n",
      "4123/4123 [==============================] - ETA: 0s - loss: 21.1290 - accuracy: 0.636 - 0s 23us/step - loss: 23.4769 - accuracy: 0.6376 - val_loss: 31.8327 - val_accuracy: 0.7148\n",
      "Epoch 424/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 24.8710 - accuracy: 0.6583 - val_loss: 23.7242 - val_accuracy: 0.6528\n",
      "Epoch 425/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.8668 - accuracy: 0.6544 - val_loss: 29.9056 - val_accuracy: 0.6576\n",
      "Epoch 426/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.4272 - accuracy: 0.6362 - val_loss: 22.2559 - val_accuracy: 0.6964\n",
      "Epoch 427/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.0065 - accuracy: 0.6330 - val_loss: 32.3712 - val_accuracy: 0.6159\n",
      "Epoch 428/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.2704 - accuracy: 0.6408 - val_loss: 18.2994 - val_accuracy: 0.6499\n",
      "Epoch 429/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.5382 - accuracy: 0.6556 - val_loss: 31.2288 - val_accuracy: 0.6363\n",
      "Epoch 430/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.2600 - accuracy: 0.6655 - val_loss: 30.7325 - val_accuracy: 0.6518\n",
      "Epoch 431/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.8640 - accuracy: 0.6580 - val_loss: 32.5509 - val_accuracy: 0.6159\n",
      "Epoch 432/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.6897 - accuracy: 0.6469 - val_loss: 19.7585 - val_accuracy: 0.6916\n",
      "Epoch 433/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.5531 - accuracy: 0.6575 - val_loss: 32.6055 - val_accuracy: 0.6392\n",
      "Epoch 434/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 24.5085 - accuracy: 0.6682 - val_loss: 29.0207 - val_accuracy: 0.6499\n",
      "Epoch 435/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.1528 - accuracy: 0.6612 - val_loss: 20.9656 - val_accuracy: 0.6906\n",
      "Epoch 436/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.2562 - accuracy: 0.6619 - val_loss: 22.6903 - val_accuracy: 0.6722\n",
      "Epoch 437/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.7512 - accuracy: 0.6524 - val_loss: 34.5431 - val_accuracy: 0.6101\n",
      "Epoch 438/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.9485 - accuracy: 0.6585 - val_loss: 32.3797 - val_accuracy: 0.6625\n",
      "Epoch 439/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.8751 - accuracy: 0.6561 - val_loss: 22.6613 - val_accuracy: 0.6275\n",
      "Epoch 440/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.1507 - accuracy: 0.6423 - val_loss: 19.5601 - val_accuracy: 0.6188\n",
      "Epoch 441/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.1095 - accuracy: 0.6857 - val_loss: 35.0898 - val_accuracy: 0.7236\n",
      "Epoch 442/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.9275 - accuracy: 0.6961 - val_loss: 17.1813 - val_accuracy: 0.7255\n",
      "Epoch 443/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.4603 - accuracy: 0.6619 - val_loss: 41.3197 - val_accuracy: 0.6266\n",
      "Epoch 444/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.3361 - accuracy: 0.6760 - val_loss: 28.1169 - val_accuracy: 0.6256\n",
      "Epoch 445/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.8749 - accuracy: 0.6631 - val_loss: 30.1981 - val_accuracy: 0.7304\n",
      "Epoch 446/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.6942 - accuracy: 0.6823 - val_loss: 32.6880 - val_accuracy: 0.6712\n",
      "Epoch 447/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.6965 - accuracy: 0.6866 - val_loss: 22.5115 - val_accuracy: 0.7313\n",
      "Epoch 448/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.1860 - accuracy: 0.7177 - val_loss: 28.4732 - val_accuracy: 0.6392\n",
      "Epoch 449/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.1374 - accuracy: 0.6818 - val_loss: 33.2347 - val_accuracy: 0.7595\n",
      "Epoch 450/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.9816 - accuracy: 0.6932 - val_loss: 25.3352 - val_accuracy: 0.6363\n",
      "Epoch 451/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 23.6816 - accuracy: 0.6922 - val_loss: 36.9378 - val_accuracy: 0.7081\n",
      "Epoch 452/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.6277 - accuracy: 0.7017 - val_loss: 18.7768 - val_accuracy: 0.7236\n",
      "Epoch 453/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.5446 - accuracy: 0.6731 - val_loss: 32.6430 - val_accuracy: 0.7401\n",
      "Epoch 454/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 23.0738 - accuracy: 0.7068 - val_loss: 29.8146 - val_accuracy: 0.7148\n",
      "Epoch 455/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 24.0460 - accuracy: 0.6842 - val_loss: 39.8396 - val_accuracy: 0.6460\n",
      "Epoch 456/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.9324 - accuracy: 0.6760 - val_loss: 19.2866 - val_accuracy: 0.6479\n",
      "Epoch 457/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.6137 - accuracy: 0.7039 - val_loss: 29.2470 - val_accuracy: 0.6450\n",
      "Epoch 458/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.8749 - accuracy: 0.6956 - val_loss: 30.3667 - val_accuracy: 0.7168\n",
      "Epoch 459/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 23.3304 - accuracy: 0.6830 - val_loss: 22.5786 - val_accuracy: 0.6712\n",
      "Epoch 460/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.3846 - accuracy: 0.6748 - val_loss: 20.6799 - val_accuracy: 0.6372\n",
      "Epoch 461/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.4421 - accuracy: 0.6995 - val_loss: 31.8604 - val_accuracy: 0.6625\n",
      "Epoch 462/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.5486 - accuracy: 0.6893 - val_loss: 21.9833 - val_accuracy: 0.6809\n",
      "Epoch 463/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.2339 - accuracy: 0.6772 - val_loss: 25.8853 - val_accuracy: 0.7585\n",
      "Epoch 464/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 22.7282 - accuracy: 0.7400 - val_loss: 39.0843 - val_accuracy: 0.7595\n",
      "Epoch 465/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.1390 - accuracy: 0.7111 - val_loss: 16.4924 - val_accuracy: 0.7624\n",
      "Epoch 466/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 21.4241 - accuracy: 0.7145 - val_loss: 19.0747 - val_accuracy: 0.6964\n",
      "Epoch 467/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.7459 - accuracy: 0.6815 - val_loss: 35.4679 - val_accuracy: 0.6557\n",
      "Epoch 468/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.1837 - accuracy: 0.6665 - val_loss: 22.5568 - val_accuracy: 0.6305\n",
      "Epoch 469/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.2672 - accuracy: 0.6777 - val_loss: 27.4743 - val_accuracy: 0.7265\n",
      "Epoch 470/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.9712 - accuracy: 0.7133 - val_loss: 22.0594 - val_accuracy: 0.7177\n",
      "Epoch 471/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.7245 - accuracy: 0.7092 - val_loss: 24.1253 - val_accuracy: 0.7158\n",
      "Epoch 472/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 23.0244 - accuracy: 0.6854 - val_loss: 22.5438 - val_accuracy: 0.7488\n",
      "Epoch 473/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.2622 - accuracy: 0.7177 - val_loss: 35.2310 - val_accuracy: 0.6246\n",
      "Epoch 474/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.2406 - accuracy: 0.7284 - val_loss: 34.6511 - val_accuracy: 0.6964\n",
      "Epoch 475/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.9381 - accuracy: 0.6963 - val_loss: 25.4762 - val_accuracy: 0.7517\n",
      "Epoch 476/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.8201 - accuracy: 0.7058 - val_loss: 34.4630 - val_accuracy: 0.6722\n",
      "Epoch 477/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.4093 - accuracy: 0.7138 - val_loss: 39.9990 - val_accuracy: 0.6954\n",
      "Epoch 478/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.4559 - accuracy: 0.6791 - val_loss: 28.6407 - val_accuracy: 0.6440\n",
      "Epoch 479/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.6676 - accuracy: 0.6755 - val_loss: 23.0213 - val_accuracy: 0.7207\n",
      "Epoch 480/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.6674 - accuracy: 0.7048 - val_loss: 27.7476 - val_accuracy: 0.7430\n",
      "Epoch 481/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.8859 - accuracy: 0.6779 - val_loss: 30.8256 - val_accuracy: 0.7468\n",
      "Epoch 482/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.7642 - accuracy: 0.7347 - val_loss: 23.5895 - val_accuracy: 0.7740\n",
      "Epoch 483/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 22.5726 - accuracy: 0.7344 - val_loss: 27.0636 - val_accuracy: 0.7682\n",
      "Epoch 484/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.4502 - accuracy: 0.6997 - val_loss: 29.7570 - val_accuracy: 0.8050\n",
      "Epoch 485/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 23.0380 - accuracy: 0.7230 - val_loss: 32.2581 - val_accuracy: 0.6285\n",
      "Epoch 486/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 23.1073 - accuracy: 0.7077 - val_loss: 26.6583 - val_accuracy: 0.7207\n",
      "Epoch 487/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.1328 - accuracy: 0.7284 - val_loss: 25.9852 - val_accuracy: 0.6431\n",
      "Epoch 488/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.2210 - accuracy: 0.7036 - val_loss: 32.0450 - val_accuracy: 0.6518\n",
      "Epoch 489/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 22.2301 - accuracy: 0.6951 - val_loss: 32.7878 - val_accuracy: 0.6334\n",
      "Epoch 490/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.9141 - accuracy: 0.7359 - val_loss: 27.1145 - val_accuracy: 0.6596\n",
      "Epoch 491/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 22.4370 - accuracy: 0.6898 - val_loss: 24.5598 - val_accuracy: 0.7042\n",
      "Epoch 492/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.5332 - accuracy: 0.7233 - val_loss: 28.4374 - val_accuracy: 0.6314\n",
      "Epoch 493/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.1370 - accuracy: 0.6900 - val_loss: 26.1761 - val_accuracy: 0.6382\n",
      "Epoch 494/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.6119 - accuracy: 0.7237 - val_loss: 21.6641 - val_accuracy: 0.7371\n",
      "Epoch 495/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.8763 - accuracy: 0.7000 - val_loss: 20.2762 - val_accuracy: 0.7633\n",
      "Epoch 496/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.0589 - accuracy: 0.7194 - val_loss: 28.2187 - val_accuracy: 0.6615\n",
      "Epoch 497/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.2984 - accuracy: 0.6983 - val_loss: 20.8118 - val_accuracy: 0.7284\n",
      "Epoch 498/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.3121 - accuracy: 0.7288 - val_loss: 31.1918 - val_accuracy: 0.7556\n",
      "Epoch 499/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.0873 - accuracy: 0.7182 - val_loss: 33.3331 - val_accuracy: 0.6576\n",
      "Epoch 500/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.6672 - accuracy: 0.6779 - val_loss: 22.4114 - val_accuracy: 0.6945\n",
      "Epoch 501/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.6095 - accuracy: 0.7099 - val_loss: 29.5220 - val_accuracy: 0.6246\n",
      "Epoch 502/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.0397 - accuracy: 0.7070 - val_loss: 20.3080 - val_accuracy: 0.7410\n",
      "Epoch 503/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 21.6790 - accuracy: 0.6988 - val_loss: 27.1560 - val_accuracy: 0.6596\n",
      "Epoch 504/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.3352 - accuracy: 0.7017 - val_loss: 15.5589 - val_accuracy: 0.7139\n",
      "Epoch 505/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 21.8233 - accuracy: 0.6692 - val_loss: 24.5335 - val_accuracy: 0.6285\n",
      "Epoch 506/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.3859 - accuracy: 0.6779 - val_loss: 25.7406 - val_accuracy: 0.7866\n",
      "Epoch 507/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.1308 - accuracy: 0.7119 - val_loss: 27.0948 - val_accuracy: 0.6508\n",
      "Epoch 508/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 22.0972 - accuracy: 0.7347 - val_loss: 32.4082 - val_accuracy: 0.6596\n",
      "Epoch 509/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.9514 - accuracy: 0.7301 - val_loss: 22.8344 - val_accuracy: 0.7323\n",
      "Epoch 510/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.1360 - accuracy: 0.7322 - val_loss: 23.5407 - val_accuracy: 0.7081\n",
      "Epoch 511/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.9054 - accuracy: 0.7305 - val_loss: 33.1098 - val_accuracy: 0.6334\n",
      "Epoch 512/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.1449 - accuracy: 0.6944 - val_loss: 34.9409 - val_accuracy: 0.7245\n",
      "Epoch 513/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.3162 - accuracy: 0.6995 - val_loss: 34.0798 - val_accuracy: 0.6537\n",
      "Epoch 514/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.2715 - accuracy: 0.7531 - val_loss: 26.5902 - val_accuracy: 0.7401\n",
      "Epoch 515/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.1300 - accuracy: 0.7461 - val_loss: 15.8147 - val_accuracy: 0.7915\n",
      "Epoch 516/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.2818 - accuracy: 0.7342 - val_loss: 29.3256 - val_accuracy: 0.7342\n",
      "Epoch 517/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 21.6731 - accuracy: 0.7444 - val_loss: 20.0692 - val_accuracy: 0.7430\n",
      "Epoch 518/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.8205 - accuracy: 0.7298 - val_loss: 39.0486 - val_accuracy: 0.7595\n",
      "Epoch 519/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.3317 - accuracy: 0.7310 - val_loss: 29.4397 - val_accuracy: 0.7294\n",
      "Epoch 520/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 21.8777 - accuracy: 0.7322 - val_loss: 26.4852 - val_accuracy: 0.7342\n",
      "Epoch 521/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 22.0989 - accuracy: 0.7393 - val_loss: 30.8719 - val_accuracy: 0.7614\n",
      "Epoch 522/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 21.9169 - accuracy: 0.7223 - val_loss: 26.9408 - val_accuracy: 0.7468\n",
      "Epoch 523/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.7957 - accuracy: 0.7672 - val_loss: 29.3865 - val_accuracy: 0.7430\n",
      "Epoch 524/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.3950 - accuracy: 0.7448 - val_loss: 19.6131 - val_accuracy: 0.6838\n",
      "Epoch 525/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.8378 - accuracy: 0.7022 - val_loss: 26.6540 - val_accuracy: 0.6916\n",
      "Epoch 526/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.2955 - accuracy: 0.7288 - val_loss: 21.6168 - val_accuracy: 0.6547\n",
      "Epoch 527/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.4033 - accuracy: 0.7533 - val_loss: 19.1802 - val_accuracy: 0.6227\n",
      "Epoch 528/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.0229 - accuracy: 0.7356 - val_loss: 27.0411 - val_accuracy: 0.7556\n",
      "Epoch 529/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.3640 - accuracy: 0.7170 - val_loss: 30.0202 - val_accuracy: 0.7478\n",
      "Epoch 530/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.9029 - accuracy: 0.7470 - val_loss: 22.0195 - val_accuracy: 0.6324\n",
      "Epoch 531/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.2411 - accuracy: 0.7317 - val_loss: 17.8800 - val_accuracy: 0.7304\n",
      "Epoch 532/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 21.1286 - accuracy: 0.7361 - val_loss: 33.3160 - val_accuracy: 0.7546\n",
      "Epoch 533/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.0900 - accuracy: 0.7533 - val_loss: 29.1382 - val_accuracy: 0.6450\n",
      "Epoch 534/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.5987 - accuracy: 0.7257 - val_loss: 29.4716 - val_accuracy: 0.7527\n",
      "Epoch 535/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.6528 - accuracy: 0.7153 - val_loss: 28.4976 - val_accuracy: 0.6188\n",
      "Epoch 536/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.6125 - accuracy: 0.7395 - val_loss: 30.0783 - val_accuracy: 0.7381\n",
      "Epoch 537/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.3749 - accuracy: 0.7570 - val_loss: 34.0649 - val_accuracy: 0.7507\n",
      "Epoch 538/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.9882 - accuracy: 0.7385 - val_loss: 20.8588 - val_accuracy: 0.7682\n",
      "Epoch 539/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.7801 - accuracy: 0.7269 - val_loss: 21.8605 - val_accuracy: 0.7381\n",
      "Epoch 540/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.2304 - accuracy: 0.7092 - val_loss: 18.6648 - val_accuracy: 0.8177\n",
      "Epoch 541/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 20.3821 - accuracy: 0.7628 - val_loss: 30.0873 - val_accuracy: 0.7818\n",
      "Epoch 542/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.4013 - accuracy: 0.7778 - val_loss: 23.7039 - val_accuracy: 0.7818\n",
      "Epoch 543/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.3535 - accuracy: 0.7400 - val_loss: 30.3067 - val_accuracy: 0.7478\n",
      "Epoch 544/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.0095 - accuracy: 0.7458 - val_loss: 22.7416 - val_accuracy: 0.7779\n",
      "Epoch 545/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.8060 - accuracy: 0.7284 - val_loss: 26.0247 - val_accuracy: 0.7468\n",
      "Epoch 546/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.3488 - accuracy: 0.6925 - val_loss: 18.1042 - val_accuracy: 0.7381\n",
      "Epoch 547/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.0824 - accuracy: 0.7528 - val_loss: 18.9052 - val_accuracy: 0.7478\n",
      "Epoch 548/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.7568 - accuracy: 0.7313 - val_loss: 28.4836 - val_accuracy: 0.7488\n",
      "Epoch 549/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.8270 - accuracy: 0.7308 - val_loss: 29.4999 - val_accuracy: 0.7624\n",
      "Epoch 550/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 21.0204 - accuracy: 0.7332 - val_loss: 28.5537 - val_accuracy: 0.7207\n",
      "Epoch 551/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.2712 - accuracy: 0.7279 - val_loss: 25.6705 - val_accuracy: 0.7653\n",
      "Epoch 552/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.9329 - accuracy: 0.7475 - val_loss: 23.2441 - val_accuracy: 0.7352\n",
      "Epoch 553/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 21.0262 - accuracy: 0.7143 - val_loss: 15.8213 - val_accuracy: 0.6343\n",
      "Epoch 554/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.0018 - accuracy: 0.7596 - val_loss: 24.9351 - val_accuracy: 0.8225\n",
      "Epoch 555/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.7237 - accuracy: 0.7914 - val_loss: 27.9355 - val_accuracy: 0.6945\n",
      "Epoch 556/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 21.2183 - accuracy: 0.7116 - val_loss: 20.4122 - val_accuracy: 0.7585\n",
      "Epoch 557/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.4443 - accuracy: 0.7347 - val_loss: 26.4542 - val_accuracy: 0.7459\n",
      "Epoch 558/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.6893 - accuracy: 0.7461 - val_loss: 25.9216 - val_accuracy: 0.7546\n",
      "Epoch 559/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.8979 - accuracy: 0.7606 - val_loss: 30.2340 - val_accuracy: 0.7721\n",
      "Epoch 560/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.9756 - accuracy: 0.7839 - val_loss: 29.0372 - val_accuracy: 0.8448\n",
      "Epoch 561/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 21.0085 - accuracy: 0.7596 - val_loss: 34.5627 - val_accuracy: 0.8215\n",
      "Epoch 562/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.7921 - accuracy: 0.7497 - val_loss: 21.3688 - val_accuracy: 0.7565\n",
      "Epoch 563/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.3835 - accuracy: 0.7691 - val_loss: 19.7648 - val_accuracy: 0.7478\n",
      "Epoch 564/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.7361 - accuracy: 0.7395 - val_loss: 29.5338 - val_accuracy: 0.7342\n",
      "Epoch 565/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.8828 - accuracy: 0.7715 - val_loss: 17.1929 - val_accuracy: 0.6324\n",
      "Epoch 566/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.3890 - accuracy: 0.7410 - val_loss: 24.4054 - val_accuracy: 0.8341\n",
      "Epoch 567/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.6928 - accuracy: 0.7851 - val_loss: 30.0026 - val_accuracy: 0.7401\n",
      "Epoch 568/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.7782 - accuracy: 0.7611 - val_loss: 18.1738 - val_accuracy: 0.6372\n",
      "Epoch 569/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.0379 - accuracy: 0.7575 - val_loss: 32.2709 - val_accuracy: 0.8147\n",
      "Epoch 570/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.2565 - accuracy: 0.7611 - val_loss: 27.4249 - val_accuracy: 0.7692\n",
      "Epoch 571/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.5061 - accuracy: 0.7696 - val_loss: 21.3281 - val_accuracy: 0.7478\n",
      "Epoch 572/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 20.6115 - accuracy: 0.7468 - val_loss: 25.1697 - val_accuracy: 0.8361\n",
      "Epoch 573/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.6010 - accuracy: 0.8079 - val_loss: 23.4399 - val_accuracy: 0.8118\n",
      "Epoch 574/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.5423 - accuracy: 0.7752 - val_loss: 31.2166 - val_accuracy: 0.7284\n",
      "Epoch 575/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.6637 - accuracy: 0.7841 - val_loss: 24.9602 - val_accuracy: 0.7536\n",
      "Epoch 576/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.5551 - accuracy: 0.7577 - val_loss: 15.6571 - val_accuracy: 0.7672\n",
      "Epoch 577/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.8609 - accuracy: 0.7829 - val_loss: 27.0006 - val_accuracy: 0.7808\n",
      "Epoch 578/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.3270 - accuracy: 0.7820 - val_loss: 28.5111 - val_accuracy: 0.7071\n",
      "Epoch 579/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 20.6776 - accuracy: 0.7291 - val_loss: 21.2174 - val_accuracy: 0.7391\n",
      "Epoch 580/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 20.0673 - accuracy: 0.7640 - val_loss: 17.8055 - val_accuracy: 0.8400\n",
      "Epoch 581/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 20.2298 - accuracy: 0.7754 - val_loss: 23.9910 - val_accuracy: 0.8060\n",
      "Epoch 582/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.4475 - accuracy: 0.7878 - val_loss: 24.1646 - val_accuracy: 0.7575\n",
      "Epoch 583/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.3819 - accuracy: 0.7368 - val_loss: 22.4473 - val_accuracy: 0.7740\n",
      "Epoch 584/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.2047 - accuracy: 0.7609 - val_loss: 27.9554 - val_accuracy: 0.8041\n",
      "Epoch 585/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.5121 - accuracy: 0.7480 - val_loss: 25.1903 - val_accuracy: 0.6324\n",
      "Epoch 586/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.7266 - accuracy: 0.7451 - val_loss: 34.4468 - val_accuracy: 0.6896\n",
      "Epoch 587/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.0127 - accuracy: 0.7250 - val_loss: 31.1111 - val_accuracy: 0.7236\n",
      "Epoch 588/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.0610 - accuracy: 0.7623 - val_loss: 35.0491 - val_accuracy: 0.8429\n",
      "Epoch 589/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 19.2473 - accuracy: 0.7783 - val_loss: 21.7759 - val_accuracy: 0.7653\n",
      "Epoch 590/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 20.0596 - accuracy: 0.7810 - val_loss: 16.2914 - val_accuracy: 0.8351\n",
      "Epoch 591/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 20.0288 - accuracy: 0.7490 - val_loss: 27.9898 - val_accuracy: 0.7391\n",
      "Epoch 592/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 20.1990 - accuracy: 0.7616 - val_loss: 18.2087 - val_accuracy: 0.7449\n",
      "Epoch 593/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 19.8700 - accuracy: 0.7679 - val_loss: 26.1435 - val_accuracy: 0.7333\n",
      "Epoch 594/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 20.4041 - accuracy: 0.7635 - val_loss: 30.7360 - val_accuracy: 0.8060\n",
      "Epoch 595/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 19.3183 - accuracy: 0.7599 - val_loss: 37.6507 - val_accuracy: 0.7847\n",
      "Epoch 596/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 20.0733 - accuracy: 0.7451 - val_loss: 28.2959 - val_accuracy: 0.8050\n",
      "Epoch 597/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.0487 - accuracy: 0.7177 - val_loss: 29.4170 - val_accuracy: 0.7963\n",
      "Epoch 598/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.1574 - accuracy: 0.7269 - val_loss: 27.2937 - val_accuracy: 0.7401\n",
      "Epoch 599/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 20.0128 - accuracy: 0.7342 - val_loss: 18.9951 - val_accuracy: 0.7449\n",
      "Epoch 600/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.4444 - accuracy: 0.7487 - val_loss: 21.3772 - val_accuracy: 0.8050\n",
      "Epoch 601/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 20.0871 - accuracy: 0.7638 - val_loss: 22.8984 - val_accuracy: 0.7633\n",
      "Epoch 602/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 20.0887 - accuracy: 0.7233 - val_loss: 34.1126 - val_accuracy: 0.6295\n",
      "Epoch 603/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 20.0027 - accuracy: 0.7524 - val_loss: 26.7101 - val_accuracy: 0.8400\n",
      "Epoch 604/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.5344 - accuracy: 0.7924 - val_loss: 22.5340 - val_accuracy: 0.7362\n",
      "Epoch 605/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.7702 - accuracy: 0.7870 - val_loss: 23.1322 - val_accuracy: 0.8225\n",
      "Epoch 606/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 19.9793 - accuracy: 0.8128 - val_loss: 22.6052 - val_accuracy: 0.7595\n",
      "Epoch 607/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.0846 - accuracy: 0.7839 - val_loss: 18.8942 - val_accuracy: 0.6741\n",
      "Epoch 608/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.9294 - accuracy: 0.7698 - val_loss: 25.2169 - val_accuracy: 0.8526\n",
      "Epoch 609/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.6709 - accuracy: 0.8060 - val_loss: 24.5621 - val_accuracy: 0.7313\n",
      "Epoch 610/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.2193 - accuracy: 0.7929 - val_loss: 33.0180 - val_accuracy: 0.8089\n",
      "Epoch 611/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 20.0274 - accuracy: 0.8018 - val_loss: 19.3786 - val_accuracy: 0.7565\n",
      "Epoch 612/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.8278 - accuracy: 0.7672 - val_loss: 32.9582 - val_accuracy: 0.8671\n",
      "Epoch 613/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 19.8724 - accuracy: 0.7698 - val_loss: 27.0980 - val_accuracy: 0.7808\n",
      "Epoch 614/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 20.0230 - accuracy: 0.8018 - val_loss: 22.8181 - val_accuracy: 0.7808\n",
      "Epoch 615/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.7871 - accuracy: 0.7919 - val_loss: 24.2696 - val_accuracy: 0.8147\n",
      "Epoch 616/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.3925 - accuracy: 0.7972 - val_loss: 19.7305 - val_accuracy: 0.6343\n",
      "Epoch 617/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 19.5044 - accuracy: 0.7778 - val_loss: 25.5427 - val_accuracy: 0.7614\n",
      "Epoch 618/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 20.2646 - accuracy: 0.7924 - val_loss: 21.8971 - val_accuracy: 0.8002\n",
      "Epoch 619/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 19.5484 - accuracy: 0.7824 - val_loss: 22.4974 - val_accuracy: 0.7798\n",
      "Epoch 620/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 20.0640 - accuracy: 0.7943 - val_loss: 29.8554 - val_accuracy: 0.7517\n",
      "Epoch 621/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.8787 - accuracy: 0.7861 - val_loss: 20.2288 - val_accuracy: 0.7798\n",
      "Epoch 622/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.6369 - accuracy: 0.7642 - val_loss: 16.5800 - val_accuracy: 0.7061\n",
      "Epoch 623/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.0368 - accuracy: 0.7698 - val_loss: 22.1872 - val_accuracy: 0.7934\n",
      "Epoch 624/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.4816 - accuracy: 0.8130 - val_loss: 17.6678 - val_accuracy: 0.7197\n",
      "Epoch 625/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 19.3826 - accuracy: 0.7761 - val_loss: 21.8230 - val_accuracy: 0.7759\n",
      "Epoch 626/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.6139 - accuracy: 0.7567 - val_loss: 27.8199 - val_accuracy: 0.7527\n",
      "Epoch 627/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 19.8050 - accuracy: 0.7504 - val_loss: 21.8902 - val_accuracy: 0.8371\n",
      "Epoch 628/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 19.5602 - accuracy: 0.8065 - val_loss: 32.4815 - val_accuracy: 0.7856\n",
      "Epoch 629/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.8010 - accuracy: 0.7989 - val_loss: 25.3810 - val_accuracy: 0.7633\n",
      "Epoch 630/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 19.5110 - accuracy: 0.7786 - val_loss: 28.8666 - val_accuracy: 0.7536\n",
      "Epoch 631/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.6088 - accuracy: 0.8210 - val_loss: 24.2400 - val_accuracy: 0.8070\n",
      "Epoch 632/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.4375 - accuracy: 0.8314 - val_loss: 21.5111 - val_accuracy: 0.8293\n",
      "Epoch 633/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 19.2469 - accuracy: 0.8060 - val_loss: 28.4829 - val_accuracy: 0.8361\n",
      "Epoch 634/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 19.1057 - accuracy: 0.8060 - val_loss: 27.0904 - val_accuracy: 0.7614\n",
      "Epoch 635/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 19.4635 - accuracy: 0.7960 - val_loss: 23.0051 - val_accuracy: 0.7701\n",
      "Epoch 636/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.6856 - accuracy: 0.7883 - val_loss: 23.7516 - val_accuracy: 0.8526\n",
      "Epoch 637/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 19.3224 - accuracy: 0.7965 - val_loss: 17.3173 - val_accuracy: 0.8235\n",
      "Epoch 638/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.9272 - accuracy: 0.7667 - val_loss: 15.9511 - val_accuracy: 0.8060\n",
      "Epoch 639/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 18.6592 - accuracy: 0.7861 - val_loss: 29.1452 - val_accuracy: 0.8526\n",
      "Epoch 640/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.6862 - accuracy: 0.7815 - val_loss: 25.2038 - val_accuracy: 0.7265\n",
      "Epoch 641/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 19.6505 - accuracy: 0.7892 - val_loss: 20.6125 - val_accuracy: 0.7798\n",
      "Epoch 642/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 18.7185 - accuracy: 0.7883 - val_loss: 26.9346 - val_accuracy: 0.8642\n",
      "Epoch 643/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 19.5555 - accuracy: 0.8043 - val_loss: 26.7766 - val_accuracy: 0.6887\n",
      "Epoch 644/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 19.5579 - accuracy: 0.7912 - val_loss: 35.0221 - val_accuracy: 0.6935\n",
      "Epoch 645/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.1561 - accuracy: 0.7803 - val_loss: 42.5582 - val_accuracy: 0.8293\n",
      "Epoch 646/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.9723 - accuracy: 0.7902 - val_loss: 16.2079 - val_accuracy: 0.7701\n",
      "Epoch 647/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 18.9944 - accuracy: 0.8018 - val_loss: 33.0515 - val_accuracy: 0.8584\n",
      "Epoch 648/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 19.3175 - accuracy: 0.7972 - val_loss: 30.3205 - val_accuracy: 0.7895\n",
      "Epoch 649/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 19.5856 - accuracy: 0.7963 - val_loss: 27.3315 - val_accuracy: 0.8526\n",
      "Epoch 650/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 19.3711 - accuracy: 0.8135 - val_loss: 30.3628 - val_accuracy: 0.7517\n",
      "Epoch 651/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.0082 - accuracy: 0.7992 - val_loss: 31.3909 - val_accuracy: 0.7265\n",
      "Epoch 652/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.2229 - accuracy: 0.7793 - val_loss: 21.9667 - val_accuracy: 0.8118\n",
      "Epoch 653/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.2289 - accuracy: 0.8086 - val_loss: 28.3192 - val_accuracy: 0.7701\n",
      "Epoch 654/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.8845 - accuracy: 0.8018 - val_loss: 23.2255 - val_accuracy: 0.7944\n",
      "Epoch 655/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.3429 - accuracy: 0.7820 - val_loss: 20.1769 - val_accuracy: 0.7886\n",
      "Epoch 656/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.3624 - accuracy: 0.7730 - val_loss: 22.6126 - val_accuracy: 0.8293\n",
      "Epoch 657/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.1170 - accuracy: 0.7965 - val_loss: 21.7166 - val_accuracy: 0.7711\n",
      "Epoch 658/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.3131 - accuracy: 0.7926 - val_loss: 32.4089 - val_accuracy: 0.8196\n",
      "Epoch 659/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.8100 - accuracy: 0.8096 - val_loss: 20.3770 - val_accuracy: 0.7837\n",
      "Epoch 660/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.0815 - accuracy: 0.8132 - val_loss: 29.8993 - val_accuracy: 0.7692\n",
      "Epoch 661/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.4511 - accuracy: 0.7740 - val_loss: 26.1905 - val_accuracy: 0.7391\n",
      "Epoch 662/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.0511 - accuracy: 0.7943 - val_loss: 29.1672 - val_accuracy: 0.7730\n",
      "Epoch 663/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.3371 - accuracy: 0.7754 - val_loss: 22.1635 - val_accuracy: 0.8555\n",
      "Epoch 664/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.8951 - accuracy: 0.7902 - val_loss: 24.7762 - val_accuracy: 0.7129\n",
      "Epoch 665/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.2776 - accuracy: 0.8271 - val_loss: 22.3070 - val_accuracy: 0.8526\n",
      "Epoch 666/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.4133 - accuracy: 0.8137 - val_loss: 24.8365 - val_accuracy: 0.8506\n",
      "Epoch 667/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.1481 - accuracy: 0.8399 - val_loss: 17.9840 - val_accuracy: 0.8021\n",
      "Epoch 668/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.9718 - accuracy: 0.8111 - val_loss: 28.8120 - val_accuracy: 0.7740\n",
      "Epoch 669/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.1562 - accuracy: 0.7851 - val_loss: 29.1163 - val_accuracy: 0.7876\n",
      "Epoch 670/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.2066 - accuracy: 0.8045 - val_loss: 16.5101 - val_accuracy: 0.7905\n",
      "Epoch 671/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.8800 - accuracy: 0.8217 - val_loss: 26.8297 - val_accuracy: 0.8002\n",
      "Epoch 672/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.9582 - accuracy: 0.8208 - val_loss: 20.1939 - val_accuracy: 0.7595\n",
      "Epoch 673/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.7070 - accuracy: 0.7929 - val_loss: 23.6222 - val_accuracy: 0.8371\n",
      "Epoch 674/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.9244 - accuracy: 0.8271 - val_loss: 32.0849 - val_accuracy: 0.7798\n",
      "Epoch 675/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.8824 - accuracy: 0.8140 - val_loss: 24.9203 - val_accuracy: 0.8613\n",
      "Epoch 676/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.5529 - accuracy: 0.8295 - val_loss: 23.3176 - val_accuracy: 0.7498\n",
      "Epoch 677/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.0402 - accuracy: 0.7902 - val_loss: 26.3597 - val_accuracy: 0.7682\n",
      "Epoch 678/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.0611 - accuracy: 0.8040 - val_loss: 23.8285 - val_accuracy: 0.6440\n",
      "Epoch 679/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.6753 - accuracy: 0.7863 - val_loss: 19.8579 - val_accuracy: 0.7750\n",
      "Epoch 680/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.0900 - accuracy: 0.8280 - val_loss: 23.4594 - val_accuracy: 0.7362\n",
      "Epoch 681/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.8730 - accuracy: 0.8159 - val_loss: 23.0372 - val_accuracy: 0.8487\n",
      "Epoch 682/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.2220 - accuracy: 0.8244 - val_loss: 16.1668 - val_accuracy: 0.8060\n",
      "Epoch 683/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.4376 - accuracy: 0.8023 - val_loss: 16.8666 - val_accuracy: 0.7662\n",
      "Epoch 684/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.7721 - accuracy: 0.7793 - val_loss: 24.5154 - val_accuracy: 0.8788\n",
      "Epoch 685/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 19.0877 - accuracy: 0.8375 - val_loss: 21.0871 - val_accuracy: 0.7711\n",
      "Epoch 686/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.7945 - accuracy: 0.8154 - val_loss: 26.6222 - val_accuracy: 0.7662\n",
      "Epoch 687/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.6619 - accuracy: 0.7941 - val_loss: 30.4885 - val_accuracy: 0.8700\n",
      "Epoch 688/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.3140 - accuracy: 0.8414 - val_loss: 23.7103 - val_accuracy: 0.8196\n",
      "Epoch 689/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.0003 - accuracy: 0.8193 - val_loss: 24.0423 - val_accuracy: 0.8341\n",
      "Epoch 690/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.6120 - accuracy: 0.8414 - val_loss: 15.3705 - val_accuracy: 0.8225\n",
      "Epoch 691/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.2096 - accuracy: 0.8399 - val_loss: 21.3024 - val_accuracy: 0.7692\n",
      "Epoch 692/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.1512 - accuracy: 0.8152 - val_loss: 24.1728 - val_accuracy: 0.7886\n",
      "Epoch 693/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.4467 - accuracy: 0.8227 - val_loss: 26.1210 - val_accuracy: 0.7682\n",
      "Epoch 694/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.4672 - accuracy: 0.8142 - val_loss: 27.0061 - val_accuracy: 0.8429\n",
      "Epoch 695/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.7143 - accuracy: 0.8239 - val_loss: 28.7130 - val_accuracy: 0.8458\n",
      "Epoch 696/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 19.1757 - accuracy: 0.8038 - val_loss: 31.4711 - val_accuracy: 0.7595\n",
      "Epoch 697/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.9883 - accuracy: 0.8225 - val_loss: 27.2677 - val_accuracy: 0.7032\n",
      "Epoch 698/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.7138 - accuracy: 0.8431 - val_loss: 22.9676 - val_accuracy: 0.8283\n",
      "Epoch 699/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.8396 - accuracy: 0.8302 - val_loss: 19.2539 - val_accuracy: 0.7808\n",
      "Epoch 700/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.7328 - accuracy: 0.8399 - val_loss: 25.1938 - val_accuracy: 0.8429\n",
      "Epoch 701/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.5745 - accuracy: 0.8368 - val_loss: 20.9189 - val_accuracy: 0.7633\n",
      "Epoch 702/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 18.1146 - accuracy: 0.8322 - val_loss: 28.1970 - val_accuracy: 0.7003\n",
      "Epoch 703/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.4302 - accuracy: 0.8203 - val_loss: 20.1212 - val_accuracy: 0.8458\n",
      "Epoch 704/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.5458 - accuracy: 0.8086 - val_loss: 28.5636 - val_accuracy: 0.7798\n",
      "Epoch 705/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.8003 - accuracy: 0.8428 - val_loss: 29.4584 - val_accuracy: 0.7585\n",
      "Epoch 706/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.7069 - accuracy: 0.8370 - val_loss: 20.9825 - val_accuracy: 0.8545\n",
      "Epoch 707/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.7920 - accuracy: 0.8077 - val_loss: 19.8207 - val_accuracy: 0.7507\n",
      "Epoch 708/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.6852 - accuracy: 0.8271 - val_loss: 27.5052 - val_accuracy: 0.7886\n",
      "Epoch 709/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.7473 - accuracy: 0.8438 - val_loss: 17.6183 - val_accuracy: 0.7992\n",
      "Epoch 710/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.4383 - accuracy: 0.8305 - val_loss: 28.5532 - val_accuracy: 0.8681\n",
      "Epoch 711/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.6348 - accuracy: 0.8465 - val_loss: 20.9544 - val_accuracy: 0.8312\n",
      "Epoch 712/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.7277 - accuracy: 0.8426 - val_loss: 19.6831 - val_accuracy: 0.8080\n",
      "Epoch 713/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.5406 - accuracy: 0.7917 - val_loss: 30.1414 - val_accuracy: 0.8545\n",
      "Epoch 714/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.5132 - accuracy: 0.8038 - val_loss: 24.8764 - val_accuracy: 0.7527\n",
      "Epoch 715/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.3625 - accuracy: 0.8186 - val_loss: 21.1279 - val_accuracy: 0.8632\n",
      "Epoch 716/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.7830 - accuracy: 0.8285 - val_loss: 26.7134 - val_accuracy: 0.7294\n",
      "Epoch 717/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.4473 - accuracy: 0.8324 - val_loss: 21.0486 - val_accuracy: 0.8661\n",
      "Epoch 718/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 18.5545 - accuracy: 0.8065 - val_loss: 34.8003 - val_accuracy: 0.7507\n",
      "Epoch 719/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 18.2371 - accuracy: 0.8123 - val_loss: 20.5699 - val_accuracy: 0.8691\n",
      "Epoch 720/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 18.4125 - accuracy: 0.8305 - val_loss: 17.0546 - val_accuracy: 0.8468\n",
      "Epoch 721/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 18.0654 - accuracy: 0.8246 - val_loss: 31.8126 - val_accuracy: 0.8012\n",
      "Epoch 722/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 18.4274 - accuracy: 0.8397 - val_loss: 24.7428 - val_accuracy: 0.8147\n",
      "Epoch 723/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 18.6714 - accuracy: 0.8382 - val_loss: 21.8399 - val_accuracy: 0.7808\n",
      "Epoch 724/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.1409 - accuracy: 0.8181 - val_loss: 26.0294 - val_accuracy: 0.8351\n",
      "Epoch 725/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.4741 - accuracy: 0.8179 - val_loss: 27.0890 - val_accuracy: 0.8477\n",
      "Epoch 726/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.1637 - accuracy: 0.8465 - val_loss: 19.1748 - val_accuracy: 0.8526\n",
      "Epoch 727/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.0553 - accuracy: 0.8256 - val_loss: 17.3756 - val_accuracy: 0.7604\n",
      "Epoch 728/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.2544 - accuracy: 0.8081 - val_loss: 16.4603 - val_accuracy: 0.7488\n",
      "Epoch 729/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 18.1266 - accuracy: 0.8132 - val_loss: 21.2223 - val_accuracy: 0.8012\n",
      "Epoch 730/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 18.1121 - accuracy: 0.8348 - val_loss: 27.3245 - val_accuracy: 0.8429\n",
      "Epoch 731/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 18.3922 - accuracy: 0.8179 - val_loss: 16.5182 - val_accuracy: 0.8400\n",
      "Epoch 732/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 17.9279 - accuracy: 0.8499 - val_loss: 20.9314 - val_accuracy: 0.7740\n",
      "Epoch 733/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 18.1527 - accuracy: 0.8220 - val_loss: 14.9530 - val_accuracy: 0.8458\n",
      "Epoch 734/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 17.9259 - accuracy: 0.8365 - val_loss: 20.8551 - val_accuracy: 0.8012\n",
      "Epoch 735/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.7204 - accuracy: 0.8188 - val_loss: 22.5594 - val_accuracy: 0.8380\n",
      "Epoch 736/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.3605 - accuracy: 0.8215 - val_loss: 29.0037 - val_accuracy: 0.8429\n",
      "Epoch 737/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 18.1261 - accuracy: 0.8280 - val_loss: 25.9022 - val_accuracy: 0.8594\n",
      "Epoch 738/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 18.3297 - accuracy: 0.8416 - val_loss: 15.4497 - val_accuracy: 0.8477\n",
      "Epoch 739/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 17.8761 - accuracy: 0.8225 - val_loss: 26.3545 - val_accuracy: 0.8254\n",
      "Epoch 740/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.2995 - accuracy: 0.8225 - val_loss: 22.0156 - val_accuracy: 0.8283\n",
      "Epoch 741/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.5133 - accuracy: 0.8397 - val_loss: 22.9437 - val_accuracy: 0.7798\n",
      "Epoch 742/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.7087 - accuracy: 0.8322 - val_loss: 22.0552 - val_accuracy: 0.8322\n",
      "Epoch 743/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.8495 - accuracy: 0.8380 - val_loss: 16.6791 - val_accuracy: 0.8371\n",
      "Epoch 744/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.7067 - accuracy: 0.8431 - val_loss: 24.2643 - val_accuracy: 0.8574\n",
      "Epoch 745/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.1541 - accuracy: 0.8312 - val_loss: 16.0661 - val_accuracy: 0.8128\n",
      "Epoch 746/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.0597 - accuracy: 0.8314 - val_loss: 24.3134 - val_accuracy: 0.8128\n",
      "Epoch 747/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.3916 - accuracy: 0.8455 - val_loss: 19.7355 - val_accuracy: 0.8322\n",
      "Epoch 748/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.0919 - accuracy: 0.8229 - val_loss: 22.1511 - val_accuracy: 0.7886\n",
      "Epoch 749/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.4620 - accuracy: 0.8123 - val_loss: 28.5747 - val_accuracy: 0.7090\n",
      "Epoch 750/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.0780 - accuracy: 0.8162 - val_loss: 32.5667 - val_accuracy: 0.8244\n",
      "Epoch 751/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.3814 - accuracy: 0.8370 - val_loss: 31.1012 - val_accuracy: 0.7924\n",
      "Epoch 752/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.7102 - accuracy: 0.8140 - val_loss: 22.1878 - val_accuracy: 0.8555\n",
      "Epoch 753/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.1457 - accuracy: 0.8215 - val_loss: 20.3622 - val_accuracy: 0.8429\n",
      "Epoch 754/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.9572 - accuracy: 0.8212 - val_loss: 19.5195 - val_accuracy: 0.8390\n",
      "Epoch 755/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.0337 - accuracy: 0.8494 - val_loss: 31.0386 - val_accuracy: 0.7866\n",
      "Epoch 756/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6274 - accuracy: 0.8368 - val_loss: 24.1831 - val_accuracy: 0.7992\n",
      "Epoch 757/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 18.0874 - accuracy: 0.8431 - val_loss: 30.4668 - val_accuracy: 0.8070\n",
      "Epoch 758/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.7766 - accuracy: 0.8259 - val_loss: 17.9593 - val_accuracy: 0.8836\n",
      "Epoch 759/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.2497 - accuracy: 0.8467 - val_loss: 20.2308 - val_accuracy: 0.8526\n",
      "Epoch 760/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.0917 - accuracy: 0.8523 - val_loss: 22.6641 - val_accuracy: 0.7051\n",
      "Epoch 761/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.0818 - accuracy: 0.8525 - val_loss: 26.7182 - val_accuracy: 0.8671\n",
      "Epoch 762/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.9691 - accuracy: 0.8421 - val_loss: 18.5023 - val_accuracy: 0.7769\n",
      "Epoch 763/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.7414 - accuracy: 0.8217 - val_loss: 25.7828 - val_accuracy: 0.7779\n",
      "Epoch 764/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.2808 - accuracy: 0.8392 - val_loss: 16.1200 - val_accuracy: 0.8448\n",
      "Epoch 765/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.5672 - accuracy: 0.8234 - val_loss: 27.9824 - val_accuracy: 0.8050\n",
      "Epoch 766/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.0269 - accuracy: 0.8297 - val_loss: 31.3615 - val_accuracy: 0.8691\n",
      "Epoch 767/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.8915 - accuracy: 0.8625 - val_loss: 23.1323 - val_accuracy: 0.8351\n",
      "Epoch 768/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.9115 - accuracy: 0.8421 - val_loss: 17.9760 - val_accuracy: 0.8380\n",
      "Epoch 769/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.0717 - accuracy: 0.8596 - val_loss: 22.4923 - val_accuracy: 0.8681\n",
      "Epoch 770/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.0193 - accuracy: 0.8472 - val_loss: 16.7196 - val_accuracy: 0.7721\n",
      "Epoch 771/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.7510 - accuracy: 0.8242 - val_loss: 27.8623 - val_accuracy: 0.7759\n",
      "Epoch 772/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 18.4012 - accuracy: 0.8358 - val_loss: 27.0251 - val_accuracy: 0.8681\n",
      "Epoch 773/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.9667 - accuracy: 0.8518 - val_loss: 23.9787 - val_accuracy: 0.7139\n",
      "Epoch 774/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.5655 - accuracy: 0.8239 - val_loss: 23.8917 - val_accuracy: 0.7381\n",
      "Epoch 775/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.8768 - accuracy: 0.8154 - val_loss: 21.5633 - val_accuracy: 0.8468\n",
      "Epoch 776/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.8951 - accuracy: 0.8613 - val_loss: 22.8639 - val_accuracy: 0.8555\n",
      "Epoch 777/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.9322 - accuracy: 0.8528 - val_loss: 18.5774 - val_accuracy: 0.8041\n",
      "Epoch 778/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.2446 - accuracy: 0.8280 - val_loss: 22.2399 - val_accuracy: 0.7915\n",
      "Epoch 779/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.9582 - accuracy: 0.8081 - val_loss: 28.2502 - val_accuracy: 0.8283\n",
      "Epoch 780/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.9957 - accuracy: 0.8511 - val_loss: 24.9549 - val_accuracy: 0.8235\n",
      "Epoch 781/2000\n",
      "4123/4123 [==============================] - ETA: 0s - loss: 19.5793 - accuracy: 0.856 - 0s 21us/step - loss: 17.7141 - accuracy: 0.8569 - val_loss: 26.3907 - val_accuracy: 0.8409\n",
      "Epoch 782/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.9662 - accuracy: 0.8249 - val_loss: 22.0606 - val_accuracy: 0.8274\n",
      "Epoch 783/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.2952 - accuracy: 0.8421 - val_loss: 31.8523 - val_accuracy: 0.8778\n",
      "Epoch 784/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.7716 - accuracy: 0.8188 - val_loss: 26.0295 - val_accuracy: 0.8060\n",
      "Epoch 785/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.8180 - accuracy: 0.8147 - val_loss: 20.7390 - val_accuracy: 0.7536\n",
      "Epoch 786/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.7142 - accuracy: 0.8351 - val_loss: 23.0547 - val_accuracy: 0.8497\n",
      "Epoch 787/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.5772 - accuracy: 0.8547 - val_loss: 26.3384 - val_accuracy: 0.7827\n",
      "Epoch 788/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 18.0516 - accuracy: 0.7934 - val_loss: 14.4984 - val_accuracy: 0.7856\n",
      "Epoch 789/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.2109 - accuracy: 0.8550 - val_loss: 28.6423 - val_accuracy: 0.8487\n",
      "Epoch 790/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.4993 - accuracy: 0.8329 - val_loss: 23.4803 - val_accuracy: 0.8147\n",
      "Epoch 791/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.6891 - accuracy: 0.8550 - val_loss: 17.9593 - val_accuracy: 0.8186\n",
      "Epoch 792/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.5581 - accuracy: 0.8423 - val_loss: 33.1901 - val_accuracy: 0.7459\n",
      "Epoch 793/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.6919 - accuracy: 0.8404 - val_loss: 25.4405 - val_accuracy: 0.8429\n",
      "Epoch 794/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.6692 - accuracy: 0.8423 - val_loss: 22.7217 - val_accuracy: 0.8138\n",
      "Epoch 795/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 18.0126 - accuracy: 0.8314 - val_loss: 23.2617 - val_accuracy: 0.8729\n",
      "Epoch 796/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 18.0104 - accuracy: 0.8448 - val_loss: 22.3718 - val_accuracy: 0.8409\n",
      "Epoch 797/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.7354 - accuracy: 0.8237 - val_loss: 25.1952 - val_accuracy: 0.8642\n",
      "Epoch 798/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.3692 - accuracy: 0.8336 - val_loss: 28.1161 - val_accuracy: 0.7934\n",
      "Epoch 799/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.1772 - accuracy: 0.8179 - val_loss: 21.3109 - val_accuracy: 0.8080\n",
      "Epoch 800/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 17.4863 - accuracy: 0.8501 - val_loss: 21.2594 - val_accuracy: 0.8885\n",
      "Epoch 801/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 17.5697 - accuracy: 0.8438 - val_loss: 22.4320 - val_accuracy: 0.8361\n",
      "Epoch 802/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 17.8971 - accuracy: 0.8227 - val_loss: 16.8539 - val_accuracy: 0.7750\n",
      "Epoch 803/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.1647 - accuracy: 0.8700 - val_loss: 17.8314 - val_accuracy: 0.8865\n",
      "Epoch 804/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.5642 - accuracy: 0.8593 - val_loss: 22.2581 - val_accuracy: 0.8468\n",
      "Epoch 805/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 17.4607 - accuracy: 0.8554 - val_loss: 23.4929 - val_accuracy: 0.8855\n",
      "Epoch 806/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 17.2756 - accuracy: 0.8552 - val_loss: 30.8982 - val_accuracy: 0.8244\n",
      "Epoch 807/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 17.8072 - accuracy: 0.8528 - val_loss: 20.5753 - val_accuracy: 0.8565\n",
      "Epoch 808/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.7168 - accuracy: 0.8351 - val_loss: 19.9521 - val_accuracy: 0.8526\n",
      "Epoch 809/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 16.9265 - accuracy: 0.8593 - val_loss: 23.6476 - val_accuracy: 0.8361\n",
      "Epoch 810/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.7239 - accuracy: 0.8700 - val_loss: 19.8490 - val_accuracy: 0.8758\n",
      "Epoch 811/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.4137 - accuracy: 0.8520 - val_loss: 17.7835 - val_accuracy: 0.8642\n",
      "Epoch 812/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.5914 - accuracy: 0.8470 - val_loss: 28.3105 - val_accuracy: 0.8429\n",
      "Epoch 813/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.5082 - accuracy: 0.8690 - val_loss: 29.0219 - val_accuracy: 0.8613\n",
      "Epoch 814/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.2218 - accuracy: 0.8440 - val_loss: 23.6157 - val_accuracy: 0.8089\n",
      "Epoch 815/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.6448 - accuracy: 0.8118 - val_loss: 20.1151 - val_accuracy: 0.8254\n",
      "Epoch 816/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.4411 - accuracy: 0.8360 - val_loss: 21.5686 - val_accuracy: 0.8642\n",
      "Epoch 817/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 17.1003 - accuracy: 0.8610 - val_loss: 29.9170 - val_accuracy: 0.8167\n",
      "Epoch 818/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.6323 - accuracy: 0.8508 - val_loss: 28.4475 - val_accuracy: 0.8661\n",
      "Epoch 819/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.3208 - accuracy: 0.8601 - val_loss: 17.3031 - val_accuracy: 0.8526\n",
      "Epoch 820/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 17.1753 - accuracy: 0.8508 - val_loss: 27.5378 - val_accuracy: 0.8613\n",
      "Epoch 821/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.4710 - accuracy: 0.8448 - val_loss: 28.3530 - val_accuracy: 0.8817\n",
      "Epoch 822/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 17.5357 - accuracy: 0.8457 - val_loss: 25.1399 - val_accuracy: 0.7953\n",
      "Epoch 823/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 17.5870 - accuracy: 0.8656 - val_loss: 22.6763 - val_accuracy: 0.8244\n",
      "Epoch 824/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 17.3093 - accuracy: 0.8625 - val_loss: 25.2898 - val_accuracy: 0.8836\n",
      "Epoch 825/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.6742 - accuracy: 0.8528 - val_loss: 17.1678 - val_accuracy: 0.8390\n",
      "Epoch 826/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.2723 - accuracy: 0.8467 - val_loss: 22.0152 - val_accuracy: 0.8623\n",
      "Epoch 827/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.1267 - accuracy: 0.8520 - val_loss: 23.3371 - val_accuracy: 0.8002\n",
      "Epoch 828/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.8608 - accuracy: 0.8467 - val_loss: 22.1089 - val_accuracy: 0.7876\n",
      "Epoch 829/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 17.1348 - accuracy: 0.8205 - val_loss: 14.8006 - val_accuracy: 0.8758\n",
      "Epoch 830/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 17.1009 - accuracy: 0.8520 - val_loss: 21.2113 - val_accuracy: 0.8681\n",
      "Epoch 831/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.2929 - accuracy: 0.8591 - val_loss: 26.9241 - val_accuracy: 0.8632\n",
      "Epoch 832/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.7142 - accuracy: 0.8460 - val_loss: 24.2896 - val_accuracy: 0.7585\n",
      "Epoch 833/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.6166 - accuracy: 0.8018 - val_loss: 21.5980 - val_accuracy: 0.8846\n",
      "Epoch 834/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.3026 - accuracy: 0.8717 - val_loss: 15.9622 - val_accuracy: 0.8516\n",
      "Epoch 835/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.1352 - accuracy: 0.8487 - val_loss: 17.8999 - val_accuracy: 0.8477\n",
      "Epoch 836/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.3334 - accuracy: 0.8499 - val_loss: 23.0501 - val_accuracy: 0.8138\n",
      "Epoch 837/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.4697 - accuracy: 0.8273 - val_loss: 22.8880 - val_accuracy: 0.8778\n",
      "Epoch 838/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.3574 - accuracy: 0.8598 - val_loss: 23.0698 - val_accuracy: 0.7837\n",
      "Epoch 839/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.4472 - accuracy: 0.8656 - val_loss: 17.7659 - val_accuracy: 0.8526\n",
      "Epoch 840/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.1772 - accuracy: 0.8644 - val_loss: 20.2928 - val_accuracy: 0.8632\n",
      "Epoch 841/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.1508 - accuracy: 0.8671 - val_loss: 17.9578 - val_accuracy: 0.8681\n",
      "Epoch 842/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.4759 - accuracy: 0.8038 - val_loss: 26.8487 - val_accuracy: 0.7876\n",
      "Epoch 843/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.4567 - accuracy: 0.8588 - val_loss: 28.9308 - val_accuracy: 0.8516\n",
      "Epoch 844/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.9887 - accuracy: 0.8581 - val_loss: 23.0095 - val_accuracy: 0.8545\n",
      "Epoch 845/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.2964 - accuracy: 0.8385 - val_loss: 29.5433 - val_accuracy: 0.8885\n",
      "Epoch 846/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.3027 - accuracy: 0.8678 - val_loss: 22.6933 - val_accuracy: 0.8458\n",
      "Epoch 847/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.7137 - accuracy: 0.8431 - val_loss: 24.3703 - val_accuracy: 0.8691\n",
      "Epoch 848/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 17.3416 - accuracy: 0.8591 - val_loss: 24.6118 - val_accuracy: 0.8817\n",
      "Epoch 849/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.9694 - accuracy: 0.8484 - val_loss: 26.4726 - val_accuracy: 0.8526\n",
      "Epoch 850/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.7323 - accuracy: 0.8632 - val_loss: 22.2546 - val_accuracy: 0.8603\n",
      "Epoch 851/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.7371 - accuracy: 0.8516 - val_loss: 17.1367 - val_accuracy: 0.8477\n",
      "Epoch 852/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 17.2852 - accuracy: 0.8482 - val_loss: 28.9437 - val_accuracy: 0.8487\n",
      "Epoch 853/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 17.2128 - accuracy: 0.8479 - val_loss: 25.0233 - val_accuracy: 0.7633\n",
      "Epoch 854/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 17.2076 - accuracy: 0.8487 - val_loss: 16.9226 - val_accuracy: 0.8875\n",
      "Epoch 855/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.0154 - accuracy: 0.8559 - val_loss: 22.6197 - val_accuracy: 0.8729\n",
      "Epoch 856/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.7014 - accuracy: 0.8266 - val_loss: 26.2105 - val_accuracy: 0.8555\n",
      "Epoch 857/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.7848 - accuracy: 0.8506 - val_loss: 20.6827 - val_accuracy: 0.8788\n",
      "Epoch 858/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.4021 - accuracy: 0.8462 - val_loss: 23.8846 - val_accuracy: 0.8865\n",
      "Epoch 859/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.0471 - accuracy: 0.8639 - val_loss: 16.4724 - val_accuracy: 0.8700\n",
      "Epoch 860/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 17.1016 - accuracy: 0.8622 - val_loss: 22.9779 - val_accuracy: 0.8458\n",
      "Epoch 861/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6772 - accuracy: 0.8176 - val_loss: 25.2576 - val_accuracy: 0.8438\n",
      "Epoch 862/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.2109 - accuracy: 0.8727 - val_loss: 23.6834 - val_accuracy: 0.8603\n",
      "Epoch 863/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.2453 - accuracy: 0.8559 - val_loss: 23.9743 - val_accuracy: 0.8574\n",
      "Epoch 864/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.6632 - accuracy: 0.8634 - val_loss: 18.3258 - val_accuracy: 0.8623\n",
      "Epoch 865/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6758 - accuracy: 0.8622 - val_loss: 19.2872 - val_accuracy: 0.8914\n",
      "Epoch 866/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.2197 - accuracy: 0.8717 - val_loss: 22.9326 - val_accuracy: 0.8341\n",
      "Epoch 867/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.0654 - accuracy: 0.8705 - val_loss: 19.4713 - val_accuracy: 0.8603\n",
      "Epoch 868/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.9189 - accuracy: 0.8724 - val_loss: 17.0110 - val_accuracy: 0.8817\n",
      "Epoch 869/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.1629 - accuracy: 0.8596 - val_loss: 21.1681 - val_accuracy: 0.8623\n",
      "Epoch 870/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.9554 - accuracy: 0.8419 - val_loss: 17.5831 - val_accuracy: 0.8526\n",
      "Epoch 871/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.1400 - accuracy: 0.8525 - val_loss: 18.9457 - val_accuracy: 0.8681\n",
      "Epoch 872/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.4517 - accuracy: 0.8482 - val_loss: 22.4473 - val_accuracy: 0.8206\n",
      "Epoch 873/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.2428 - accuracy: 0.8676 - val_loss: 15.8080 - val_accuracy: 0.8875\n",
      "Epoch 874/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.6833 - accuracy: 0.8588 - val_loss: 25.7803 - val_accuracy: 0.8758\n",
      "Epoch 875/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.0310 - accuracy: 0.8637 - val_loss: 24.3141 - val_accuracy: 0.8584\n",
      "Epoch 876/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6632 - accuracy: 0.8654 - val_loss: 16.2147 - val_accuracy: 0.8768\n",
      "Epoch 877/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8487 - accuracy: 0.8545 - val_loss: 19.1223 - val_accuracy: 0.8138\n",
      "Epoch 878/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.1905 - accuracy: 0.8518 - val_loss: 17.8835 - val_accuracy: 0.8855\n",
      "Epoch 879/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.9882 - accuracy: 0.8710 - val_loss: 26.8066 - val_accuracy: 0.8700\n",
      "Epoch 880/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.0471 - accuracy: 0.8603 - val_loss: 26.3539 - val_accuracy: 0.7614\n",
      "Epoch 881/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.7740 - accuracy: 0.8702 - val_loss: 29.5841 - val_accuracy: 0.8535\n",
      "Epoch 882/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.3376 - accuracy: 0.8605 - val_loss: 23.8362 - val_accuracy: 0.8710\n",
      "Epoch 883/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.1595 - accuracy: 0.8598 - val_loss: 15.0793 - val_accuracy: 0.8526\n",
      "Epoch 884/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.4546 - accuracy: 0.8579 - val_loss: 26.4799 - val_accuracy: 0.8497\n",
      "Epoch 885/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8398 - accuracy: 0.8642 - val_loss: 15.5480 - val_accuracy: 0.8778\n",
      "Epoch 886/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.7106 - accuracy: 0.8537 - val_loss: 24.2341 - val_accuracy: 0.8807\n",
      "Epoch 887/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.2210 - accuracy: 0.8668 - val_loss: 22.3664 - val_accuracy: 0.8109\n",
      "Epoch 888/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.1248 - accuracy: 0.8608 - val_loss: 24.6784 - val_accuracy: 0.7430\n",
      "Epoch 889/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 17.1992 - accuracy: 0.8113 - val_loss: 26.7377 - val_accuracy: 0.8671\n",
      "Epoch 890/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.1805 - accuracy: 0.8695 - val_loss: 21.2382 - val_accuracy: 0.8555\n",
      "Epoch 891/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.9318 - accuracy: 0.8504 - val_loss: 27.3948 - val_accuracy: 0.7750\n",
      "Epoch 892/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8983 - accuracy: 0.8525 - val_loss: 23.4567 - val_accuracy: 0.8021\n",
      "Epoch 893/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.1348 - accuracy: 0.8596 - val_loss: 21.8107 - val_accuracy: 0.8089\n",
      "Epoch 894/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 17.0210 - accuracy: 0.8445 - val_loss: 25.2106 - val_accuracy: 0.7837\n",
      "Epoch 895/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.9554 - accuracy: 0.8326 - val_loss: 25.1063 - val_accuracy: 0.8419\n",
      "Epoch 896/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.6331 - accuracy: 0.8756 - val_loss: 25.3047 - val_accuracy: 0.8652\n",
      "Epoch 897/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 17.2466 - accuracy: 0.8693 - val_loss: 19.9487 - val_accuracy: 0.8972\n",
      "Epoch 898/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.6740 - accuracy: 0.8637 - val_loss: 23.0320 - val_accuracy: 0.8332\n",
      "Epoch 899/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.1412 - accuracy: 0.8693 - val_loss: 15.6828 - val_accuracy: 0.8797\n",
      "Epoch 900/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3625 - accuracy: 0.8554 - val_loss: 22.0584 - val_accuracy: 0.8196\n",
      "Epoch 901/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.9798 - accuracy: 0.8724 - val_loss: 16.5147 - val_accuracy: 0.8788\n",
      "Epoch 902/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.7600 - accuracy: 0.8734 - val_loss: 18.2376 - val_accuracy: 0.8661\n",
      "Epoch 903/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.9586 - accuracy: 0.8455 - val_loss: 19.8624 - val_accuracy: 0.8545\n",
      "Epoch 904/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.4370 - accuracy: 0.8666 - val_loss: 24.4555 - val_accuracy: 0.8506\n",
      "Epoch 905/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.1223 - accuracy: 0.8547 - val_loss: 21.7697 - val_accuracy: 0.8458\n",
      "Epoch 906/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6556 - accuracy: 0.8567 - val_loss: 24.2098 - val_accuracy: 0.7856\n",
      "Epoch 907/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.9586 - accuracy: 0.8416 - val_loss: 24.6400 - val_accuracy: 0.8477\n",
      "Epoch 908/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.9277 - accuracy: 0.8540 - val_loss: 29.2238 - val_accuracy: 0.8535\n",
      "Epoch 909/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.7118 - accuracy: 0.8588 - val_loss: 21.6039 - val_accuracy: 0.7944\n",
      "Epoch 910/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5590 - accuracy: 0.8567 - val_loss: 27.7125 - val_accuracy: 0.7963\n",
      "Epoch 911/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.9478 - accuracy: 0.8683 - val_loss: 17.1014 - val_accuracy: 0.7672\n",
      "Epoch 912/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8982 - accuracy: 0.8562 - val_loss: 19.5047 - val_accuracy: 0.9001\n",
      "Epoch 913/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.7777 - accuracy: 0.8547 - val_loss: 20.6349 - val_accuracy: 0.8506\n",
      "Epoch 914/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.4446 - accuracy: 0.8533 - val_loss: 28.4886 - val_accuracy: 0.8109\n",
      "Epoch 915/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.7872 - accuracy: 0.8753 - val_loss: 20.7168 - val_accuracy: 0.8894\n",
      "Epoch 916/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.0142 - accuracy: 0.8474 - val_loss: 17.4663 - val_accuracy: 0.8681\n",
      "Epoch 917/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.9814 - accuracy: 0.8501 - val_loss: 23.0281 - val_accuracy: 0.7187\n",
      "Epoch 918/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.8875 - accuracy: 0.8537 - val_loss: 21.9399 - val_accuracy: 0.8749\n",
      "Epoch 919/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.7253 - accuracy: 0.8717 - val_loss: 25.8136 - val_accuracy: 0.8390\n",
      "Epoch 920/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.4269 - accuracy: 0.8414 - val_loss: 17.4414 - val_accuracy: 0.8516\n",
      "Epoch 921/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.4700 - accuracy: 0.8610 - val_loss: 24.0211 - val_accuracy: 0.8613\n",
      "Epoch 922/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.8567 - accuracy: 0.8644 - val_loss: 23.0888 - val_accuracy: 0.8555\n",
      "Epoch 923/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 17.0318 - accuracy: 0.8647 - val_loss: 25.5524 - val_accuracy: 0.8109\n",
      "Epoch 924/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.4541 - accuracy: 0.8564 - val_loss: 20.7930 - val_accuracy: 0.8477\n",
      "Epoch 925/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3364 - accuracy: 0.8375 - val_loss: 21.2373 - val_accuracy: 0.7769\n",
      "Epoch 926/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.2053 - accuracy: 0.8499 - val_loss: 23.6021 - val_accuracy: 0.8429\n",
      "Epoch 927/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.9675 - accuracy: 0.8719 - val_loss: 21.7016 - val_accuracy: 0.8749\n",
      "Epoch 928/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.5742 - accuracy: 0.8673 - val_loss: 17.7168 - val_accuracy: 0.8729\n",
      "Epoch 929/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8126 - accuracy: 0.8341 - val_loss: 18.3994 - val_accuracy: 0.8788\n",
      "Epoch 930/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.6343 - accuracy: 0.8821 - val_loss: 15.0794 - val_accuracy: 0.8448\n",
      "Epoch 931/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8223 - accuracy: 0.8695 - val_loss: 22.1048 - val_accuracy: 0.8778\n",
      "Epoch 932/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6101 - accuracy: 0.8375 - val_loss: 24.0744 - val_accuracy: 0.7692\n",
      "Epoch 933/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.7997 - accuracy: 0.8479 - val_loss: 23.0440 - val_accuracy: 0.6537\n",
      "Epoch 934/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.3885 - accuracy: 0.8242 - val_loss: 18.8945 - val_accuracy: 0.8458\n",
      "Epoch 935/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8910 - accuracy: 0.8649 - val_loss: 16.9137 - val_accuracy: 0.7992\n",
      "Epoch 936/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3357 - accuracy: 0.8346 - val_loss: 28.1730 - val_accuracy: 0.8613\n",
      "Epoch 937/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.8707 - accuracy: 0.8778 - val_loss: 24.3164 - val_accuracy: 0.8138\n",
      "Epoch 938/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.9800 - accuracy: 0.8693 - val_loss: 23.2429 - val_accuracy: 0.8652\n",
      "Epoch 939/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.8514 - accuracy: 0.8841 - val_loss: 22.8426 - val_accuracy: 0.8632\n",
      "Epoch 940/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.0448 - accuracy: 0.8853 - val_loss: 24.1406 - val_accuracy: 0.8788\n",
      "Epoch 941/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8515 - accuracy: 0.8564 - val_loss: 27.8197 - val_accuracy: 0.8632\n",
      "Epoch 942/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2070 - accuracy: 0.8511 - val_loss: 18.9366 - val_accuracy: 0.8497\n",
      "Epoch 943/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8452 - accuracy: 0.8666 - val_loss: 18.0623 - val_accuracy: 0.8885\n",
      "Epoch 944/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.2965 - accuracy: 0.8685 - val_loss: 22.9738 - val_accuracy: 0.8855\n",
      "Epoch 945/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.7214 - accuracy: 0.8588 - val_loss: 17.7488 - val_accuracy: 0.8613\n",
      "Epoch 946/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 17.0240 - accuracy: 0.8613 - val_loss: 25.3302 - val_accuracy: 0.8235\n",
      "Epoch 947/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8895 - accuracy: 0.8654 - val_loss: 20.1796 - val_accuracy: 0.8215\n",
      "Epoch 948/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 17.0190 - accuracy: 0.8651 - val_loss: 16.8471 - val_accuracy: 0.8050\n",
      "Epoch 949/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6033 - accuracy: 0.8756 - val_loss: 18.9784 - val_accuracy: 0.8681\n",
      "Epoch 950/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6960 - accuracy: 0.8698 - val_loss: 26.4571 - val_accuracy: 0.8555\n",
      "Epoch 951/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2443 - accuracy: 0.8656 - val_loss: 20.3188 - val_accuracy: 0.8807\n",
      "Epoch 952/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.3517 - accuracy: 0.8758 - val_loss: 22.7731 - val_accuracy: 0.8613\n",
      "Epoch 953/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.7472 - accuracy: 0.8533 - val_loss: 26.1115 - val_accuracy: 0.8623\n",
      "Epoch 954/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.9207 - accuracy: 0.8688 - val_loss: 22.2362 - val_accuracy: 0.8904\n",
      "Epoch 955/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.5998 - accuracy: 0.8804 - val_loss: 22.4422 - val_accuracy: 0.8206\n",
      "Epoch 956/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6542 - accuracy: 0.8683 - val_loss: 18.8100 - val_accuracy: 0.8836\n",
      "Epoch 957/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.6003 - accuracy: 0.8729 - val_loss: 17.0544 - val_accuracy: 0.8361\n",
      "Epoch 958/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.6122 - accuracy: 0.8613 - val_loss: 14.7340 - val_accuracy: 0.7769\n",
      "Epoch 959/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9839 - accuracy: 0.8183 - val_loss: 20.5538 - val_accuracy: 0.8691\n",
      "Epoch 960/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.8337 - accuracy: 0.8613 - val_loss: 26.2600 - val_accuracy: 0.8380\n",
      "Epoch 961/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8980 - accuracy: 0.8581 - val_loss: 18.6076 - val_accuracy: 0.8933\n",
      "Epoch 962/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8752 - accuracy: 0.8654 - val_loss: 18.0504 - val_accuracy: 0.8700\n",
      "Epoch 963/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6939 - accuracy: 0.8671 - val_loss: 24.3837 - val_accuracy: 0.8632\n",
      "Epoch 964/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.8374 - accuracy: 0.8712 - val_loss: 18.4286 - val_accuracy: 0.8661\n",
      "Epoch 965/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.6692 - accuracy: 0.8758 - val_loss: 17.3013 - val_accuracy: 0.8691\n",
      "Epoch 966/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.2236 - accuracy: 0.8630 - val_loss: 25.8626 - val_accuracy: 0.7905\n",
      "Epoch 967/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.9655 - accuracy: 0.8613 - val_loss: 22.6069 - val_accuracy: 0.8186\n",
      "Epoch 968/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.7206 - accuracy: 0.8613 - val_loss: 22.5775 - val_accuracy: 0.8545\n",
      "Epoch 969/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.6828 - accuracy: 0.8632 - val_loss: 23.7020 - val_accuracy: 0.8642\n",
      "Epoch 970/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6739 - accuracy: 0.8562 - val_loss: 23.3640 - val_accuracy: 0.8904\n",
      "Epoch 971/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5659 - accuracy: 0.8741 - val_loss: 22.1290 - val_accuracy: 0.8409\n",
      "Epoch 972/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.2340 - accuracy: 0.8613 - val_loss: 28.9929 - val_accuracy: 0.8225\n",
      "Epoch 973/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 17.1395 - accuracy: 0.8758 - val_loss: 20.1774 - val_accuracy: 0.8215\n",
      "Epoch 974/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.4519 - accuracy: 0.8668 - val_loss: 22.1683 - val_accuracy: 0.8700\n",
      "Epoch 975/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.6392 - accuracy: 0.8719 - val_loss: 15.2117 - val_accuracy: 0.8778\n",
      "Epoch 976/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1912 - accuracy: 0.8569 - val_loss: 25.4841 - val_accuracy: 0.8691\n",
      "Epoch 977/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5615 - accuracy: 0.8850 - val_loss: 20.8965 - val_accuracy: 0.8962\n",
      "Epoch 978/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.3483 - accuracy: 0.8528 - val_loss: 20.5396 - val_accuracy: 0.8768\n",
      "Epoch 979/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6974 - accuracy: 0.8831 - val_loss: 26.2252 - val_accuracy: 0.8982\n",
      "Epoch 980/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.7939 - accuracy: 0.8547 - val_loss: 24.1906 - val_accuracy: 0.7895\n",
      "Epoch 981/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0798 - accuracy: 0.8448 - val_loss: 17.2539 - val_accuracy: 0.8691\n",
      "Epoch 982/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2392 - accuracy: 0.8450 - val_loss: 24.5949 - val_accuracy: 0.7284\n",
      "Epoch 983/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9333 - accuracy: 0.8518 - val_loss: 15.0501 - val_accuracy: 0.8623\n",
      "Epoch 984/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.2381 - accuracy: 0.8569 - val_loss: 15.3139 - val_accuracy: 0.8254\n",
      "Epoch 985/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.0721 - accuracy: 0.8732 - val_loss: 24.0315 - val_accuracy: 0.8477\n",
      "Epoch 986/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.6101 - accuracy: 0.8770 - val_loss: 23.9895 - val_accuracy: 0.8691\n",
      "Epoch 987/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6128 - accuracy: 0.8768 - val_loss: 24.2763 - val_accuracy: 0.8555\n",
      "Epoch 988/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6555 - accuracy: 0.8598 - val_loss: 16.0022 - val_accuracy: 0.8361\n",
      "Epoch 989/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.1621 - accuracy: 0.8836 - val_loss: 24.3833 - val_accuracy: 0.8487\n",
      "Epoch 990/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.8989 - accuracy: 0.8736 - val_loss: 24.2573 - val_accuracy: 0.8836\n",
      "Epoch 991/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.5869 - accuracy: 0.8651 - val_loss: 20.6487 - val_accuracy: 0.7963\n",
      "Epoch 992/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.6728 - accuracy: 0.8746 - val_loss: 22.5481 - val_accuracy: 0.8147\n",
      "Epoch 993/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 16.6264 - accuracy: 0.8647 - val_loss: 25.2751 - val_accuracy: 0.7633\n",
      "Epoch 994/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.7972 - accuracy: 0.8593 - val_loss: 21.3487 - val_accuracy: 0.8933\n",
      "Epoch 995/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.3463 - accuracy: 0.8508 - val_loss: 17.3206 - val_accuracy: 0.8099\n",
      "Epoch 996/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5609 - accuracy: 0.8654 - val_loss: 21.0205 - val_accuracy: 0.7789\n",
      "Epoch 997/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3476 - accuracy: 0.8632 - val_loss: 26.9575 - val_accuracy: 0.8215\n",
      "Epoch 998/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.4028 - accuracy: 0.8448 - val_loss: 21.9465 - val_accuracy: 0.8264\n",
      "Epoch 999/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5898 - accuracy: 0.8719 - val_loss: 32.9811 - val_accuracy: 0.8041\n",
      "Epoch 1000/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5666 - accuracy: 0.8659 - val_loss: 21.6527 - val_accuracy: 0.8574\n",
      "Epoch 1001/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.9653 - accuracy: 0.8712 - val_loss: 26.2830 - val_accuracy: 0.8846\n",
      "Epoch 1002/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.8789 - accuracy: 0.8782 - val_loss: 18.3674 - val_accuracy: 0.8594\n",
      "Epoch 1003/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.4580 - accuracy: 0.8702 - val_loss: 22.2032 - val_accuracy: 0.8341\n",
      "Epoch 1004/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.8015 - accuracy: 0.8681 - val_loss: 23.0844 - val_accuracy: 0.8991\n",
      "Epoch 1005/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.6516 - accuracy: 0.8812 - val_loss: 23.7794 - val_accuracy: 0.8448\n",
      "Epoch 1006/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.6281 - accuracy: 0.8608 - val_loss: 24.9697 - val_accuracy: 0.7924\n",
      "Epoch 1007/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5865 - accuracy: 0.8494 - val_loss: 23.7693 - val_accuracy: 0.8361\n",
      "Epoch 1008/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.3531 - accuracy: 0.8455 - val_loss: 18.6260 - val_accuracy: 0.8904\n",
      "Epoch 1009/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6495 - accuracy: 0.8625 - val_loss: 24.5595 - val_accuracy: 0.8574\n",
      "Epoch 1010/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.2072 - accuracy: 0.8727 - val_loss: 25.8720 - val_accuracy: 0.8778\n",
      "Epoch 1011/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3937 - accuracy: 0.8598 - val_loss: 22.8704 - val_accuracy: 0.8632\n",
      "Epoch 1012/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3135 - accuracy: 0.8700 - val_loss: 16.8234 - val_accuracy: 0.8729\n",
      "Epoch 1013/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1960 - accuracy: 0.8729 - val_loss: 25.5593 - val_accuracy: 0.7604\n",
      "Epoch 1014/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.8933 - accuracy: 0.8605 - val_loss: 27.1692 - val_accuracy: 0.7866\n",
      "Epoch 1015/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.5651 - accuracy: 0.8717 - val_loss: 25.1797 - val_accuracy: 0.8283\n",
      "Epoch 1016/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.4329 - accuracy: 0.8664 - val_loss: 22.1996 - val_accuracy: 0.6984\n",
      "Epoch 1017/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6618 - accuracy: 0.8693 - val_loss: 16.1670 - val_accuracy: 0.8788\n",
      "Epoch 1018/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2715 - accuracy: 0.8860 - val_loss: 23.0730 - val_accuracy: 0.8720\n",
      "Epoch 1019/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6061 - accuracy: 0.8744 - val_loss: 21.6406 - val_accuracy: 0.8603\n",
      "Epoch 1020/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5802 - accuracy: 0.8656 - val_loss: 21.7396 - val_accuracy: 0.8768\n",
      "Epoch 1021/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.2110 - accuracy: 0.8710 - val_loss: 22.2495 - val_accuracy: 0.8603\n",
      "Epoch 1022/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.5458 - accuracy: 0.8763 - val_loss: 16.2701 - val_accuracy: 0.8739\n",
      "Epoch 1023/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.2450 - accuracy: 0.8705 - val_loss: 22.9541 - val_accuracy: 0.8322\n",
      "Epoch 1024/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.7171 - accuracy: 0.8537 - val_loss: 21.6296 - val_accuracy: 0.8768\n",
      "Epoch 1025/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.3208 - accuracy: 0.8630 - val_loss: 24.5144 - val_accuracy: 0.7556\n",
      "Epoch 1026/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 16.5443 - accuracy: 0.8520 - val_loss: 31.0868 - val_accuracy: 0.8691\n",
      "Epoch 1027/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.7271 - accuracy: 0.8666 - val_loss: 19.4672 - val_accuracy: 0.8807\n",
      "Epoch 1028/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0486 - accuracy: 0.8605 - val_loss: 17.2693 - val_accuracy: 0.8167\n",
      "Epoch 1029/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.5739 - accuracy: 0.8639 - val_loss: 26.4591 - val_accuracy: 0.8661\n",
      "Epoch 1030/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.4238 - accuracy: 0.8732 - val_loss: 22.0034 - val_accuracy: 0.8846\n",
      "Epoch 1031/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5730 - accuracy: 0.8729 - val_loss: 25.9002 - val_accuracy: 0.8312\n",
      "Epoch 1032/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.4458 - accuracy: 0.8499 - val_loss: 26.6050 - val_accuracy: 0.8322\n",
      "Epoch 1033/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1946 - accuracy: 0.8748 - val_loss: 15.4890 - val_accuracy: 0.8758\n",
      "Epoch 1034/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.4838 - accuracy: 0.8710 - val_loss: 15.4614 - val_accuracy: 0.8758\n",
      "Epoch 1035/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1774 - accuracy: 0.8676 - val_loss: 27.1087 - val_accuracy: 0.8380\n",
      "Epoch 1036/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7819 - accuracy: 0.8470 - val_loss: 23.5882 - val_accuracy: 0.8933\n",
      "Epoch 1037/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.4465 - accuracy: 0.8765 - val_loss: 17.1401 - val_accuracy: 0.8904\n",
      "Epoch 1038/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.4613 - accuracy: 0.8727 - val_loss: 18.5841 - val_accuracy: 0.8758\n",
      "Epoch 1039/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5205 - accuracy: 0.8620 - val_loss: 25.0905 - val_accuracy: 0.8623\n",
      "Epoch 1040/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.3977 - accuracy: 0.8804 - val_loss: 23.6498 - val_accuracy: 0.8758\n",
      "Epoch 1041/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7703 - accuracy: 0.8579 - val_loss: 21.7313 - val_accuracy: 0.8642\n",
      "Epoch 1042/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.4569 - accuracy: 0.8613 - val_loss: 25.4550 - val_accuracy: 0.7798\n",
      "Epoch 1043/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.7587 - accuracy: 0.8661 - val_loss: 18.6098 - val_accuracy: 0.8448\n",
      "Epoch 1044/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1733 - accuracy: 0.8758 - val_loss: 20.4291 - val_accuracy: 0.8720\n",
      "Epoch 1045/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3282 - accuracy: 0.8579 - val_loss: 22.5422 - val_accuracy: 0.8535\n",
      "Epoch 1046/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1862 - accuracy: 0.8734 - val_loss: 20.8288 - val_accuracy: 0.8632\n",
      "Epoch 1047/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.1672 - accuracy: 0.8448 - val_loss: 27.5241 - val_accuracy: 0.8652\n",
      "Epoch 1048/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3422 - accuracy: 0.8739 - val_loss: 21.7811 - val_accuracy: 0.8778\n",
      "Epoch 1049/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6084 - accuracy: 0.8666 - val_loss: 25.9151 - val_accuracy: 0.8371\n",
      "Epoch 1050/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.5983 - accuracy: 0.8802 - val_loss: 25.2965 - val_accuracy: 0.8807\n",
      "Epoch 1051/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2969 - accuracy: 0.8688 - val_loss: 26.2742 - val_accuracy: 0.8623\n",
      "Epoch 1052/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1212 - accuracy: 0.8615 - val_loss: 20.8205 - val_accuracy: 0.8458\n",
      "Epoch 1053/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3494 - accuracy: 0.8465 - val_loss: 22.4760 - val_accuracy: 0.8341\n",
      "Epoch 1054/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2809 - accuracy: 0.8695 - val_loss: 25.5120 - val_accuracy: 0.8826\n",
      "Epoch 1055/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.6113 - accuracy: 0.8778 - val_loss: 22.1342 - val_accuracy: 0.8506\n",
      "Epoch 1056/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.2396 - accuracy: 0.8625 - val_loss: 19.4058 - val_accuracy: 0.8661\n",
      "Epoch 1057/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.4187 - accuracy: 0.8770 - val_loss: 15.2892 - val_accuracy: 0.8836\n",
      "Epoch 1058/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9640 - accuracy: 0.8545 - val_loss: 27.1806 - val_accuracy: 0.8758\n",
      "Epoch 1059/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.2670 - accuracy: 0.8693 - val_loss: 19.8464 - val_accuracy: 0.8952\n",
      "Epoch 1060/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3467 - accuracy: 0.8739 - val_loss: 20.7452 - val_accuracy: 0.8322\n",
      "Epoch 1061/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9973 - accuracy: 0.8673 - val_loss: 28.0548 - val_accuracy: 0.8409\n",
      "Epoch 1062/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.2162 - accuracy: 0.8707 - val_loss: 20.2382 - val_accuracy: 0.8914\n",
      "Epoch 1063/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2468 - accuracy: 0.8821 - val_loss: 22.1856 - val_accuracy: 0.8855\n",
      "Epoch 1064/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5336 - accuracy: 0.8724 - val_loss: 20.6685 - val_accuracy: 0.7876\n",
      "Epoch 1065/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.2903 - accuracy: 0.8778 - val_loss: 20.0407 - val_accuracy: 0.8758\n",
      "Epoch 1066/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2981 - accuracy: 0.8695 - val_loss: 17.4803 - val_accuracy: 0.8826\n",
      "Epoch 1067/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3808 - accuracy: 0.8525 - val_loss: 16.5521 - val_accuracy: 0.8516\n",
      "Epoch 1068/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0496 - accuracy: 0.8860 - val_loss: 22.3766 - val_accuracy: 0.8894\n",
      "Epoch 1069/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3822 - accuracy: 0.8792 - val_loss: 17.7194 - val_accuracy: 0.8468\n",
      "Epoch 1070/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2438 - accuracy: 0.8782 - val_loss: 22.0177 - val_accuracy: 0.8710\n",
      "Epoch 1071/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.4473 - accuracy: 0.8719 - val_loss: 23.8063 - val_accuracy: 0.8274\n",
      "Epoch 1072/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5504 - accuracy: 0.8620 - val_loss: 18.9055 - val_accuracy: 0.8836\n",
      "Epoch 1073/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.2210 - accuracy: 0.8506 - val_loss: 22.8702 - val_accuracy: 0.8739\n",
      "Epoch 1074/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6625 - accuracy: 0.8785 - val_loss: 24.9100 - val_accuracy: 0.8758\n",
      "Epoch 1075/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1712 - accuracy: 0.8855 - val_loss: 17.5607 - val_accuracy: 0.8817\n",
      "Epoch 1076/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2416 - accuracy: 0.8627 - val_loss: 20.9851 - val_accuracy: 0.8099\n",
      "Epoch 1077/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.0568 - accuracy: 0.8586 - val_loss: 23.7264 - val_accuracy: 0.7953\n",
      "Epoch 1078/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1572 - accuracy: 0.8528 - val_loss: 21.9890 - val_accuracy: 0.8215\n",
      "Epoch 1079/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2922 - accuracy: 0.8598 - val_loss: 18.8595 - val_accuracy: 0.8894\n",
      "Epoch 1080/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7111 - accuracy: 0.8775 - val_loss: 23.9099 - val_accuracy: 0.8448\n",
      "Epoch 1081/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2666 - accuracy: 0.8656 - val_loss: 19.6033 - val_accuracy: 0.8788\n",
      "Epoch 1082/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.3705 - accuracy: 0.8753 - val_loss: 26.6961 - val_accuracy: 0.8729\n",
      "Epoch 1083/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.7484 - accuracy: 0.8550 - val_loss: 17.7830 - val_accuracy: 0.8506\n",
      "Epoch 1084/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8098 - accuracy: 0.8702 - val_loss: 21.0618 - val_accuracy: 0.9079\n",
      "Epoch 1085/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.0805 - accuracy: 0.8838 - val_loss: 23.4280 - val_accuracy: 0.8681\n",
      "Epoch 1086/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.5889 - accuracy: 0.8751 - val_loss: 28.2628 - val_accuracy: 0.8138\n",
      "Epoch 1087/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9387 - accuracy: 0.8603 - val_loss: 19.4351 - val_accuracy: 0.8729\n",
      "Epoch 1088/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.6995 - accuracy: 0.8729 - val_loss: 23.0657 - val_accuracy: 0.8642\n",
      "Epoch 1089/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.3247 - accuracy: 0.8892 - val_loss: 19.6374 - val_accuracy: 0.8875\n",
      "Epoch 1090/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.5420 - accuracy: 0.8855 - val_loss: 22.9253 - val_accuracy: 0.8652\n",
      "Epoch 1091/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1059 - accuracy: 0.8770 - val_loss: 21.5124 - val_accuracy: 0.8361\n",
      "Epoch 1092/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.3976 - accuracy: 0.8729 - val_loss: 21.0873 - val_accuracy: 0.8468\n",
      "Epoch 1093/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3633 - accuracy: 0.8705 - val_loss: 27.4299 - val_accuracy: 0.8448\n",
      "Epoch 1094/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.4281 - accuracy: 0.8765 - val_loss: 24.2648 - val_accuracy: 0.8535\n",
      "Epoch 1095/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.0724 - accuracy: 0.8603 - val_loss: 26.9738 - val_accuracy: 0.8613\n",
      "Epoch 1096/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.5481 - accuracy: 0.8610 - val_loss: 18.6932 - val_accuracy: 0.8904\n",
      "Epoch 1097/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.9957 - accuracy: 0.8727 - val_loss: 19.1438 - val_accuracy: 0.8506\n",
      "Epoch 1098/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1822 - accuracy: 0.8819 - val_loss: 28.2075 - val_accuracy: 0.8865\n",
      "Epoch 1099/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8063 - accuracy: 0.8804 - val_loss: 14.9488 - val_accuracy: 0.8788\n",
      "Epoch 1100/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8520 - accuracy: 0.8673 - val_loss: 18.9574 - val_accuracy: 0.8497\n",
      "Epoch 1101/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1271 - accuracy: 0.8622 - val_loss: 21.4225 - val_accuracy: 0.8671\n",
      "Epoch 1102/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.0256 - accuracy: 0.8804 - val_loss: 24.4002 - val_accuracy: 0.8943\n",
      "Epoch 1103/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.3317 - accuracy: 0.8829 - val_loss: 22.4213 - val_accuracy: 0.8807\n",
      "Epoch 1104/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.4098 - accuracy: 0.8748 - val_loss: 24.8011 - val_accuracy: 0.8468\n",
      "Epoch 1105/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.7686 - accuracy: 0.8785 - val_loss: 17.5799 - val_accuracy: 0.6974\n",
      "Epoch 1106/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.9792 - accuracy: 0.8513 - val_loss: 27.6567 - val_accuracy: 0.8565\n",
      "Epoch 1107/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.1223 - accuracy: 0.8654 - val_loss: 19.5914 - val_accuracy: 0.8477\n",
      "Epoch 1108/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.3516 - accuracy: 0.8627 - val_loss: 16.3456 - val_accuracy: 0.8535\n",
      "Epoch 1109/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.0906 - accuracy: 0.8385 - val_loss: 24.4204 - val_accuracy: 0.8768\n",
      "Epoch 1110/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.1598 - accuracy: 0.8879 - val_loss: 24.4265 - val_accuracy: 0.8438\n",
      "Epoch 1111/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.0146 - accuracy: 0.8744 - val_loss: 22.3368 - val_accuracy: 0.8409\n",
      "Epoch 1112/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.1760 - accuracy: 0.8693 - val_loss: 21.5771 - val_accuracy: 0.8778\n",
      "Epoch 1113/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 16.2729 - accuracy: 0.8615 - val_loss: 17.6742 - val_accuracy: 0.8710\n",
      "Epoch 1114/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.1242 - accuracy: 0.8584 - val_loss: 25.9455 - val_accuracy: 0.8574\n",
      "Epoch 1115/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 16.0343 - accuracy: 0.8654 - val_loss: 21.2300 - val_accuracy: 0.8681\n",
      "Epoch 1116/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 16.2788 - accuracy: 0.8865 - val_loss: 26.1333 - val_accuracy: 0.8535\n",
      "Epoch 1117/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.8131 - accuracy: 0.8695 - val_loss: 23.8687 - val_accuracy: 0.8516\n",
      "Epoch 1118/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.5370 - accuracy: 0.8712 - val_loss: 23.0422 - val_accuracy: 0.8545\n",
      "Epoch 1119/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.3239 - accuracy: 0.8787 - val_loss: 19.5625 - val_accuracy: 0.8807\n",
      "Epoch 1120/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2134 - accuracy: 0.8802 - val_loss: 19.1715 - val_accuracy: 0.8826\n",
      "Epoch 1121/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1908 - accuracy: 0.8671 - val_loss: 14.3737 - val_accuracy: 0.8603\n",
      "Epoch 1122/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2484 - accuracy: 0.8664 - val_loss: 15.4218 - val_accuracy: 0.8778\n",
      "Epoch 1123/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 16.0151 - accuracy: 0.8656 - val_loss: 17.8417 - val_accuracy: 0.8351\n",
      "Epoch 1124/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.8663 - accuracy: 0.8770 - val_loss: 21.6827 - val_accuracy: 0.9040\n",
      "Epoch 1125/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 16.1303 - accuracy: 0.8732 - val_loss: 29.3357 - val_accuracy: 0.8720\n",
      "Epoch 1126/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.4061 - accuracy: 0.8698 - val_loss: 19.0767 - val_accuracy: 0.8661\n",
      "Epoch 1127/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0575 - accuracy: 0.8678 - val_loss: 20.1411 - val_accuracy: 0.8691\n",
      "Epoch 1128/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.9368 - accuracy: 0.8831 - val_loss: 16.8758 - val_accuracy: 0.8807\n",
      "Epoch 1129/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1846 - accuracy: 0.8734 - val_loss: 25.6033 - val_accuracy: 0.8894\n",
      "Epoch 1130/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1451 - accuracy: 0.8812 - val_loss: 18.0579 - val_accuracy: 0.8894\n",
      "Epoch 1131/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9435 - accuracy: 0.8790 - val_loss: 20.0280 - val_accuracy: 0.8691\n",
      "Epoch 1132/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8715 - accuracy: 0.8569 - val_loss: 20.8434 - val_accuracy: 0.8506\n",
      "Epoch 1133/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3869 - accuracy: 0.8649 - val_loss: 18.8181 - val_accuracy: 0.8826\n",
      "Epoch 1134/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.4184 - accuracy: 0.8812 - val_loss: 21.1189 - val_accuracy: 0.8817\n",
      "Epoch 1135/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1384 - accuracy: 0.8848 - val_loss: 25.4132 - val_accuracy: 0.8642\n",
      "Epoch 1136/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8058 - accuracy: 0.8603 - val_loss: 20.9284 - val_accuracy: 0.8720\n",
      "Epoch 1137/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.3445 - accuracy: 0.8695 - val_loss: 18.0772 - val_accuracy: 0.8565\n",
      "Epoch 1138/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.2510 - accuracy: 0.8807 - val_loss: 24.7314 - val_accuracy: 0.8729\n",
      "Epoch 1139/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1003 - accuracy: 0.8654 - val_loss: 20.6664 - val_accuracy: 0.8574\n",
      "Epoch 1140/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.0233 - accuracy: 0.8826 - val_loss: 16.3648 - val_accuracy: 0.8555\n",
      "Epoch 1141/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9326 - accuracy: 0.8795 - val_loss: 25.0722 - val_accuracy: 0.8632\n",
      "Epoch 1142/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8813 - accuracy: 0.8700 - val_loss: 25.1387 - val_accuracy: 0.8594\n",
      "Epoch 1143/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0960 - accuracy: 0.8610 - val_loss: 19.7801 - val_accuracy: 0.8555\n",
      "Epoch 1144/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2952 - accuracy: 0.8647 - val_loss: 24.6591 - val_accuracy: 0.8885\n",
      "Epoch 1145/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2760 - accuracy: 0.8685 - val_loss: 14.1899 - val_accuracy: 0.8807\n",
      "Epoch 1146/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.4522 - accuracy: 0.8601 - val_loss: 22.8264 - val_accuracy: 0.8206\n",
      "Epoch 1147/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.9817 - accuracy: 0.8630 - val_loss: 20.1351 - val_accuracy: 0.8836\n",
      "Epoch 1148/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.2783 - accuracy: 0.8807 - val_loss: 20.9030 - val_accuracy: 0.8749\n",
      "Epoch 1149/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2710 - accuracy: 0.8666 - val_loss: 21.0641 - val_accuracy: 0.8468\n",
      "Epoch 1150/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7822 - accuracy: 0.8727 - val_loss: 14.7653 - val_accuracy: 0.9059\n",
      "Epoch 1151/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.6675 - accuracy: 0.8722 - val_loss: 21.8338 - val_accuracy: 0.8807\n",
      "Epoch 1152/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7175 - accuracy: 0.8710 - val_loss: 23.4871 - val_accuracy: 0.8031\n",
      "Epoch 1153/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.3321 - accuracy: 0.8453 - val_loss: 30.1757 - val_accuracy: 0.8390\n",
      "Epoch 1154/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0618 - accuracy: 0.8433 - val_loss: 15.6335 - val_accuracy: 0.8661\n",
      "Epoch 1155/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8726 - accuracy: 0.8690 - val_loss: 21.8180 - val_accuracy: 0.8982\n",
      "Epoch 1156/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8510 - accuracy: 0.8620 - val_loss: 23.5694 - val_accuracy: 0.8855\n",
      "Epoch 1157/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9732 - accuracy: 0.8812 - val_loss: 24.5728 - val_accuracy: 0.8623\n",
      "Epoch 1158/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.1999 - accuracy: 0.8656 - val_loss: 23.2398 - val_accuracy: 0.8691\n",
      "Epoch 1159/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7742 - accuracy: 0.8688 - val_loss: 20.3866 - val_accuracy: 0.8758\n",
      "Epoch 1160/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.2384 - accuracy: 0.8705 - val_loss: 18.7334 - val_accuracy: 0.8186\n",
      "Epoch 1161/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8416 - accuracy: 0.8698 - val_loss: 22.3811 - val_accuracy: 0.8409\n",
      "Epoch 1162/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.2335 - accuracy: 0.8625 - val_loss: 18.0749 - val_accuracy: 0.8109\n",
      "Epoch 1163/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9775 - accuracy: 0.8761 - val_loss: 18.9146 - val_accuracy: 0.8778\n",
      "Epoch 1164/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.0675 - accuracy: 0.8685 - val_loss: 27.9798 - val_accuracy: 0.8429\n",
      "Epoch 1165/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0068 - accuracy: 0.8753 - val_loss: 17.3465 - val_accuracy: 0.8904\n",
      "Epoch 1166/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9672 - accuracy: 0.8850 - val_loss: 25.4435 - val_accuracy: 0.8797\n",
      "Epoch 1167/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8113 - accuracy: 0.8584 - val_loss: 17.1794 - val_accuracy: 0.8972\n",
      "Epoch 1168/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0266 - accuracy: 0.8763 - val_loss: 21.9048 - val_accuracy: 0.8594\n",
      "Epoch 1169/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1733 - accuracy: 0.8542 - val_loss: 25.0785 - val_accuracy: 0.8594\n",
      "Epoch 1170/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9212 - accuracy: 0.8719 - val_loss: 28.2360 - val_accuracy: 0.8933\n",
      "Epoch 1171/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3005 - accuracy: 0.8586 - val_loss: 18.9994 - val_accuracy: 0.8729\n",
      "Epoch 1172/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0619 - accuracy: 0.8598 - val_loss: 20.9744 - val_accuracy: 0.8293\n",
      "Epoch 1173/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.2153 - accuracy: 0.8824 - val_loss: 15.2307 - val_accuracy: 0.8788\n",
      "Epoch 1174/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1564 - accuracy: 0.8778 - val_loss: 19.7886 - val_accuracy: 0.8739\n",
      "Epoch 1175/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8692 - accuracy: 0.8790 - val_loss: 21.0122 - val_accuracy: 0.8914\n",
      "Epoch 1176/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9853 - accuracy: 0.8724 - val_loss: 20.6371 - val_accuracy: 0.8031\n",
      "Epoch 1177/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1139 - accuracy: 0.8705 - val_loss: 23.3551 - val_accuracy: 0.8118\n",
      "Epoch 1178/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1248 - accuracy: 0.8618 - val_loss: 18.6950 - val_accuracy: 0.8477\n",
      "Epoch 1179/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 16.0860 - accuracy: 0.8620 - val_loss: 16.1740 - val_accuracy: 0.8613\n",
      "Epoch 1180/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.0839 - accuracy: 0.8751 - val_loss: 21.1418 - val_accuracy: 0.8661\n",
      "Epoch 1181/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8781 - accuracy: 0.8717 - val_loss: 21.0954 - val_accuracy: 0.8691\n",
      "Epoch 1182/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7430 - accuracy: 0.8603 - val_loss: 21.9180 - val_accuracy: 0.8468\n",
      "Epoch 1183/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7842 - accuracy: 0.8678 - val_loss: 20.2452 - val_accuracy: 0.8613\n",
      "Epoch 1184/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.4063 - accuracy: 0.8642 - val_loss: 21.8592 - val_accuracy: 0.8661\n",
      "Epoch 1185/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 16.1438 - accuracy: 0.8821 - val_loss: 24.8802 - val_accuracy: 0.8235\n",
      "Epoch 1186/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.8854 - accuracy: 0.8787 - val_loss: 21.3292 - val_accuracy: 0.8545\n",
      "Epoch 1187/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.8546 - accuracy: 0.8795 - val_loss: 14.9624 - val_accuracy: 0.8652\n",
      "Epoch 1188/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 14.9568 - accuracy: 0.8727 - val_loss: 16.9444 - val_accuracy: 0.8603\n",
      "Epoch 1189/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.8317 - accuracy: 0.8656 - val_loss: 20.6334 - val_accuracy: 0.8002\n",
      "Epoch 1190/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.1107 - accuracy: 0.8748 - val_loss: 18.2713 - val_accuracy: 0.8623\n",
      "Epoch 1191/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0456 - accuracy: 0.8627 - val_loss: 24.6458 - val_accuracy: 0.8603\n",
      "Epoch 1192/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7904 - accuracy: 0.8659 - val_loss: 20.2677 - val_accuracy: 0.8885\n",
      "Epoch 1193/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8733 - accuracy: 0.8821 - val_loss: 19.0628 - val_accuracy: 0.8758\n",
      "Epoch 1194/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3998 - accuracy: 0.8695 - val_loss: 17.3600 - val_accuracy: 0.8118\n",
      "Epoch 1195/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.7916 - accuracy: 0.8727 - val_loss: 25.2658 - val_accuracy: 0.8632\n",
      "Epoch 1196/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.3780 - accuracy: 0.8622 - val_loss: 17.6634 - val_accuracy: 0.8972\n",
      "Epoch 1197/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4980 - accuracy: 0.8700 - val_loss: 15.4027 - val_accuracy: 0.8448\n",
      "Epoch 1198/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8966 - accuracy: 0.8627 - val_loss: 18.5417 - val_accuracy: 0.8555\n",
      "Epoch 1199/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8497 - accuracy: 0.8596 - val_loss: 18.5862 - val_accuracy: 0.9011\n",
      "Epoch 1200/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 16.0275 - accuracy: 0.8872 - val_loss: 20.7225 - val_accuracy: 0.8952\n",
      "Epoch 1201/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9143 - accuracy: 0.8727 - val_loss: 20.3603 - val_accuracy: 0.8438\n",
      "Epoch 1202/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8599 - accuracy: 0.8523 - val_loss: 28.8352 - val_accuracy: 0.8632\n",
      "Epoch 1203/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7752 - accuracy: 0.8426 - val_loss: 16.8007 - val_accuracy: 0.8710\n",
      "Epoch 1204/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4706 - accuracy: 0.8598 - val_loss: 15.0513 - val_accuracy: 0.8438\n",
      "Epoch 1205/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.9121 - accuracy: 0.8666 - val_loss: 22.6721 - val_accuracy: 0.8943\n",
      "Epoch 1206/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0590 - accuracy: 0.8734 - val_loss: 17.9238 - val_accuracy: 0.8584\n",
      "Epoch 1207/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8287 - accuracy: 0.8685 - val_loss: 25.6626 - val_accuracy: 0.8584\n",
      "Epoch 1208/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.9846 - accuracy: 0.8581 - val_loss: 22.8059 - val_accuracy: 0.8904\n",
      "Epoch 1209/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0135 - accuracy: 0.8520 - val_loss: 18.1165 - val_accuracy: 0.8361\n",
      "Epoch 1210/2000\n",
      "4123/4123 [==============================] - ETA: 0s - loss: 17.3386 - accuracy: 0.852 - 0s 22us/step - loss: 15.7762 - accuracy: 0.8579 - val_loss: 19.1480 - val_accuracy: 0.8109\n",
      "Epoch 1211/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8161 - accuracy: 0.8559 - val_loss: 19.5807 - val_accuracy: 0.8167\n",
      "Epoch 1212/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7841 - accuracy: 0.8455 - val_loss: 18.7224 - val_accuracy: 0.8826\n",
      "Epoch 1213/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.9016 - accuracy: 0.8826 - val_loss: 27.0404 - val_accuracy: 0.8235\n",
      "Epoch 1214/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8619 - accuracy: 0.8523 - val_loss: 23.5438 - val_accuracy: 0.8855\n",
      "Epoch 1215/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.0322 - accuracy: 0.8882 - val_loss: 24.4780 - val_accuracy: 0.8613\n",
      "Epoch 1216/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.2930 - accuracy: 0.8554 - val_loss: 18.8119 - val_accuracy: 0.7721\n",
      "Epoch 1217/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8532 - accuracy: 0.8533 - val_loss: 26.7663 - val_accuracy: 0.9011\n",
      "Epoch 1218/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6164 - accuracy: 0.8625 - val_loss: 15.5699 - val_accuracy: 0.8923\n",
      "Epoch 1219/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.6263 - accuracy: 0.8584 - val_loss: 22.9671 - val_accuracy: 0.8555\n",
      "Epoch 1220/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7663 - accuracy: 0.8690 - val_loss: 19.1387 - val_accuracy: 0.8836\n",
      "Epoch 1221/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.7634 - accuracy: 0.8615 - val_loss: 20.5157 - val_accuracy: 0.8778\n",
      "Epoch 1222/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.9685 - accuracy: 0.8809 - val_loss: 24.2951 - val_accuracy: 0.8594\n",
      "Epoch 1223/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8743 - accuracy: 0.8596 - val_loss: 17.5417 - val_accuracy: 0.8380\n",
      "Epoch 1224/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8082 - accuracy: 0.8620 - val_loss: 21.9164 - val_accuracy: 0.8797\n",
      "Epoch 1225/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9837 - accuracy: 0.8719 - val_loss: 18.9648 - val_accuracy: 0.8186\n",
      "Epoch 1226/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8671 - accuracy: 0.8673 - val_loss: 22.8005 - val_accuracy: 0.8720\n",
      "Epoch 1227/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9510 - accuracy: 0.8654 - val_loss: 23.9946 - val_accuracy: 0.8400\n",
      "Epoch 1228/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.0430 - accuracy: 0.8712 - val_loss: 17.3025 - val_accuracy: 0.8914\n",
      "Epoch 1229/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7222 - accuracy: 0.8707 - val_loss: 19.8861 - val_accuracy: 0.8749\n",
      "Epoch 1230/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9299 - accuracy: 0.8632 - val_loss: 21.8859 - val_accuracy: 0.8894\n",
      "Epoch 1231/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7499 - accuracy: 0.8596 - val_loss: 17.5199 - val_accuracy: 0.8982\n",
      "Epoch 1232/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8945 - accuracy: 0.8775 - val_loss: 19.5415 - val_accuracy: 0.8274\n",
      "Epoch 1233/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9664 - accuracy: 0.8773 - val_loss: 20.6941 - val_accuracy: 0.8157\n",
      "Epoch 1234/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3200 - accuracy: 0.8499 - val_loss: 25.8824 - val_accuracy: 0.8671\n",
      "Epoch 1235/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4117 - accuracy: 0.8363 - val_loss: 23.1871 - val_accuracy: 0.8322\n",
      "Epoch 1236/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.9728 - accuracy: 0.8666 - val_loss: 23.4300 - val_accuracy: 0.8138\n",
      "Epoch 1237/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.0155 - accuracy: 0.8642 - val_loss: 21.9185 - val_accuracy: 0.8283\n",
      "Epoch 1238/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8427 - accuracy: 0.8588 - val_loss: 18.7397 - val_accuracy: 0.8836\n",
      "Epoch 1239/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8261 - accuracy: 0.8707 - val_loss: 17.5548 - val_accuracy: 0.8807\n",
      "Epoch 1240/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.3797 - accuracy: 0.8761 - val_loss: 20.5788 - val_accuracy: 0.8739\n",
      "Epoch 1241/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.6356 - accuracy: 0.8717 - val_loss: 18.8117 - val_accuracy: 0.8118\n",
      "Epoch 1242/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6085 - accuracy: 0.8676 - val_loss: 22.3128 - val_accuracy: 0.8642\n",
      "Epoch 1243/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0252 - accuracy: 0.8608 - val_loss: 26.5132 - val_accuracy: 0.8361\n",
      "Epoch 1244/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.8926 - accuracy: 0.8780 - val_loss: 21.7178 - val_accuracy: 0.8526\n",
      "Epoch 1245/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0436 - accuracy: 0.8613 - val_loss: 20.4160 - val_accuracy: 0.8351\n",
      "Epoch 1246/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.8513 - accuracy: 0.8736 - val_loss: 17.7756 - val_accuracy: 0.8826\n",
      "Epoch 1247/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4590 - accuracy: 0.8717 - val_loss: 22.5770 - val_accuracy: 0.7818\n",
      "Epoch 1248/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.6090 - accuracy: 0.8484 - val_loss: 19.5129 - val_accuracy: 0.8778\n",
      "Epoch 1249/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3681 - accuracy: 0.8659 - val_loss: 25.9167 - val_accuracy: 0.8351\n",
      "Epoch 1250/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9350 - accuracy: 0.8554 - val_loss: 22.2212 - val_accuracy: 0.8322\n",
      "Epoch 1251/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9663 - accuracy: 0.8739 - val_loss: 25.3753 - val_accuracy: 0.8739\n",
      "Epoch 1252/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 16.0043 - accuracy: 0.8722 - val_loss: 20.9245 - val_accuracy: 0.8128\n",
      "Epoch 1253/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.7396 - accuracy: 0.8775 - val_loss: 20.6989 - val_accuracy: 0.8846\n",
      "Epoch 1254/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.7937 - accuracy: 0.8700 - val_loss: 14.8317 - val_accuracy: 0.8894\n",
      "Epoch 1255/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.4514 - accuracy: 0.8610 - val_loss: 25.5352 - val_accuracy: 0.8855\n",
      "Epoch 1256/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 16.0051 - accuracy: 0.8586 - val_loss: 20.6556 - val_accuracy: 0.8855\n",
      "Epoch 1257/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.8808 - accuracy: 0.8647 - val_loss: 23.0016 - val_accuracy: 0.8700\n",
      "Epoch 1258/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.8571 - accuracy: 0.8792 - val_loss: 14.8470 - val_accuracy: 0.8865\n",
      "Epoch 1259/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.6013 - accuracy: 0.8603 - val_loss: 18.6574 - val_accuracy: 0.8118\n",
      "Epoch 1260/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0904 - accuracy: 0.8467 - val_loss: 17.5127 - val_accuracy: 0.8400\n",
      "Epoch 1261/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.7200 - accuracy: 0.8765 - val_loss: 15.7809 - val_accuracy: 0.8652\n",
      "Epoch 1262/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5958 - accuracy: 0.8739 - val_loss: 23.2602 - val_accuracy: 0.8826\n",
      "Epoch 1263/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.8877 - accuracy: 0.8809 - val_loss: 16.4531 - val_accuracy: 0.8807\n",
      "Epoch 1264/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.6554 - accuracy: 0.8775 - val_loss: 18.7542 - val_accuracy: 0.8720\n",
      "Epoch 1265/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7129 - accuracy: 0.8637 - val_loss: 16.0454 - val_accuracy: 0.8390\n",
      "Epoch 1266/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3695 - accuracy: 0.8707 - val_loss: 24.0977 - val_accuracy: 0.8623\n",
      "Epoch 1267/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8718 - accuracy: 0.8634 - val_loss: 16.1868 - val_accuracy: 0.8661\n",
      "Epoch 1268/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7181 - accuracy: 0.8761 - val_loss: 18.7770 - val_accuracy: 0.8691\n",
      "Epoch 1269/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.1385 - accuracy: 0.8664 - val_loss: 14.9579 - val_accuracy: 0.8380\n",
      "Epoch 1270/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0968 - accuracy: 0.8487 - val_loss: 23.9707 - val_accuracy: 0.8351\n",
      "Epoch 1271/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.6446 - accuracy: 0.8586 - val_loss: 24.2788 - val_accuracy: 0.8855\n",
      "Epoch 1272/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6880 - accuracy: 0.8688 - val_loss: 23.6638 - val_accuracy: 0.8526\n",
      "Epoch 1273/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.6362 - accuracy: 0.8579 - val_loss: 21.3659 - val_accuracy: 0.8341\n",
      "Epoch 1274/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 16.0247 - accuracy: 0.8661 - val_loss: 22.8995 - val_accuracy: 0.8700\n",
      "Epoch 1275/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7686 - accuracy: 0.8814 - val_loss: 20.9753 - val_accuracy: 0.8933\n",
      "Epoch 1276/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.6644 - accuracy: 0.8899 - val_loss: 21.9227 - val_accuracy: 0.8962\n",
      "Epoch 1277/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6200 - accuracy: 0.8824 - val_loss: 18.3640 - val_accuracy: 0.8661\n",
      "Epoch 1278/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7449 - accuracy: 0.8671 - val_loss: 16.6646 - val_accuracy: 0.8710\n",
      "Epoch 1279/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5208 - accuracy: 0.8683 - val_loss: 22.2951 - val_accuracy: 0.8322\n",
      "Epoch 1280/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9073 - accuracy: 0.8700 - val_loss: 20.8017 - val_accuracy: 0.8855\n",
      "Epoch 1281/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7470 - accuracy: 0.8732 - val_loss: 20.5836 - val_accuracy: 0.8341\n",
      "Epoch 1282/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7216 - accuracy: 0.8622 - val_loss: 21.8121 - val_accuracy: 0.8468\n",
      "Epoch 1283/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.7032 - accuracy: 0.8474 - val_loss: 15.3840 - val_accuracy: 0.8729\n",
      "Epoch 1284/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5688 - accuracy: 0.8618 - val_loss: 20.6798 - val_accuracy: 0.8312\n",
      "Epoch 1285/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.6754 - accuracy: 0.8676 - val_loss: 23.3770 - val_accuracy: 0.9001\n",
      "Epoch 1286/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.7278 - accuracy: 0.8739 - val_loss: 24.3991 - val_accuracy: 0.8400\n",
      "Epoch 1287/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8270 - accuracy: 0.8647 - val_loss: 15.8206 - val_accuracy: 0.9069\n",
      "Epoch 1288/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.7071 - accuracy: 0.8855 - val_loss: 23.8461 - val_accuracy: 0.8128\n",
      "Epoch 1289/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5963 - accuracy: 0.8734 - val_loss: 23.2749 - val_accuracy: 0.8438\n",
      "Epoch 1290/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.9597 - accuracy: 0.8666 - val_loss: 23.9564 - val_accuracy: 0.8177\n",
      "Epoch 1291/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4770 - accuracy: 0.8700 - val_loss: 24.1084 - val_accuracy: 0.7953\n",
      "Epoch 1292/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5692 - accuracy: 0.8668 - val_loss: 19.9072 - val_accuracy: 0.8788\n",
      "Epoch 1293/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6408 - accuracy: 0.8637 - val_loss: 20.6631 - val_accuracy: 0.8215\n",
      "Epoch 1294/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6489 - accuracy: 0.8676 - val_loss: 19.8914 - val_accuracy: 0.8681\n",
      "Epoch 1295/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.7354 - accuracy: 0.8710 - val_loss: 20.0899 - val_accuracy: 0.8380\n",
      "Epoch 1296/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4062 - accuracy: 0.8533 - val_loss: 22.4975 - val_accuracy: 0.8671\n",
      "Epoch 1297/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3042 - accuracy: 0.8542 - val_loss: 21.0720 - val_accuracy: 0.8739\n",
      "Epoch 1298/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8806 - accuracy: 0.8525 - val_loss: 22.2562 - val_accuracy: 0.8332\n",
      "Epoch 1299/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.9090 - accuracy: 0.8717 - val_loss: 24.3900 - val_accuracy: 0.8409\n",
      "Epoch 1300/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.8429 - accuracy: 0.8702 - val_loss: 22.7760 - val_accuracy: 0.8817\n",
      "Epoch 1301/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7875 - accuracy: 0.8690 - val_loss: 23.5690 - val_accuracy: 0.8613\n",
      "Epoch 1302/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3333 - accuracy: 0.8753 - val_loss: 22.8688 - val_accuracy: 0.8341\n",
      "Epoch 1303/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5791 - accuracy: 0.8608 - val_loss: 17.4373 - val_accuracy: 0.8380\n",
      "Epoch 1304/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0099 - accuracy: 0.8504 - val_loss: 21.4557 - val_accuracy: 0.8826\n",
      "Epoch 1305/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2763 - accuracy: 0.8601 - val_loss: 15.0791 - val_accuracy: 0.8400\n",
      "Epoch 1306/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6803 - accuracy: 0.8683 - val_loss: 24.3691 - val_accuracy: 0.8477\n",
      "Epoch 1307/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4460 - accuracy: 0.8719 - val_loss: 22.2150 - val_accuracy: 0.8865\n",
      "Epoch 1308/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6837 - accuracy: 0.8681 - val_loss: 23.7354 - val_accuracy: 0.8923\n",
      "Epoch 1309/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5204 - accuracy: 0.8656 - val_loss: 17.9777 - val_accuracy: 0.8448\n",
      "Epoch 1310/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4213 - accuracy: 0.8799 - val_loss: 19.0759 - val_accuracy: 0.8429\n",
      "Epoch 1311/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7524 - accuracy: 0.8700 - val_loss: 26.5461 - val_accuracy: 0.8982\n",
      "Epoch 1312/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.7684 - accuracy: 0.8860 - val_loss: 17.9473 - val_accuracy: 0.8506\n",
      "Epoch 1313/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6767 - accuracy: 0.8853 - val_loss: 17.0797 - val_accuracy: 0.8089\n",
      "Epoch 1314/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5836 - accuracy: 0.8727 - val_loss: 25.0837 - val_accuracy: 0.8215\n",
      "Epoch 1315/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2160 - accuracy: 0.8610 - val_loss: 20.6269 - val_accuracy: 0.8002\n",
      "Epoch 1316/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5294 - accuracy: 0.8598 - val_loss: 28.6029 - val_accuracy: 0.7963\n",
      "Epoch 1317/2000\n",
      "4123/4123 [==============================] - 0s 28us/step - loss: 15.3745 - accuracy: 0.8661 - val_loss: 19.5261 - val_accuracy: 0.8894\n",
      "Epoch 1318/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.8518 - accuracy: 0.8705 - val_loss: 20.6818 - val_accuracy: 0.8894\n",
      "Epoch 1319/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2428 - accuracy: 0.8625 - val_loss: 17.7547 - val_accuracy: 0.8438\n",
      "Epoch 1320/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6879 - accuracy: 0.8613 - val_loss: 20.7733 - val_accuracy: 0.8487\n",
      "Epoch 1321/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8965 - accuracy: 0.8770 - val_loss: 21.2712 - val_accuracy: 0.8594\n",
      "Epoch 1322/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5209 - accuracy: 0.8671 - val_loss: 17.4203 - val_accuracy: 0.8962\n",
      "Epoch 1323/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 15.6162 - accuracy: 0.8622 - val_loss: 17.9933 - val_accuracy: 0.8594\n",
      "Epoch 1324/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.5730 - accuracy: 0.8715 - val_loss: 20.3908 - val_accuracy: 0.8380\n",
      "Epoch 1325/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.6095 - accuracy: 0.8809 - val_loss: 19.5657 - val_accuracy: 0.8565\n",
      "Epoch 1326/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5220 - accuracy: 0.8729 - val_loss: 20.2422 - val_accuracy: 0.8836\n",
      "Epoch 1327/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5808 - accuracy: 0.8795 - val_loss: 18.7475 - val_accuracy: 0.8700\n",
      "Epoch 1328/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3779 - accuracy: 0.8479 - val_loss: 23.7085 - val_accuracy: 0.8400\n",
      "Epoch 1329/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.3226 - accuracy: 0.8615 - val_loss: 16.5757 - val_accuracy: 0.8758\n",
      "Epoch 1330/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3741 - accuracy: 0.8438 - val_loss: 19.2415 - val_accuracy: 0.8855\n",
      "Epoch 1331/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5953 - accuracy: 0.8824 - val_loss: 21.1676 - val_accuracy: 0.8332\n",
      "Epoch 1332/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.9317 - accuracy: 0.8615 - val_loss: 14.9973 - val_accuracy: 0.8642\n",
      "Epoch 1333/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5183 - accuracy: 0.8681 - val_loss: 20.6944 - val_accuracy: 0.8613\n",
      "Epoch 1334/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5418 - accuracy: 0.8700 - val_loss: 28.8334 - val_accuracy: 0.8244\n",
      "Epoch 1335/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.7384 - accuracy: 0.8838 - val_loss: 19.4579 - val_accuracy: 0.8506\n",
      "Epoch 1336/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3758 - accuracy: 0.8598 - val_loss: 17.0088 - val_accuracy: 0.8545\n",
      "Epoch 1337/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4992 - accuracy: 0.8700 - val_loss: 22.4164 - val_accuracy: 0.8749\n",
      "Epoch 1338/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.6884 - accuracy: 0.8872 - val_loss: 17.3989 - val_accuracy: 0.8846\n",
      "Epoch 1339/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4444 - accuracy: 0.8831 - val_loss: 22.0751 - val_accuracy: 0.8991\n",
      "Epoch 1340/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5600 - accuracy: 0.8661 - val_loss: 17.9881 - val_accuracy: 0.8681\n",
      "Epoch 1341/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4164 - accuracy: 0.8576 - val_loss: 14.7754 - val_accuracy: 0.8826\n",
      "Epoch 1342/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5281 - accuracy: 0.8853 - val_loss: 19.9124 - val_accuracy: 0.8758\n",
      "Epoch 1343/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2336 - accuracy: 0.8666 - val_loss: 23.0072 - val_accuracy: 0.8167\n",
      "Epoch 1344/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1897 - accuracy: 0.8695 - val_loss: 21.9475 - val_accuracy: 0.7963\n",
      "Epoch 1345/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.5691 - accuracy: 0.8761 - val_loss: 16.1677 - val_accuracy: 0.8468\n",
      "Epoch 1346/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5049 - accuracy: 0.8567 - val_loss: 22.3488 - val_accuracy: 0.8400\n",
      "Epoch 1347/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6630 - accuracy: 0.8613 - val_loss: 18.5465 - val_accuracy: 0.8448\n",
      "Epoch 1348/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.8492 - accuracy: 0.8739 - val_loss: 21.9004 - val_accuracy: 0.8720\n",
      "Epoch 1349/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6948 - accuracy: 0.8550 - val_loss: 22.5403 - val_accuracy: 0.8681\n",
      "Epoch 1350/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.7189 - accuracy: 0.8710 - val_loss: 20.3040 - val_accuracy: 0.8332\n",
      "Epoch 1351/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4438 - accuracy: 0.8608 - val_loss: 14.9363 - val_accuracy: 0.8788\n",
      "Epoch 1352/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4206 - accuracy: 0.8744 - val_loss: 22.2049 - val_accuracy: 0.8477\n",
      "Epoch 1353/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5180 - accuracy: 0.8816 - val_loss: 20.4843 - val_accuracy: 0.8506\n",
      "Epoch 1354/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4416 - accuracy: 0.8642 - val_loss: 23.7064 - val_accuracy: 0.8361\n",
      "Epoch 1355/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6426 - accuracy: 0.8782 - val_loss: 20.7090 - val_accuracy: 0.8894\n",
      "Epoch 1356/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.3293 - accuracy: 0.8741 - val_loss: 27.1068 - val_accuracy: 0.8603\n",
      "Epoch 1357/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.6047 - accuracy: 0.8758 - val_loss: 17.9448 - val_accuracy: 0.8885\n",
      "Epoch 1358/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3870 - accuracy: 0.8792 - val_loss: 26.8325 - val_accuracy: 0.8661\n",
      "Epoch 1359/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7892 - accuracy: 0.8765 - val_loss: 20.4079 - val_accuracy: 0.8758\n",
      "Epoch 1360/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4549 - accuracy: 0.8678 - val_loss: 18.1683 - val_accuracy: 0.8691\n",
      "Epoch 1361/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5569 - accuracy: 0.8550 - val_loss: 20.9781 - val_accuracy: 0.8952\n",
      "Epoch 1362/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6657 - accuracy: 0.8773 - val_loss: 17.5422 - val_accuracy: 0.8341\n",
      "Epoch 1363/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.3484 - accuracy: 0.8693 - val_loss: 17.4949 - val_accuracy: 0.8700\n",
      "Epoch 1364/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.0100 - accuracy: 0.8474 - val_loss: 17.4323 - val_accuracy: 0.8817\n",
      "Epoch 1365/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3713 - accuracy: 0.8637 - val_loss: 21.9536 - val_accuracy: 0.9001\n",
      "Epoch 1366/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.7198 - accuracy: 0.8795 - val_loss: 16.3804 - val_accuracy: 0.8788\n",
      "Epoch 1367/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4959 - accuracy: 0.8494 - val_loss: 25.1683 - val_accuracy: 0.8516\n",
      "Epoch 1368/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5577 - accuracy: 0.8765 - val_loss: 20.1180 - val_accuracy: 0.8749\n",
      "Epoch 1369/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.5184 - accuracy: 0.8710 - val_loss: 21.8245 - val_accuracy: 0.8409\n",
      "Epoch 1370/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7339 - accuracy: 0.8778 - val_loss: 22.0692 - val_accuracy: 0.8846\n",
      "Epoch 1371/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3887 - accuracy: 0.8782 - val_loss: 17.2869 - val_accuracy: 0.8826\n",
      "Epoch 1372/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.0578 - accuracy: 0.8632 - val_loss: 23.5779 - val_accuracy: 0.8274\n",
      "Epoch 1373/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.7415 - accuracy: 0.8676 - val_loss: 23.0413 - val_accuracy: 0.8545\n",
      "Epoch 1374/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7285 - accuracy: 0.8729 - val_loss: 19.8399 - val_accuracy: 0.8419\n",
      "Epoch 1375/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.5243 - accuracy: 0.8719 - val_loss: 19.5902 - val_accuracy: 0.8758\n",
      "Epoch 1376/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.4950 - accuracy: 0.8673 - val_loss: 23.5050 - val_accuracy: 0.8933\n",
      "Epoch 1377/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3489 - accuracy: 0.8804 - val_loss: 18.5366 - val_accuracy: 0.8565\n",
      "Epoch 1378/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3303 - accuracy: 0.8736 - val_loss: 19.3873 - val_accuracy: 0.8380\n",
      "Epoch 1379/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.4015 - accuracy: 0.8824 - val_loss: 24.6683 - val_accuracy: 0.9079\n",
      "Epoch 1380/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0791 - accuracy: 0.8732 - val_loss: 22.1126 - val_accuracy: 0.8797\n",
      "Epoch 1381/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1786 - accuracy: 0.8795 - val_loss: 26.4079 - val_accuracy: 0.8565\n",
      "Epoch 1382/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.1060 - accuracy: 0.8765 - val_loss: 18.9408 - val_accuracy: 0.8574\n",
      "Epoch 1383/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2238 - accuracy: 0.8778 - val_loss: 18.2532 - val_accuracy: 0.9001\n",
      "Epoch 1384/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.5454 - accuracy: 0.8816 - val_loss: 27.1247 - val_accuracy: 0.8885\n",
      "Epoch 1385/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.5239 - accuracy: 0.8637 - val_loss: 16.7084 - val_accuracy: 0.8293\n",
      "Epoch 1386/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7309 - accuracy: 0.8799 - val_loss: 18.1914 - val_accuracy: 0.8700\n",
      "Epoch 1387/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5005 - accuracy: 0.8727 - val_loss: 19.9886 - val_accuracy: 0.8720\n",
      "Epoch 1388/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4475 - accuracy: 0.8787 - val_loss: 22.1581 - val_accuracy: 0.8778\n",
      "Epoch 1389/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.5931 - accuracy: 0.8790 - val_loss: 18.1903 - val_accuracy: 0.8729\n",
      "Epoch 1390/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4870 - accuracy: 0.8819 - val_loss: 21.3069 - val_accuracy: 0.8904\n",
      "Epoch 1391/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6038 - accuracy: 0.8865 - val_loss: 18.5925 - val_accuracy: 0.8855\n",
      "Epoch 1392/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.6081 - accuracy: 0.8853 - val_loss: 15.7852 - val_accuracy: 0.8448\n",
      "Epoch 1393/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.1682 - accuracy: 0.8753 - val_loss: 25.3289 - val_accuracy: 0.8565\n",
      "Epoch 1394/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1802 - accuracy: 0.8758 - val_loss: 25.1850 - val_accuracy: 0.8710\n",
      "Epoch 1395/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4121 - accuracy: 0.8552 - val_loss: 20.3504 - val_accuracy: 0.8361\n",
      "Epoch 1396/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5816 - accuracy: 0.8700 - val_loss: 17.2683 - val_accuracy: 0.8865\n",
      "Epoch 1397/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3149 - accuracy: 0.8812 - val_loss: 17.8275 - val_accuracy: 0.8739\n",
      "Epoch 1398/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.4133 - accuracy: 0.8778 - val_loss: 16.9612 - val_accuracy: 0.8729\n",
      "Epoch 1399/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2514 - accuracy: 0.8705 - val_loss: 20.8663 - val_accuracy: 0.8855\n",
      "Epoch 1400/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.1931 - accuracy: 0.8770 - val_loss: 21.9061 - val_accuracy: 0.8293\n",
      "Epoch 1401/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.6897 - accuracy: 0.8676 - val_loss: 16.8781 - val_accuracy: 0.8545\n",
      "Epoch 1402/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.3930 - accuracy: 0.8683 - val_loss: 23.0847 - val_accuracy: 0.8526\n",
      "Epoch 1403/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5486 - accuracy: 0.8651 - val_loss: 21.6380 - val_accuracy: 0.8952\n",
      "Epoch 1404/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2087 - accuracy: 0.8787 - val_loss: 16.9668 - val_accuracy: 0.8468\n",
      "Epoch 1405/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4365 - accuracy: 0.8741 - val_loss: 21.6079 - val_accuracy: 0.8254\n",
      "Epoch 1406/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6304 - accuracy: 0.8593 - val_loss: 15.1574 - val_accuracy: 0.8904\n",
      "Epoch 1407/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3007 - accuracy: 0.8843 - val_loss: 22.0335 - val_accuracy: 0.8778\n",
      "Epoch 1408/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1212 - accuracy: 0.8850 - val_loss: 21.6944 - val_accuracy: 0.8429\n",
      "Epoch 1409/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2878 - accuracy: 0.8717 - val_loss: 18.1391 - val_accuracy: 0.8632\n",
      "Epoch 1410/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.3633 - accuracy: 0.8654 - val_loss: 24.3308 - val_accuracy: 0.8293\n",
      "Epoch 1411/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4408 - accuracy: 0.8799 - val_loss: 15.6399 - val_accuracy: 0.8962\n",
      "Epoch 1412/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2776 - accuracy: 0.8775 - val_loss: 18.8779 - val_accuracy: 0.9117\n",
      "Epoch 1413/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.4603 - accuracy: 0.8756 - val_loss: 18.0208 - val_accuracy: 0.8710\n",
      "Epoch 1414/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.3393 - accuracy: 0.8739 - val_loss: 21.1965 - val_accuracy: 0.8778\n",
      "Epoch 1415/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2916 - accuracy: 0.8644 - val_loss: 14.8436 - val_accuracy: 0.8739\n",
      "Epoch 1416/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.5402 - accuracy: 0.8681 - val_loss: 26.3745 - val_accuracy: 0.8865\n",
      "Epoch 1417/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3083 - accuracy: 0.8836 - val_loss: 20.8792 - val_accuracy: 0.8904\n",
      "Epoch 1418/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.3679 - accuracy: 0.8571 - val_loss: 19.3201 - val_accuracy: 0.8681\n",
      "Epoch 1419/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2167 - accuracy: 0.8647 - val_loss: 18.6978 - val_accuracy: 0.8943\n",
      "Epoch 1420/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2773 - accuracy: 0.8821 - val_loss: 18.4171 - val_accuracy: 0.8632\n",
      "Epoch 1421/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0916 - accuracy: 0.8865 - val_loss: 26.0887 - val_accuracy: 0.8768\n",
      "Epoch 1422/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.3593 - accuracy: 0.8618 - val_loss: 16.1301 - val_accuracy: 0.8555\n",
      "Epoch 1423/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3931 - accuracy: 0.8681 - val_loss: 27.6694 - val_accuracy: 0.8632\n",
      "Epoch 1424/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.5698 - accuracy: 0.8698 - val_loss: 20.6802 - val_accuracy: 0.8923\n",
      "Epoch 1425/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4644 - accuracy: 0.8838 - val_loss: 17.2579 - val_accuracy: 0.8885\n",
      "Epoch 1426/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5002 - accuracy: 0.8724 - val_loss: 23.6199 - val_accuracy: 0.8535\n",
      "Epoch 1427/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1734 - accuracy: 0.8785 - val_loss: 16.0428 - val_accuracy: 0.8720\n",
      "Epoch 1428/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.4357 - accuracy: 0.8729 - val_loss: 17.3930 - val_accuracy: 0.8720\n",
      "Epoch 1429/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2675 - accuracy: 0.8763 - val_loss: 21.9123 - val_accuracy: 0.8371\n",
      "Epoch 1430/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5148 - accuracy: 0.8787 - val_loss: 19.4902 - val_accuracy: 0.8477\n",
      "Epoch 1431/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5235 - accuracy: 0.8722 - val_loss: 22.7979 - val_accuracy: 0.8749\n",
      "Epoch 1432/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5078 - accuracy: 0.8853 - val_loss: 20.0588 - val_accuracy: 0.8477\n",
      "Epoch 1433/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9239 - accuracy: 0.8668 - val_loss: 17.1297 - val_accuracy: 0.8089\n",
      "Epoch 1434/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0764 - accuracy: 0.8409 - val_loss: 20.9456 - val_accuracy: 0.8438\n",
      "Epoch 1435/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5285 - accuracy: 0.8705 - val_loss: 25.2415 - val_accuracy: 0.8855\n",
      "Epoch 1436/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7408 - accuracy: 0.8773 - val_loss: 20.2838 - val_accuracy: 0.8943\n",
      "Epoch 1437/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0795 - accuracy: 0.8778 - val_loss: 17.3081 - val_accuracy: 0.8623\n",
      "Epoch 1438/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6094 - accuracy: 0.8620 - val_loss: 24.4862 - val_accuracy: 0.8264\n",
      "Epoch 1439/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0532 - accuracy: 0.8547 - val_loss: 20.8065 - val_accuracy: 0.8739\n",
      "Epoch 1440/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.7312 - accuracy: 0.8702 - val_loss: 22.4827 - val_accuracy: 0.8099\n",
      "Epoch 1441/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4778 - accuracy: 0.8775 - val_loss: 20.3855 - val_accuracy: 0.8846\n",
      "Epoch 1442/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.5401 - accuracy: 0.8710 - val_loss: 21.8959 - val_accuracy: 0.8390\n",
      "Epoch 1443/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6171 - accuracy: 0.8717 - val_loss: 21.1941 - val_accuracy: 0.9020\n",
      "Epoch 1444/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2428 - accuracy: 0.8768 - val_loss: 21.1467 - val_accuracy: 0.8371\n",
      "Epoch 1445/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1977 - accuracy: 0.8586 - val_loss: 25.0668 - val_accuracy: 0.8497\n",
      "Epoch 1446/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3282 - accuracy: 0.8799 - val_loss: 20.3246 - val_accuracy: 0.8991\n",
      "Epoch 1447/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4960 - accuracy: 0.8758 - val_loss: 20.6549 - val_accuracy: 0.8885\n",
      "Epoch 1448/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3113 - accuracy: 0.8901 - val_loss: 25.2279 - val_accuracy: 0.8448\n",
      "Epoch 1449/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.5248 - accuracy: 0.8678 - val_loss: 22.6285 - val_accuracy: 0.8332\n",
      "Epoch 1450/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4597 - accuracy: 0.8678 - val_loss: 14.3219 - val_accuracy: 0.8797\n",
      "Epoch 1451/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0079 - accuracy: 0.8715 - val_loss: 24.6985 - val_accuracy: 0.8458\n",
      "Epoch 1452/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2317 - accuracy: 0.8685 - val_loss: 21.4389 - val_accuracy: 0.8390\n",
      "Epoch 1453/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5037 - accuracy: 0.8673 - val_loss: 18.6359 - val_accuracy: 0.8914\n",
      "Epoch 1454/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5274 - accuracy: 0.8824 - val_loss: 21.1565 - val_accuracy: 0.9001\n",
      "Epoch 1455/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3416 - accuracy: 0.8792 - val_loss: 17.2410 - val_accuracy: 0.8341\n",
      "Epoch 1456/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1937 - accuracy: 0.8748 - val_loss: 21.0239 - val_accuracy: 0.8904\n",
      "Epoch 1457/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5301 - accuracy: 0.8770 - val_loss: 24.2844 - val_accuracy: 0.8914\n",
      "Epoch 1458/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3947 - accuracy: 0.8802 - val_loss: 20.2051 - val_accuracy: 0.8788\n",
      "Epoch 1459/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2921 - accuracy: 0.8877 - val_loss: 20.0972 - val_accuracy: 0.8390\n",
      "Epoch 1460/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1917 - accuracy: 0.8739 - val_loss: 17.7082 - val_accuracy: 0.8661\n",
      "Epoch 1461/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3517 - accuracy: 0.8947 - val_loss: 19.0095 - val_accuracy: 0.8768\n",
      "Epoch 1462/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6127 - accuracy: 0.8705 - val_loss: 21.0783 - val_accuracy: 0.8758\n",
      "Epoch 1463/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4511 - accuracy: 0.8848 - val_loss: 21.8156 - val_accuracy: 0.8991\n",
      "Epoch 1464/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3994 - accuracy: 0.8853 - val_loss: 22.9401 - val_accuracy: 0.8303\n",
      "Epoch 1465/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1833 - accuracy: 0.8700 - val_loss: 18.6239 - val_accuracy: 0.8768\n",
      "Epoch 1466/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3128 - accuracy: 0.8809 - val_loss: 23.1689 - val_accuracy: 0.8681\n",
      "Epoch 1467/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2616 - accuracy: 0.8899 - val_loss: 24.5206 - val_accuracy: 0.8565\n",
      "Epoch 1468/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.5168 - accuracy: 0.8748 - val_loss: 19.0958 - val_accuracy: 0.8691\n",
      "Epoch 1469/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.1975 - accuracy: 0.8734 - val_loss: 26.1077 - val_accuracy: 0.8700\n",
      "Epoch 1470/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2199 - accuracy: 0.8831 - val_loss: 20.7009 - val_accuracy: 0.8885\n",
      "Epoch 1471/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.6034 - accuracy: 0.8843 - val_loss: 19.5795 - val_accuracy: 0.8865\n",
      "Epoch 1472/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.4963 - accuracy: 0.8812 - val_loss: 26.1360 - val_accuracy: 0.8700\n",
      "Epoch 1473/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1385 - accuracy: 0.8870 - val_loss: 20.4092 - val_accuracy: 0.8836\n",
      "Epoch 1474/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3714 - accuracy: 0.8860 - val_loss: 15.6094 - val_accuracy: 0.9001\n",
      "Epoch 1475/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1529 - accuracy: 0.8736 - val_loss: 16.3832 - val_accuracy: 0.8943\n",
      "Epoch 1476/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2547 - accuracy: 0.8894 - val_loss: 22.8297 - val_accuracy: 0.8933\n",
      "Epoch 1477/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3712 - accuracy: 0.8841 - val_loss: 17.8836 - val_accuracy: 0.8855\n",
      "Epoch 1478/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4614 - accuracy: 0.8785 - val_loss: 23.2458 - val_accuracy: 0.8962\n",
      "Epoch 1479/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.4779 - accuracy: 0.8887 - val_loss: 15.3483 - val_accuracy: 0.9011\n",
      "Epoch 1480/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0749 - accuracy: 0.8770 - val_loss: 19.5853 - val_accuracy: 0.8797\n",
      "Epoch 1481/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.1592 - accuracy: 0.8814 - val_loss: 17.6061 - val_accuracy: 0.8855\n",
      "Epoch 1482/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1658 - accuracy: 0.8938 - val_loss: 15.9428 - val_accuracy: 0.8933\n",
      "Epoch 1483/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3989 - accuracy: 0.8812 - val_loss: 15.4863 - val_accuracy: 0.9001\n",
      "Epoch 1484/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1480 - accuracy: 0.8875 - val_loss: 20.6795 - val_accuracy: 0.8671\n",
      "Epoch 1485/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.2881 - accuracy: 0.8831 - val_loss: 22.2518 - val_accuracy: 0.8438\n",
      "Epoch 1486/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.5835 - accuracy: 0.8799 - val_loss: 25.9136 - val_accuracy: 0.8506\n",
      "Epoch 1487/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3418 - accuracy: 0.8904 - val_loss: 19.2648 - val_accuracy: 0.8661\n",
      "Epoch 1488/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2762 - accuracy: 0.8875 - val_loss: 24.0274 - val_accuracy: 0.8458\n",
      "Epoch 1489/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4470 - accuracy: 0.8829 - val_loss: 23.2187 - val_accuracy: 0.8778\n",
      "Epoch 1490/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3617 - accuracy: 0.8690 - val_loss: 23.9643 - val_accuracy: 0.8865\n",
      "Epoch 1491/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1564 - accuracy: 0.8736 - val_loss: 18.5813 - val_accuracy: 0.8817\n",
      "Epoch 1492/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.1014 - accuracy: 0.8715 - val_loss: 23.3683 - val_accuracy: 0.8400\n",
      "Epoch 1493/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.3290 - accuracy: 0.8732 - val_loss: 21.8805 - val_accuracy: 0.8797\n",
      "Epoch 1494/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3453 - accuracy: 0.8877 - val_loss: 17.1290 - val_accuracy: 0.9001\n",
      "Epoch 1495/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3614 - accuracy: 0.8901 - val_loss: 17.2780 - val_accuracy: 0.8739\n",
      "Epoch 1496/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3274 - accuracy: 0.8889 - val_loss: 15.1789 - val_accuracy: 0.8982\n",
      "Epoch 1497/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8401 - accuracy: 0.8899 - val_loss: 18.0227 - val_accuracy: 0.7759\n",
      "Epoch 1498/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0625 - accuracy: 0.8795 - val_loss: 21.6429 - val_accuracy: 0.8691\n",
      "Epoch 1499/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1541 - accuracy: 0.8872 - val_loss: 20.7278 - val_accuracy: 0.8642\n",
      "Epoch 1500/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1513 - accuracy: 0.8765 - val_loss: 14.3486 - val_accuracy: 0.8468\n",
      "Epoch 1501/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8939 - accuracy: 0.8700 - val_loss: 22.5755 - val_accuracy: 0.8865\n",
      "Epoch 1502/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.4359 - accuracy: 0.8838 - val_loss: 16.3160 - val_accuracy: 0.8797\n",
      "Epoch 1503/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2629 - accuracy: 0.8753 - val_loss: 24.7875 - val_accuracy: 0.8497\n",
      "Epoch 1504/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5059 - accuracy: 0.8702 - val_loss: 22.7744 - val_accuracy: 0.8661\n",
      "Epoch 1505/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3521 - accuracy: 0.8778 - val_loss: 19.6895 - val_accuracy: 0.8807\n",
      "Epoch 1506/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5095 - accuracy: 0.8799 - val_loss: 16.4596 - val_accuracy: 0.8642\n",
      "Epoch 1507/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4299 - accuracy: 0.8761 - val_loss: 24.8735 - val_accuracy: 0.8623\n",
      "Epoch 1508/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3660 - accuracy: 0.8761 - val_loss: 19.2576 - val_accuracy: 0.8914\n",
      "Epoch 1509/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0384 - accuracy: 0.8782 - val_loss: 24.1379 - val_accuracy: 0.8419\n",
      "Epoch 1510/2000\n",
      "4123/4123 [==============================] - ETA: 0s - loss: 16.5370 - accuracy: 0.874 - 0s 21us/step - loss: 15.1500 - accuracy: 0.8804 - val_loss: 17.2745 - val_accuracy: 0.8914\n",
      "Epoch 1511/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1405 - accuracy: 0.8947 - val_loss: 21.3739 - val_accuracy: 0.8817\n",
      "Epoch 1512/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1747 - accuracy: 0.8826 - val_loss: 16.6860 - val_accuracy: 0.8274\n",
      "Epoch 1513/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4218 - accuracy: 0.8751 - val_loss: 24.9946 - val_accuracy: 0.8574\n",
      "Epoch 1514/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2930 - accuracy: 0.8782 - val_loss: 17.6100 - val_accuracy: 0.8768\n",
      "Epoch 1515/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.3070 - accuracy: 0.8887 - val_loss: 22.6365 - val_accuracy: 0.8157\n",
      "Epoch 1516/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2559 - accuracy: 0.8693 - val_loss: 19.8815 - val_accuracy: 0.8021\n",
      "Epoch 1517/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3314 - accuracy: 0.8564 - val_loss: 19.3258 - val_accuracy: 0.8797\n",
      "Epoch 1518/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.9203 - accuracy: 0.8816 - val_loss: 16.0958 - val_accuracy: 0.8322\n",
      "Epoch 1519/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7752 - accuracy: 0.8656 - val_loss: 23.4665 - val_accuracy: 0.8574\n",
      "Epoch 1520/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3096 - accuracy: 0.8821 - val_loss: 19.7660 - val_accuracy: 0.8206\n",
      "Epoch 1521/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2625 - accuracy: 0.8736 - val_loss: 18.7337 - val_accuracy: 0.8846\n",
      "Epoch 1522/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2735 - accuracy: 0.8850 - val_loss: 16.0083 - val_accuracy: 0.8506\n",
      "Epoch 1523/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0166 - accuracy: 0.8821 - val_loss: 20.0124 - val_accuracy: 0.8855\n",
      "Epoch 1524/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1883 - accuracy: 0.8814 - val_loss: 20.3036 - val_accuracy: 0.8749\n",
      "Epoch 1525/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.3963 - accuracy: 0.8812 - val_loss: 24.6942 - val_accuracy: 0.8594\n",
      "Epoch 1526/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2901 - accuracy: 0.8843 - val_loss: 20.2618 - val_accuracy: 0.8768\n",
      "Epoch 1527/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.3936 - accuracy: 0.8836 - val_loss: 25.6406 - val_accuracy: 0.8885\n",
      "Epoch 1528/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2494 - accuracy: 0.8773 - val_loss: 14.2393 - val_accuracy: 0.8904\n",
      "Epoch 1529/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7351 - accuracy: 0.8748 - val_loss: 23.3232 - val_accuracy: 0.8778\n",
      "Epoch 1530/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.6242 - accuracy: 0.8826 - val_loss: 18.8844 - val_accuracy: 0.8758\n",
      "Epoch 1531/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.2248 - accuracy: 0.8875 - val_loss: 19.0926 - val_accuracy: 0.8778\n",
      "Epoch 1532/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0248 - accuracy: 0.8792 - val_loss: 25.9644 - val_accuracy: 0.8865\n",
      "Epoch 1533/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2720 - accuracy: 0.8722 - val_loss: 17.8760 - val_accuracy: 0.8875\n",
      "Epoch 1534/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3594 - accuracy: 0.8761 - val_loss: 21.0891 - val_accuracy: 0.8177\n",
      "Epoch 1535/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3647 - accuracy: 0.8702 - val_loss: 25.4532 - val_accuracy: 0.8846\n",
      "Epoch 1536/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0718 - accuracy: 0.8872 - val_loss: 22.5368 - val_accuracy: 0.8788\n",
      "Epoch 1537/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2583 - accuracy: 0.8814 - val_loss: 22.3794 - val_accuracy: 0.8846\n",
      "Epoch 1538/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2892 - accuracy: 0.8838 - val_loss: 21.3589 - val_accuracy: 0.8933\n",
      "Epoch 1539/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3426 - accuracy: 0.8846 - val_loss: 21.4189 - val_accuracy: 0.8739\n",
      "Epoch 1540/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.3023 - accuracy: 0.8741 - val_loss: 23.5833 - val_accuracy: 0.8458\n",
      "Epoch 1541/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5114 - accuracy: 0.8797 - val_loss: 19.6910 - val_accuracy: 0.8758\n",
      "Epoch 1542/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2701 - accuracy: 0.8831 - val_loss: 22.7222 - val_accuracy: 0.8603\n",
      "Epoch 1543/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1906 - accuracy: 0.8695 - val_loss: 22.2614 - val_accuracy: 0.8788\n",
      "Epoch 1544/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4575 - accuracy: 0.8884 - val_loss: 20.8639 - val_accuracy: 0.8865\n",
      "Epoch 1545/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0403 - accuracy: 0.8601 - val_loss: 19.0830 - val_accuracy: 0.8855\n",
      "Epoch 1546/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1963 - accuracy: 0.8778 - val_loss: 19.4896 - val_accuracy: 0.8904\n",
      "Epoch 1547/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0454 - accuracy: 0.8765 - val_loss: 17.0818 - val_accuracy: 0.8914\n",
      "Epoch 1548/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0710 - accuracy: 0.8753 - val_loss: 16.2754 - val_accuracy: 0.8923\n",
      "Epoch 1549/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1942 - accuracy: 0.8739 - val_loss: 24.8664 - val_accuracy: 0.8807\n",
      "Epoch 1550/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1320 - accuracy: 0.8807 - val_loss: 23.4896 - val_accuracy: 0.8642\n",
      "Epoch 1551/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2706 - accuracy: 0.8819 - val_loss: 14.3897 - val_accuracy: 0.8661\n",
      "Epoch 1552/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7901 - accuracy: 0.8775 - val_loss: 24.8278 - val_accuracy: 0.8380\n",
      "Epoch 1553/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0501 - accuracy: 0.8659 - val_loss: 23.5215 - val_accuracy: 0.8855\n",
      "Epoch 1554/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3225 - accuracy: 0.8705 - val_loss: 19.2094 - val_accuracy: 0.8429\n",
      "Epoch 1555/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3023 - accuracy: 0.8598 - val_loss: 23.0199 - val_accuracy: 0.8739\n",
      "Epoch 1556/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.5096 - accuracy: 0.8618 - val_loss: 19.6001 - val_accuracy: 0.8691\n",
      "Epoch 1557/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2088 - accuracy: 0.8782 - val_loss: 19.1541 - val_accuracy: 0.8661\n",
      "Epoch 1558/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2084 - accuracy: 0.8761 - val_loss: 18.7129 - val_accuracy: 0.8758\n",
      "Epoch 1559/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1468 - accuracy: 0.8807 - val_loss: 23.8156 - val_accuracy: 0.8594\n",
      "Epoch 1560/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3751 - accuracy: 0.8804 - val_loss: 21.4397 - val_accuracy: 0.8836\n",
      "Epoch 1561/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2774 - accuracy: 0.8911 - val_loss: 14.4653 - val_accuracy: 0.8642\n",
      "Epoch 1562/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9816 - accuracy: 0.8831 - val_loss: 20.4341 - val_accuracy: 0.8758\n",
      "Epoch 1563/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1994 - accuracy: 0.8727 - val_loss: 24.2664 - val_accuracy: 0.8729\n",
      "Epoch 1564/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3740 - accuracy: 0.8787 - val_loss: 17.9693 - val_accuracy: 0.8545\n",
      "Epoch 1565/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1828 - accuracy: 0.8882 - val_loss: 23.4422 - val_accuracy: 0.8419\n",
      "Epoch 1566/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3575 - accuracy: 0.8882 - val_loss: 22.5873 - val_accuracy: 0.8584\n",
      "Epoch 1567/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2539 - accuracy: 0.8782 - val_loss: 25.9768 - val_accuracy: 0.8312\n",
      "Epoch 1568/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3698 - accuracy: 0.8634 - val_loss: 25.2124 - val_accuracy: 0.8390\n",
      "Epoch 1569/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2870 - accuracy: 0.8809 - val_loss: 17.4316 - val_accuracy: 0.8768\n",
      "Epoch 1570/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0933 - accuracy: 0.8732 - val_loss: 16.3865 - val_accuracy: 0.8623\n",
      "Epoch 1571/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2543 - accuracy: 0.8785 - val_loss: 21.5863 - val_accuracy: 0.8555\n",
      "Epoch 1572/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0734 - accuracy: 0.8695 - val_loss: 15.1835 - val_accuracy: 0.8778\n",
      "Epoch 1573/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1422 - accuracy: 0.8768 - val_loss: 23.8874 - val_accuracy: 0.8807\n",
      "Epoch 1574/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3894 - accuracy: 0.8748 - val_loss: 14.9915 - val_accuracy: 0.8177\n",
      "Epoch 1575/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1145 - accuracy: 0.8768 - val_loss: 13.9651 - val_accuracy: 0.8661\n",
      "Epoch 1576/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.7385 - accuracy: 0.8858 - val_loss: 14.0625 - val_accuracy: 0.8885\n",
      "Epoch 1577/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9330 - accuracy: 0.8829 - val_loss: 17.4011 - val_accuracy: 0.8846\n",
      "Epoch 1578/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4944 - accuracy: 0.8661 - val_loss: 23.6480 - val_accuracy: 0.8797\n",
      "Epoch 1579/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.8177 - accuracy: 0.8780 - val_loss: 16.9807 - val_accuracy: 0.7371\n",
      "Epoch 1580/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.6282 - accuracy: 0.8596 - val_loss: 25.2828 - val_accuracy: 0.8875\n",
      "Epoch 1581/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0343 - accuracy: 0.8761 - val_loss: 24.1528 - val_accuracy: 0.8332\n",
      "Epoch 1582/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3045 - accuracy: 0.8814 - val_loss: 19.6303 - val_accuracy: 0.8341\n",
      "Epoch 1583/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.3004 - accuracy: 0.8455 - val_loss: 19.3214 - val_accuracy: 0.8788\n",
      "Epoch 1584/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1986 - accuracy: 0.8775 - val_loss: 23.5867 - val_accuracy: 0.8720\n",
      "Epoch 1585/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.0239 - accuracy: 0.8678 - val_loss: 15.3078 - val_accuracy: 0.8826\n",
      "Epoch 1586/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.1124 - accuracy: 0.8875 - val_loss: 19.9478 - val_accuracy: 0.8565\n",
      "Epoch 1587/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.1026 - accuracy: 0.8632 - val_loss: 22.7725 - val_accuracy: 0.8584\n",
      "Epoch 1588/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1149 - accuracy: 0.8792 - val_loss: 23.1013 - val_accuracy: 0.8632\n",
      "Epoch 1589/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0408 - accuracy: 0.8831 - val_loss: 19.3300 - val_accuracy: 0.8797\n",
      "Epoch 1590/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9052 - accuracy: 0.8741 - val_loss: 16.1402 - val_accuracy: 0.9079\n",
      "Epoch 1591/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9306 - accuracy: 0.8802 - val_loss: 21.5947 - val_accuracy: 0.8865\n",
      "Epoch 1592/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4515 - accuracy: 0.8862 - val_loss: 16.5943 - val_accuracy: 0.8691\n",
      "Epoch 1593/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0534 - accuracy: 0.8858 - val_loss: 22.5543 - val_accuracy: 0.8371\n",
      "Epoch 1594/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0028 - accuracy: 0.8598 - val_loss: 15.2129 - val_accuracy: 0.8739\n",
      "Epoch 1595/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0483 - accuracy: 0.8751 - val_loss: 22.5885 - val_accuracy: 0.8147\n",
      "Epoch 1596/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3843 - accuracy: 0.8799 - val_loss: 27.2050 - val_accuracy: 0.8952\n",
      "Epoch 1597/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7602 - accuracy: 0.8719 - val_loss: 14.8603 - val_accuracy: 0.8865\n",
      "Epoch 1598/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9179 - accuracy: 0.8695 - val_loss: 19.0199 - val_accuracy: 0.8904\n",
      "Epoch 1599/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2268 - accuracy: 0.8855 - val_loss: 23.8457 - val_accuracy: 0.8516\n",
      "Epoch 1600/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1907 - accuracy: 0.8790 - val_loss: 15.5042 - val_accuracy: 0.8603\n",
      "Epoch 1601/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8441 - accuracy: 0.8797 - val_loss: 18.5641 - val_accuracy: 0.8817\n",
      "Epoch 1602/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0758 - accuracy: 0.8802 - val_loss: 21.1703 - val_accuracy: 0.8710\n",
      "Epoch 1603/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3279 - accuracy: 0.8678 - val_loss: 23.8618 - val_accuracy: 0.8623\n",
      "Epoch 1604/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1828 - accuracy: 0.8807 - val_loss: 23.0373 - val_accuracy: 0.8914\n",
      "Epoch 1605/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1402 - accuracy: 0.8841 - val_loss: 14.8595 - val_accuracy: 0.8506\n",
      "Epoch 1606/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6760 - accuracy: 0.8829 - val_loss: 19.0992 - val_accuracy: 0.7973\n",
      "Epoch 1607/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1391 - accuracy: 0.8702 - val_loss: 20.5305 - val_accuracy: 0.8613\n",
      "Epoch 1608/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3345 - accuracy: 0.8809 - val_loss: 22.0879 - val_accuracy: 0.8419\n",
      "Epoch 1609/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3733 - accuracy: 0.8778 - val_loss: 26.7737 - val_accuracy: 0.8768\n",
      "Epoch 1610/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2311 - accuracy: 0.8763 - val_loss: 18.9117 - val_accuracy: 0.8952\n",
      "Epoch 1611/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2176 - accuracy: 0.8707 - val_loss: 23.3981 - val_accuracy: 0.8720\n",
      "Epoch 1612/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1986 - accuracy: 0.8814 - val_loss: 17.0951 - val_accuracy: 0.8807\n",
      "Epoch 1613/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0812 - accuracy: 0.8904 - val_loss: 17.7722 - val_accuracy: 0.8885\n",
      "Epoch 1614/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.3134 - accuracy: 0.8756 - val_loss: 17.9825 - val_accuracy: 0.8826\n",
      "Epoch 1615/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9023 - accuracy: 0.8829 - val_loss: 21.9214 - val_accuracy: 0.8409\n",
      "Epoch 1616/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1950 - accuracy: 0.8807 - val_loss: 16.9666 - val_accuracy: 0.8797\n",
      "Epoch 1617/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9332 - accuracy: 0.8693 - val_loss: 16.6739 - val_accuracy: 0.8147\n",
      "Epoch 1618/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3817 - accuracy: 0.8875 - val_loss: 22.2940 - val_accuracy: 0.8904\n",
      "Epoch 1619/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0460 - accuracy: 0.8896 - val_loss: 21.3892 - val_accuracy: 0.8855\n",
      "Epoch 1620/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9519 - accuracy: 0.8734 - val_loss: 22.4681 - val_accuracy: 0.8923\n",
      "Epoch 1621/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3608 - accuracy: 0.8867 - val_loss: 21.2600 - val_accuracy: 0.8681\n",
      "Epoch 1622/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3375 - accuracy: 0.8807 - val_loss: 23.0275 - val_accuracy: 0.8167\n",
      "Epoch 1623/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8352 - accuracy: 0.8681 - val_loss: 21.1107 - val_accuracy: 0.8613\n",
      "Epoch 1624/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.4854 - accuracy: 0.8799 - val_loss: 19.1332 - val_accuracy: 0.8788\n",
      "Epoch 1625/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.9766 - accuracy: 0.8833 - val_loss: 22.0174 - val_accuracy: 0.8574\n",
      "Epoch 1626/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1086 - accuracy: 0.8841 - val_loss: 16.4707 - val_accuracy: 0.8904\n",
      "Epoch 1627/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9791 - accuracy: 0.8824 - val_loss: 22.1166 - val_accuracy: 0.8497\n",
      "Epoch 1628/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2488 - accuracy: 0.8790 - val_loss: 21.8352 - val_accuracy: 0.8535\n",
      "Epoch 1629/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.3097 - accuracy: 0.8700 - val_loss: 19.3918 - val_accuracy: 0.8817\n",
      "Epoch 1630/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.1107 - accuracy: 0.8785 - val_loss: 25.6327 - val_accuracy: 0.8894\n",
      "Epoch 1631/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0865 - accuracy: 0.8666 - val_loss: 15.4336 - val_accuracy: 0.8836\n",
      "Epoch 1632/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9275 - accuracy: 0.8867 - val_loss: 22.6037 - val_accuracy: 0.8109\n",
      "Epoch 1633/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9397 - accuracy: 0.8681 - val_loss: 24.5578 - val_accuracy: 0.8739\n",
      "Epoch 1634/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1516 - accuracy: 0.8736 - val_loss: 19.0110 - val_accuracy: 0.8943\n",
      "Epoch 1635/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4539 - accuracy: 0.8879 - val_loss: 17.1832 - val_accuracy: 0.8409\n",
      "Epoch 1636/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3033 - accuracy: 0.8758 - val_loss: 20.2505 - val_accuracy: 0.8817\n",
      "Epoch 1637/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1872 - accuracy: 0.8765 - val_loss: 25.7935 - val_accuracy: 0.8797\n",
      "Epoch 1638/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.3571 - accuracy: 0.8780 - val_loss: 23.6354 - val_accuracy: 0.8749\n",
      "Epoch 1639/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3215 - accuracy: 0.8741 - val_loss: 18.0071 - val_accuracy: 0.8817\n",
      "Epoch 1640/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1185 - accuracy: 0.8838 - val_loss: 22.9221 - val_accuracy: 0.8681\n",
      "Epoch 1641/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.5032 - accuracy: 0.8671 - val_loss: 17.4099 - val_accuracy: 0.8710\n",
      "Epoch 1642/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9385 - accuracy: 0.8848 - val_loss: 18.2007 - val_accuracy: 0.8894\n",
      "Epoch 1643/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2146 - accuracy: 0.8911 - val_loss: 21.7851 - val_accuracy: 0.8642\n",
      "Epoch 1644/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.3195 - accuracy: 0.8799 - val_loss: 16.4596 - val_accuracy: 0.8855\n",
      "Epoch 1645/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7235 - accuracy: 0.8753 - val_loss: 17.3698 - val_accuracy: 0.8254\n",
      "Epoch 1646/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9989 - accuracy: 0.8809 - val_loss: 14.9176 - val_accuracy: 0.8875\n",
      "Epoch 1647/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0384 - accuracy: 0.8841 - val_loss: 29.4748 - val_accuracy: 0.7711\n",
      "Epoch 1648/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2433 - accuracy: 0.8567 - val_loss: 24.1954 - val_accuracy: 0.8409\n",
      "Epoch 1649/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.4292 - accuracy: 0.8799 - val_loss: 21.0532 - val_accuracy: 0.8623\n",
      "Epoch 1650/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1977 - accuracy: 0.8831 - val_loss: 16.2232 - val_accuracy: 0.8817\n",
      "Epoch 1651/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2831 - accuracy: 0.8831 - val_loss: 18.4377 - val_accuracy: 0.8826\n",
      "Epoch 1652/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8171 - accuracy: 0.8620 - val_loss: 21.0473 - val_accuracy: 0.8371\n",
      "Epoch 1653/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.3239 - accuracy: 0.8727 - val_loss: 27.4611 - val_accuracy: 0.8584\n",
      "Epoch 1654/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7409 - accuracy: 0.8702 - val_loss: 18.9302 - val_accuracy: 0.8206\n",
      "Epoch 1655/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9995 - accuracy: 0.8778 - val_loss: 17.2648 - val_accuracy: 0.8565\n",
      "Epoch 1656/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9362 - accuracy: 0.8821 - val_loss: 22.2330 - val_accuracy: 0.8788\n",
      "Epoch 1657/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.9238 - accuracy: 0.8867 - val_loss: 24.1106 - val_accuracy: 0.8458\n",
      "Epoch 1658/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9938 - accuracy: 0.8853 - val_loss: 24.3347 - val_accuracy: 0.8817\n",
      "Epoch 1659/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8952 - accuracy: 0.8763 - val_loss: 24.2304 - val_accuracy: 0.8817\n",
      "Epoch 1660/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.2192 - accuracy: 0.8814 - val_loss: 19.2362 - val_accuracy: 0.8729\n",
      "Epoch 1661/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0435 - accuracy: 0.8785 - val_loss: 25.3135 - val_accuracy: 0.9001\n",
      "Epoch 1662/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.8243 - accuracy: 0.8702 - val_loss: 23.7046 - val_accuracy: 0.8914\n",
      "Epoch 1663/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9927 - accuracy: 0.8671 - val_loss: 21.3447 - val_accuracy: 0.9127\n",
      "Epoch 1664/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2469 - accuracy: 0.8896 - val_loss: 23.3948 - val_accuracy: 0.8904\n",
      "Epoch 1665/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2422 - accuracy: 0.8770 - val_loss: 24.9225 - val_accuracy: 0.8739\n",
      "Epoch 1666/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.2333 - accuracy: 0.8765 - val_loss: 17.5363 - val_accuracy: 0.8729\n",
      "Epoch 1667/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1374 - accuracy: 0.8761 - val_loss: 23.3891 - val_accuracy: 0.8875\n",
      "Epoch 1668/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2267 - accuracy: 0.8838 - val_loss: 19.0584 - val_accuracy: 0.9137\n",
      "Epoch 1669/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1035 - accuracy: 0.8795 - val_loss: 17.1618 - val_accuracy: 0.8681\n",
      "Epoch 1670/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0814 - accuracy: 0.8824 - val_loss: 20.2656 - val_accuracy: 0.8661\n",
      "Epoch 1671/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1661 - accuracy: 0.8855 - val_loss: 17.8867 - val_accuracy: 0.8865\n",
      "Epoch 1672/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3024 - accuracy: 0.8797 - val_loss: 22.9480 - val_accuracy: 0.8807\n",
      "Epoch 1673/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 14.7822 - accuracy: 0.8727 - val_loss: 15.8024 - val_accuracy: 0.9001\n",
      "Epoch 1674/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.0946 - accuracy: 0.8775 - val_loss: 19.6508 - val_accuracy: 0.8885\n",
      "Epoch 1675/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2159 - accuracy: 0.8792 - val_loss: 20.7661 - val_accuracy: 0.8826\n",
      "Epoch 1676/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2749 - accuracy: 0.8862 - val_loss: 20.7788 - val_accuracy: 0.8729\n",
      "Epoch 1677/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2823 - accuracy: 0.8872 - val_loss: 22.8245 - val_accuracy: 0.8836\n",
      "Epoch 1678/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0177 - accuracy: 0.8780 - val_loss: 25.8467 - val_accuracy: 0.8574\n",
      "Epoch 1679/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8117 - accuracy: 0.8812 - val_loss: 16.9449 - val_accuracy: 0.8943\n",
      "Epoch 1680/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9369 - accuracy: 0.8795 - val_loss: 20.3983 - val_accuracy: 0.8632\n",
      "Epoch 1681/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.3918 - accuracy: 0.8816 - val_loss: 16.9003 - val_accuracy: 0.8962\n",
      "Epoch 1682/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.9723 - accuracy: 0.8758 - val_loss: 23.0041 - val_accuracy: 0.8380\n",
      "Epoch 1683/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.1558 - accuracy: 0.8773 - val_loss: 14.1178 - val_accuracy: 0.8613\n",
      "Epoch 1684/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.6273 - accuracy: 0.8792 - val_loss: 19.7066 - val_accuracy: 0.8400\n",
      "Epoch 1685/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3217 - accuracy: 0.8782 - val_loss: 20.9125 - val_accuracy: 0.8700\n",
      "Epoch 1686/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1632 - accuracy: 0.8695 - val_loss: 24.1758 - val_accuracy: 0.8613\n",
      "Epoch 1687/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9691 - accuracy: 0.8838 - val_loss: 20.2183 - val_accuracy: 0.8623\n",
      "Epoch 1688/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9760 - accuracy: 0.8739 - val_loss: 25.4847 - val_accuracy: 0.8312\n",
      "Epoch 1689/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1605 - accuracy: 0.8816 - val_loss: 21.3490 - val_accuracy: 0.8710\n",
      "Epoch 1690/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9742 - accuracy: 0.8790 - val_loss: 20.3134 - val_accuracy: 0.8739\n",
      "Epoch 1691/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0827 - accuracy: 0.8758 - val_loss: 15.9777 - val_accuracy: 0.8487\n",
      "Epoch 1692/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9474 - accuracy: 0.8756 - val_loss: 15.5026 - val_accuracy: 0.8749\n",
      "Epoch 1693/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2446 - accuracy: 0.8729 - val_loss: 22.0069 - val_accuracy: 0.8671\n",
      "Epoch 1694/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2317 - accuracy: 0.8807 - val_loss: 16.7324 - val_accuracy: 0.8700\n",
      "Epoch 1695/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9702 - accuracy: 0.8746 - val_loss: 18.7022 - val_accuracy: 0.8623\n",
      "Epoch 1696/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0468 - accuracy: 0.8618 - val_loss: 22.0126 - val_accuracy: 0.8419\n",
      "Epoch 1697/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2092 - accuracy: 0.8610 - val_loss: 14.2350 - val_accuracy: 0.8535\n",
      "Epoch 1698/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.5226 - accuracy: 0.8790 - val_loss: 25.0815 - val_accuracy: 0.8235\n",
      "Epoch 1699/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0756 - accuracy: 0.8870 - val_loss: 21.2894 - val_accuracy: 0.8962\n",
      "Epoch 1700/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0646 - accuracy: 0.8795 - val_loss: 21.1565 - val_accuracy: 0.8341\n",
      "Epoch 1701/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.9121 - accuracy: 0.8724 - val_loss: 20.2133 - val_accuracy: 0.8758\n",
      "Epoch 1702/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.3439 - accuracy: 0.8644 - val_loss: 18.7505 - val_accuracy: 0.8671\n",
      "Epoch 1703/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1043 - accuracy: 0.8780 - val_loss: 18.6539 - val_accuracy: 0.9011\n",
      "Epoch 1704/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0002 - accuracy: 0.8807 - val_loss: 20.6386 - val_accuracy: 0.8565\n",
      "Epoch 1705/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1950 - accuracy: 0.8727 - val_loss: 20.8499 - val_accuracy: 0.8535\n",
      "Epoch 1706/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.0448 - accuracy: 0.8790 - val_loss: 19.8167 - val_accuracy: 0.8885\n",
      "Epoch 1707/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7394 - accuracy: 0.8683 - val_loss: 25.0976 - val_accuracy: 0.8642\n",
      "Epoch 1708/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1219 - accuracy: 0.8756 - val_loss: 15.5458 - val_accuracy: 0.8855\n",
      "Epoch 1709/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0429 - accuracy: 0.8826 - val_loss: 13.8728 - val_accuracy: 0.8758\n",
      "Epoch 1710/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.2917 - accuracy: 0.8751 - val_loss: 25.4543 - val_accuracy: 0.8855\n",
      "Epoch 1711/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.5766 - accuracy: 0.8545 - val_loss: 19.8599 - val_accuracy: 0.8749\n",
      "Epoch 1712/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2134 - accuracy: 0.8770 - val_loss: 25.8331 - val_accuracy: 0.8865\n",
      "Epoch 1713/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9638 - accuracy: 0.8870 - val_loss: 21.1455 - val_accuracy: 0.8836\n",
      "Epoch 1714/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.2134 - accuracy: 0.8807 - val_loss: 20.2407 - val_accuracy: 0.8797\n",
      "Epoch 1715/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1908 - accuracy: 0.8853 - val_loss: 18.4788 - val_accuracy: 0.8177\n",
      "Epoch 1716/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1338 - accuracy: 0.8782 - val_loss: 20.2355 - val_accuracy: 0.8865\n",
      "Epoch 1717/2000\n",
      "4123/4123 [==============================] - ETA: 0s - loss: 15.1515 - accuracy: 0.841 - 0s 22us/step - loss: 14.9660 - accuracy: 0.8455 - val_loss: 29.5292 - val_accuracy: 0.8206\n",
      "Epoch 1718/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3044 - accuracy: 0.8649 - val_loss: 22.3892 - val_accuracy: 0.8817\n",
      "Epoch 1719/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.1884 - accuracy: 0.8787 - val_loss: 14.4023 - val_accuracy: 0.8691\n",
      "Epoch 1720/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7917 - accuracy: 0.8816 - val_loss: 23.6830 - val_accuracy: 0.8535\n",
      "Epoch 1721/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8844 - accuracy: 0.8775 - val_loss: 14.3654 - val_accuracy: 0.8817\n",
      "Epoch 1722/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8946 - accuracy: 0.8700 - val_loss: 20.9204 - val_accuracy: 0.7808\n",
      "Epoch 1723/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1969 - accuracy: 0.8639 - val_loss: 16.8775 - val_accuracy: 0.8739\n",
      "Epoch 1724/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9060 - accuracy: 0.8802 - val_loss: 21.4909 - val_accuracy: 0.8991\n",
      "Epoch 1725/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1012 - accuracy: 0.8785 - val_loss: 20.6648 - val_accuracy: 0.8817\n",
      "Epoch 1726/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.5597 - accuracy: 0.8656 - val_loss: 19.9721 - val_accuracy: 0.8196\n",
      "Epoch 1727/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6958 - accuracy: 0.8751 - val_loss: 21.7093 - val_accuracy: 0.8729\n",
      "Epoch 1728/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1022 - accuracy: 0.8843 - val_loss: 21.8023 - val_accuracy: 0.8758\n",
      "Epoch 1729/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8741 - accuracy: 0.8882 - val_loss: 22.2673 - val_accuracy: 0.8710\n",
      "Epoch 1730/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1422 - accuracy: 0.8765 - val_loss: 20.7504 - val_accuracy: 0.8923\n",
      "Epoch 1731/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0844 - accuracy: 0.8804 - val_loss: 24.1315 - val_accuracy: 0.8797\n",
      "Epoch 1732/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1833 - accuracy: 0.8700 - val_loss: 22.6368 - val_accuracy: 0.8826\n",
      "Epoch 1733/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.3412 - accuracy: 0.8768 - val_loss: 21.8559 - val_accuracy: 0.8623\n",
      "Epoch 1734/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.1774 - accuracy: 0.8804 - val_loss: 22.9044 - val_accuracy: 0.8332\n",
      "Epoch 1735/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1038 - accuracy: 0.8826 - val_loss: 20.7305 - val_accuracy: 0.8904\n",
      "Epoch 1736/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0618 - accuracy: 0.8831 - val_loss: 20.5177 - val_accuracy: 0.8758\n",
      "Epoch 1737/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1624 - accuracy: 0.8843 - val_loss: 14.9038 - val_accuracy: 0.8652\n",
      "Epoch 1738/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6583 - accuracy: 0.8729 - val_loss: 21.6042 - val_accuracy: 0.8778\n",
      "Epoch 1739/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1210 - accuracy: 0.8739 - val_loss: 18.8485 - val_accuracy: 0.8788\n",
      "Epoch 1740/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7481 - accuracy: 0.8821 - val_loss: 20.4711 - val_accuracy: 0.8293\n",
      "Epoch 1741/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2068 - accuracy: 0.8831 - val_loss: 15.8586 - val_accuracy: 0.8177\n",
      "Epoch 1742/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0043 - accuracy: 0.8812 - val_loss: 18.6272 - val_accuracy: 0.8448\n",
      "Epoch 1743/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6619 - accuracy: 0.8664 - val_loss: 21.6333 - val_accuracy: 0.8933\n",
      "Epoch 1744/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6465 - accuracy: 0.8770 - val_loss: 15.9114 - val_accuracy: 0.8225\n",
      "Epoch 1745/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7977 - accuracy: 0.8758 - val_loss: 17.0541 - val_accuracy: 0.8254\n",
      "Epoch 1746/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9524 - accuracy: 0.8736 - val_loss: 19.2696 - val_accuracy: 0.8720\n",
      "Epoch 1747/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9606 - accuracy: 0.8829 - val_loss: 17.9052 - val_accuracy: 0.8817\n",
      "Epoch 1748/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0207 - accuracy: 0.8855 - val_loss: 17.8532 - val_accuracy: 0.8788\n",
      "Epoch 1749/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0280 - accuracy: 0.8824 - val_loss: 18.9420 - val_accuracy: 0.8681\n",
      "Epoch 1750/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1428 - accuracy: 0.8630 - val_loss: 23.7660 - val_accuracy: 0.8836\n",
      "Epoch 1751/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.3382 - accuracy: 0.8753 - val_loss: 24.1278 - val_accuracy: 0.8652\n",
      "Epoch 1752/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8018 - accuracy: 0.8732 - val_loss: 21.0626 - val_accuracy: 0.8729\n",
      "Epoch 1753/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1651 - accuracy: 0.8855 - val_loss: 20.5823 - val_accuracy: 0.8477\n",
      "Epoch 1754/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0927 - accuracy: 0.8829 - val_loss: 13.8413 - val_accuracy: 0.8671\n",
      "Epoch 1755/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.5480 - accuracy: 0.8659 - val_loss: 16.3069 - val_accuracy: 0.8167\n",
      "Epoch 1756/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6289 - accuracy: 0.8826 - val_loss: 21.3075 - val_accuracy: 0.9020\n",
      "Epoch 1757/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.9612 - accuracy: 0.8926 - val_loss: 20.2487 - val_accuracy: 0.8943\n",
      "Epoch 1758/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 14.8241 - accuracy: 0.8722 - val_loss: 24.1254 - val_accuracy: 0.8952\n",
      "Epoch 1759/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9106 - accuracy: 0.8588 - val_loss: 18.9954 - val_accuracy: 0.8312\n",
      "Epoch 1760/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9528 - accuracy: 0.8712 - val_loss: 14.3652 - val_accuracy: 0.8545\n",
      "Epoch 1761/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9938 - accuracy: 0.8778 - val_loss: 23.4007 - val_accuracy: 0.8797\n",
      "Epoch 1762/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9059 - accuracy: 0.8802 - val_loss: 28.4137 - val_accuracy: 0.8729\n",
      "Epoch 1763/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0558 - accuracy: 0.8802 - val_loss: 25.6777 - val_accuracy: 0.8817\n",
      "Epoch 1764/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8952 - accuracy: 0.8734 - val_loss: 18.3175 - val_accuracy: 0.8952\n",
      "Epoch 1765/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1607 - accuracy: 0.8700 - val_loss: 19.5825 - val_accuracy: 0.8603\n",
      "Epoch 1766/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0567 - accuracy: 0.8799 - val_loss: 18.9956 - val_accuracy: 0.8293\n",
      "Epoch 1767/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.9735 - accuracy: 0.8698 - val_loss: 22.2374 - val_accuracy: 0.8312\n",
      "Epoch 1768/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1388 - accuracy: 0.8748 - val_loss: 25.3828 - val_accuracy: 0.8817\n",
      "Epoch 1769/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 14.8192 - accuracy: 0.8797 - val_loss: 21.6400 - val_accuracy: 0.8778\n",
      "Epoch 1770/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8536 - accuracy: 0.8693 - val_loss: 17.1407 - val_accuracy: 0.8274\n",
      "Epoch 1771/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1319 - accuracy: 0.8761 - val_loss: 19.2462 - val_accuracy: 0.8817\n",
      "Epoch 1772/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2398 - accuracy: 0.8860 - val_loss: 18.7165 - val_accuracy: 0.8914\n",
      "Epoch 1773/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0179 - accuracy: 0.8668 - val_loss: 17.5224 - val_accuracy: 0.8865\n",
      "Epoch 1774/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0347 - accuracy: 0.8729 - val_loss: 21.7351 - val_accuracy: 0.8244\n",
      "Epoch 1775/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0514 - accuracy: 0.8656 - val_loss: 21.4833 - val_accuracy: 0.8167\n",
      "Epoch 1776/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.1914 - accuracy: 0.8814 - val_loss: 16.4306 - val_accuracy: 0.8661\n",
      "Epoch 1777/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 14.6567 - accuracy: 0.8768 - val_loss: 17.7316 - val_accuracy: 0.8109\n",
      "Epoch 1778/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6346 - accuracy: 0.8627 - val_loss: 16.9478 - val_accuracy: 0.8574\n",
      "Epoch 1779/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0215 - accuracy: 0.8693 - val_loss: 20.3595 - val_accuracy: 0.8846\n",
      "Epoch 1780/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0413 - accuracy: 0.8671 - val_loss: 20.3272 - val_accuracy: 0.8555\n",
      "Epoch 1781/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.9083 - accuracy: 0.8712 - val_loss: 17.0134 - val_accuracy: 0.8739\n",
      "Epoch 1782/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 14.7944 - accuracy: 0.8756 - val_loss: 19.6919 - val_accuracy: 0.8671\n",
      "Epoch 1783/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8732 - accuracy: 0.8795 - val_loss: 20.1954 - val_accuracy: 0.8729\n",
      "Epoch 1784/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1372 - accuracy: 0.8722 - val_loss: 19.1838 - val_accuracy: 0.8729\n",
      "Epoch 1785/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0220 - accuracy: 0.8819 - val_loss: 19.9065 - val_accuracy: 0.8768\n",
      "Epoch 1786/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9338 - accuracy: 0.8833 - val_loss: 17.1207 - val_accuracy: 0.8797\n",
      "Epoch 1787/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8113 - accuracy: 0.8768 - val_loss: 16.2687 - val_accuracy: 0.8952\n",
      "Epoch 1788/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8762 - accuracy: 0.8770 - val_loss: 17.5008 - val_accuracy: 0.8720\n",
      "Epoch 1789/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.5794 - accuracy: 0.8727 - val_loss: 14.1138 - val_accuracy: 0.8584\n",
      "Epoch 1790/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7568 - accuracy: 0.8765 - val_loss: 17.3646 - val_accuracy: 0.8312\n",
      "Epoch 1791/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1565 - accuracy: 0.8717 - val_loss: 17.2279 - val_accuracy: 0.8797\n",
      "Epoch 1792/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0593 - accuracy: 0.8681 - val_loss: 21.8627 - val_accuracy: 0.8341\n",
      "Epoch 1793/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1742 - accuracy: 0.8770 - val_loss: 13.7105 - val_accuracy: 0.8574\n",
      "Epoch 1794/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6429 - accuracy: 0.8690 - val_loss: 23.9167 - val_accuracy: 0.8652\n",
      "Epoch 1795/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8883 - accuracy: 0.8785 - val_loss: 19.8796 - val_accuracy: 0.8758\n",
      "Epoch 1796/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0882 - accuracy: 0.8736 - val_loss: 21.3444 - val_accuracy: 0.8720\n",
      "Epoch 1797/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0709 - accuracy: 0.8724 - val_loss: 18.2522 - val_accuracy: 0.8846\n",
      "Epoch 1798/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9886 - accuracy: 0.8833 - val_loss: 15.1022 - val_accuracy: 0.8933\n",
      "Epoch 1799/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6044 - accuracy: 0.8685 - val_loss: 21.0037 - val_accuracy: 0.8778\n",
      "Epoch 1800/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0348 - accuracy: 0.8792 - val_loss: 22.3116 - val_accuracy: 0.8545\n",
      "Epoch 1801/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9217 - accuracy: 0.8710 - val_loss: 17.3980 - val_accuracy: 0.8768\n",
      "Epoch 1802/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8443 - accuracy: 0.8807 - val_loss: 14.6829 - val_accuracy: 0.8671\n",
      "Epoch 1803/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7712 - accuracy: 0.8676 - val_loss: 18.3579 - val_accuracy: 0.8409\n",
      "Epoch 1804/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0663 - accuracy: 0.8649 - val_loss: 25.1495 - val_accuracy: 0.8846\n",
      "Epoch 1805/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8957 - accuracy: 0.8785 - val_loss: 22.1153 - val_accuracy: 0.8865\n",
      "Epoch 1806/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0441 - accuracy: 0.8797 - val_loss: 19.4274 - val_accuracy: 0.8555\n",
      "Epoch 1807/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0472 - accuracy: 0.8569 - val_loss: 17.2896 - val_accuracy: 0.8923\n",
      "Epoch 1808/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9997 - accuracy: 0.8751 - val_loss: 26.6684 - val_accuracy: 0.8758\n",
      "Epoch 1809/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0850 - accuracy: 0.8792 - val_loss: 25.8167 - val_accuracy: 0.8565\n",
      "Epoch 1810/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9240 - accuracy: 0.8702 - val_loss: 28.6444 - val_accuracy: 0.8244\n",
      "Epoch 1811/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9869 - accuracy: 0.8683 - val_loss: 24.7728 - val_accuracy: 0.8458\n",
      "Epoch 1812/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2461 - accuracy: 0.8719 - val_loss: 15.1688 - val_accuracy: 0.8729\n",
      "Epoch 1813/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 14.8295 - accuracy: 0.8756 - val_loss: 23.6450 - val_accuracy: 0.8758\n",
      "Epoch 1814/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9838 - accuracy: 0.8719 - val_loss: 17.4214 - val_accuracy: 0.8526\n",
      "Epoch 1815/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.5920 - accuracy: 0.8729 - val_loss: 21.0549 - val_accuracy: 0.8603\n",
      "Epoch 1816/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.1588 - accuracy: 0.8814 - val_loss: 17.7514 - val_accuracy: 0.8894\n",
      "Epoch 1817/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1232 - accuracy: 0.8797 - val_loss: 22.5414 - val_accuracy: 0.8661\n",
      "Epoch 1818/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.4795 - accuracy: 0.8795 - val_loss: 18.5221 - val_accuracy: 0.8671\n",
      "Epoch 1819/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0400 - accuracy: 0.8688 - val_loss: 19.9529 - val_accuracy: 0.8565\n",
      "Epoch 1820/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.1292 - accuracy: 0.8707 - val_loss: 14.1484 - val_accuracy: 0.8613\n",
      "Epoch 1821/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.1099 - accuracy: 0.8681 - val_loss: 21.5879 - val_accuracy: 0.8623\n",
      "Epoch 1822/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1260 - accuracy: 0.8508 - val_loss: 25.7644 - val_accuracy: 0.8671\n",
      "Epoch 1823/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8708 - accuracy: 0.8615 - val_loss: 14.8585 - val_accuracy: 0.8710\n",
      "Epoch 1824/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9545 - accuracy: 0.8598 - val_loss: 18.7343 - val_accuracy: 0.8167\n",
      "Epoch 1825/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.7578 - accuracy: 0.8567 - val_loss: 22.6987 - val_accuracy: 0.8429\n",
      "Epoch 1826/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.0393 - accuracy: 0.8586 - val_loss: 21.7842 - val_accuracy: 0.8555\n",
      "Epoch 1827/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.5616 - accuracy: 0.8712 - val_loss: 18.2380 - val_accuracy: 0.8574\n",
      "Epoch 1828/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8313 - accuracy: 0.8523 - val_loss: 17.1860 - val_accuracy: 0.8303\n",
      "Epoch 1829/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0651 - accuracy: 0.8533 - val_loss: 20.9482 - val_accuracy: 0.8700\n",
      "Epoch 1830/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8518 - accuracy: 0.8719 - val_loss: 24.4410 - val_accuracy: 0.8797\n",
      "Epoch 1831/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9137 - accuracy: 0.8761 - val_loss: 17.4452 - val_accuracy: 0.8526\n",
      "Epoch 1832/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0049 - accuracy: 0.8664 - val_loss: 22.3188 - val_accuracy: 0.9069\n",
      "Epoch 1833/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0710 - accuracy: 0.8678 - val_loss: 19.0936 - val_accuracy: 0.8700\n",
      "Epoch 1834/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.0172 - accuracy: 0.8729 - val_loss: 21.7890 - val_accuracy: 0.8497\n",
      "Epoch 1835/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0019 - accuracy: 0.8705 - val_loss: 13.7997 - val_accuracy: 0.8565\n",
      "Epoch 1836/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6770 - accuracy: 0.8715 - val_loss: 20.5857 - val_accuracy: 0.8642\n",
      "Epoch 1837/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.5318 - accuracy: 0.8671 - val_loss: 20.6305 - val_accuracy: 0.8632\n",
      "Epoch 1838/2000\n",
      "4123/4123 [==============================] - ETA: 0s - loss: 13.4599 - accuracy: 0.873 - 0s 21us/step - loss: 14.8942 - accuracy: 0.8746 - val_loss: 21.8516 - val_accuracy: 0.8691\n",
      "Epoch 1839/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8374 - accuracy: 0.8673 - val_loss: 21.7237 - val_accuracy: 0.8652\n",
      "Epoch 1840/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.0743 - accuracy: 0.8756 - val_loss: 17.1917 - val_accuracy: 0.8545\n",
      "Epoch 1841/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.1121 - accuracy: 0.8637 - val_loss: 16.9500 - val_accuracy: 0.8613\n",
      "Epoch 1842/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9092 - accuracy: 0.8710 - val_loss: 15.1142 - val_accuracy: 0.8312\n",
      "Epoch 1843/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.5526 - accuracy: 0.8705 - val_loss: 18.5792 - val_accuracy: 0.8555\n",
      "Epoch 1844/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8757 - accuracy: 0.8647 - val_loss: 18.7710 - val_accuracy: 0.8700\n",
      "Epoch 1845/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6183 - accuracy: 0.8518 - val_loss: 19.8816 - val_accuracy: 0.8632\n",
      "Epoch 1846/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2248 - accuracy: 0.8678 - val_loss: 21.3268 - val_accuracy: 0.8371\n",
      "Epoch 1847/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.2337 - accuracy: 0.8666 - val_loss: 24.3730 - val_accuracy: 0.8623\n",
      "Epoch 1848/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 15.1233 - accuracy: 0.8717 - val_loss: 17.7985 - val_accuracy: 0.8623\n",
      "Epoch 1849/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.5830 - accuracy: 0.8649 - val_loss: 18.6526 - val_accuracy: 0.8691\n",
      "Epoch 1850/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0395 - accuracy: 0.8690 - val_loss: 21.1150 - val_accuracy: 0.8565\n",
      "Epoch 1851/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8060 - accuracy: 0.8586 - val_loss: 20.6571 - val_accuracy: 0.8623\n",
      "Epoch 1852/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8443 - accuracy: 0.8671 - val_loss: 14.3964 - val_accuracy: 0.8671\n",
      "Epoch 1853/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.2201 - accuracy: 0.8693 - val_loss: 16.8946 - val_accuracy: 0.8671\n",
      "Epoch 1854/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7304 - accuracy: 0.8712 - val_loss: 14.2416 - val_accuracy: 0.8729\n",
      "Epoch 1855/2000\n",
      "4123/4123 [==============================] - 0s 28us/step - loss: 14.6806 - accuracy: 0.8831 - val_loss: 20.6224 - val_accuracy: 0.8661\n",
      "Epoch 1856/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.9436 - accuracy: 0.8765 - val_loss: 19.9096 - val_accuracy: 0.8429\n",
      "Epoch 1857/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.0608 - accuracy: 0.8719 - val_loss: 14.0494 - val_accuracy: 0.8749\n",
      "Epoch 1858/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.5811 - accuracy: 0.8763 - val_loss: 17.1581 - val_accuracy: 0.8535\n",
      "Epoch 1859/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 14.3755 - accuracy: 0.8710 - val_loss: 25.4998 - val_accuracy: 0.8691\n",
      "Epoch 1860/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.0814 - accuracy: 0.8700 - val_loss: 23.6326 - val_accuracy: 0.8807\n",
      "Epoch 1861/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 15.1348 - accuracy: 0.8814 - val_loss: 17.8967 - val_accuracy: 0.8206\n",
      "Epoch 1862/2000\n",
      "4123/4123 [==============================] - 0s 29us/step - loss: 14.7369 - accuracy: 0.8511 - val_loss: 15.2654 - val_accuracy: 0.8826\n",
      "Epoch 1863/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.7080 - accuracy: 0.8700 - val_loss: 19.4160 - val_accuracy: 0.8565\n",
      "Epoch 1864/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 14.6924 - accuracy: 0.8746 - val_loss: 20.9756 - val_accuracy: 0.8438\n",
      "Epoch 1865/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.0440 - accuracy: 0.8707 - val_loss: 20.3873 - val_accuracy: 0.8700\n",
      "Epoch 1866/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 14.7599 - accuracy: 0.8683 - val_loss: 21.8407 - val_accuracy: 0.8574\n",
      "Epoch 1867/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.1889 - accuracy: 0.8807 - val_loss: 22.1077 - val_accuracy: 0.8788\n",
      "Epoch 1868/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.1329 - accuracy: 0.8814 - val_loss: 19.0307 - val_accuracy: 0.8691\n",
      "Epoch 1869/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 14.9239 - accuracy: 0.8778 - val_loss: 17.6205 - val_accuracy: 0.8380\n",
      "Epoch 1870/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.2073 - accuracy: 0.8792 - val_loss: 16.6212 - val_accuracy: 0.8904\n",
      "Epoch 1871/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.5072 - accuracy: 0.8780 - val_loss: 16.4889 - val_accuracy: 0.8817\n",
      "Epoch 1872/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7276 - accuracy: 0.8729 - val_loss: 16.9232 - val_accuracy: 0.8758\n",
      "Epoch 1873/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7692 - accuracy: 0.8727 - val_loss: 15.7210 - val_accuracy: 0.8749\n",
      "Epoch 1874/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.9897 - accuracy: 0.8673 - val_loss: 21.2853 - val_accuracy: 0.8603\n",
      "Epoch 1875/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.5688 - accuracy: 0.8736 - val_loss: 17.8143 - val_accuracy: 0.8574\n",
      "Epoch 1876/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8284 - accuracy: 0.8656 - val_loss: 19.5888 - val_accuracy: 0.8293\n",
      "Epoch 1877/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1368 - accuracy: 0.8644 - val_loss: 19.2837 - val_accuracy: 0.8778\n",
      "Epoch 1878/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0414 - accuracy: 0.8809 - val_loss: 21.2916 - val_accuracy: 0.8623\n",
      "Epoch 1879/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9035 - accuracy: 0.8700 - val_loss: 20.9371 - val_accuracy: 0.8497\n",
      "Epoch 1880/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.6287 - accuracy: 0.8690 - val_loss: 19.4760 - val_accuracy: 0.8691\n",
      "Epoch 1881/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7942 - accuracy: 0.8678 - val_loss: 20.5302 - val_accuracy: 0.8118\n",
      "Epoch 1882/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.1479 - accuracy: 0.8584 - val_loss: 18.7236 - val_accuracy: 0.8661\n",
      "Epoch 1883/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8465 - accuracy: 0.8792 - val_loss: 19.0231 - val_accuracy: 0.8565\n",
      "Epoch 1884/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8343 - accuracy: 0.8765 - val_loss: 25.9699 - val_accuracy: 0.8565\n",
      "Epoch 1885/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.5286 - accuracy: 0.8770 - val_loss: 19.4404 - val_accuracy: 0.8875\n",
      "Epoch 1886/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.7219 - accuracy: 0.8642 - val_loss: 20.6691 - val_accuracy: 0.8797\n",
      "Epoch 1887/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9550 - accuracy: 0.8664 - val_loss: 20.4301 - val_accuracy: 0.8681\n",
      "Epoch 1888/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7713 - accuracy: 0.8719 - val_loss: 19.0302 - val_accuracy: 0.8720\n",
      "Epoch 1889/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7052 - accuracy: 0.8639 - val_loss: 16.7275 - val_accuracy: 0.8778\n",
      "Epoch 1890/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9516 - accuracy: 0.8695 - val_loss: 22.2165 - val_accuracy: 0.8739\n",
      "Epoch 1891/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.5130 - accuracy: 0.8550 - val_loss: 21.1457 - val_accuracy: 0.8797\n",
      "Epoch 1892/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.8560 - accuracy: 0.8741 - val_loss: 15.5021 - val_accuracy: 0.8739\n",
      "Epoch 1893/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.3872 - accuracy: 0.8797 - val_loss: 16.0406 - val_accuracy: 0.8526\n",
      "Epoch 1894/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7206 - accuracy: 0.8751 - val_loss: 20.2058 - val_accuracy: 0.8215\n",
      "Epoch 1895/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0210 - accuracy: 0.8695 - val_loss: 23.7522 - val_accuracy: 0.8603\n",
      "Epoch 1896/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0108 - accuracy: 0.8758 - val_loss: 18.9023 - val_accuracy: 0.8652\n",
      "Epoch 1897/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6538 - accuracy: 0.8829 - val_loss: 20.0442 - val_accuracy: 0.8623\n",
      "Epoch 1898/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9617 - accuracy: 0.8792 - val_loss: 19.9525 - val_accuracy: 0.8729\n",
      "Epoch 1899/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8023 - accuracy: 0.8799 - val_loss: 19.6387 - val_accuracy: 0.8632\n",
      "Epoch 1900/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.3644 - accuracy: 0.8722 - val_loss: 23.2610 - val_accuracy: 0.8545\n",
      "Epoch 1901/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9382 - accuracy: 0.8833 - val_loss: 23.0504 - val_accuracy: 0.8720\n",
      "Epoch 1902/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9672 - accuracy: 0.8644 - val_loss: 15.6976 - val_accuracy: 0.8642\n",
      "Epoch 1903/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7373 - accuracy: 0.8559 - val_loss: 20.9910 - val_accuracy: 0.8565\n",
      "Epoch 1904/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9515 - accuracy: 0.8768 - val_loss: 21.5637 - val_accuracy: 0.8642\n",
      "Epoch 1905/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8534 - accuracy: 0.8724 - val_loss: 20.7468 - val_accuracy: 0.8836\n",
      "Epoch 1906/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.4685 - accuracy: 0.8732 - val_loss: 27.7137 - val_accuracy: 0.8516\n",
      "Epoch 1907/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8233 - accuracy: 0.8748 - val_loss: 14.7102 - val_accuracy: 0.8671\n",
      "Epoch 1908/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.3048 - accuracy: 0.8615 - val_loss: 19.3458 - val_accuracy: 0.8526\n",
      "Epoch 1909/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9496 - accuracy: 0.8814 - val_loss: 16.5637 - val_accuracy: 0.8691\n",
      "Epoch 1910/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.9869 - accuracy: 0.8668 - val_loss: 22.6881 - val_accuracy: 0.8613\n",
      "Epoch 1911/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7891 - accuracy: 0.8773 - val_loss: 20.4241 - val_accuracy: 0.8817\n",
      "Epoch 1912/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6256 - accuracy: 0.8780 - val_loss: 21.4003 - val_accuracy: 0.8885\n",
      "Epoch 1913/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8497 - accuracy: 0.8765 - val_loss: 20.5992 - val_accuracy: 0.8380\n",
      "Epoch 1914/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.9742 - accuracy: 0.8647 - val_loss: 26.4034 - val_accuracy: 0.7992\n",
      "Epoch 1915/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.4202 - accuracy: 0.8668 - val_loss: 16.0920 - val_accuracy: 0.8186\n",
      "Epoch 1916/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9572 - accuracy: 0.8715 - val_loss: 16.8413 - val_accuracy: 0.8497\n",
      "Epoch 1917/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0433 - accuracy: 0.8724 - val_loss: 15.3275 - val_accuracy: 0.8545\n",
      "Epoch 1918/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6634 - accuracy: 0.8778 - val_loss: 21.6282 - val_accuracy: 0.8002\n",
      "Epoch 1919/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.8206 - accuracy: 0.8637 - val_loss: 24.5501 - val_accuracy: 0.8235\n",
      "Epoch 1920/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9739 - accuracy: 0.8695 - val_loss: 21.5649 - val_accuracy: 0.8807\n",
      "Epoch 1921/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9597 - accuracy: 0.8785 - val_loss: 19.9834 - val_accuracy: 0.8419\n",
      "Epoch 1922/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0724 - accuracy: 0.8792 - val_loss: 19.8546 - val_accuracy: 0.8661\n",
      "Epoch 1923/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7087 - accuracy: 0.8651 - val_loss: 20.2506 - val_accuracy: 0.8865\n",
      "Epoch 1924/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9868 - accuracy: 0.8785 - val_loss: 22.3571 - val_accuracy: 0.8603\n",
      "Epoch 1925/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9211 - accuracy: 0.8756 - val_loss: 16.5677 - val_accuracy: 0.8778\n",
      "Epoch 1926/2000\n",
      "4123/4123 [==============================] - 0s 28us/step - loss: 14.7608 - accuracy: 0.8809 - val_loss: 20.3784 - val_accuracy: 0.8691\n",
      "Epoch 1927/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.1716 - accuracy: 0.8712 - val_loss: 20.7653 - val_accuracy: 0.8167\n",
      "Epoch 1928/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 15.0218 - accuracy: 0.8659 - val_loss: 25.0011 - val_accuracy: 0.8196\n",
      "Epoch 1929/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 14.7401 - accuracy: 0.8785 - val_loss: 18.4233 - val_accuracy: 0.8729\n",
      "Epoch 1930/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 14.5604 - accuracy: 0.8748 - val_loss: 19.1098 - val_accuracy: 0.8807\n",
      "Epoch 1931/2000\n",
      "4123/4123 [==============================] - 0s 30us/step - loss: 14.8062 - accuracy: 0.8695 - val_loss: 20.1540 - val_accuracy: 0.8632\n",
      "Epoch 1932/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.9200 - accuracy: 0.8668 - val_loss: 27.0410 - val_accuracy: 0.8729\n",
      "Epoch 1933/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8778 - accuracy: 0.8763 - val_loss: 19.2376 - val_accuracy: 0.8826\n",
      "Epoch 1934/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7383 - accuracy: 0.8799 - val_loss: 20.6041 - val_accuracy: 0.8875\n",
      "Epoch 1935/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9112 - accuracy: 0.8778 - val_loss: 20.4155 - val_accuracy: 0.8885\n",
      "Epoch 1936/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.7914 - accuracy: 0.8790 - val_loss: 18.7101 - val_accuracy: 0.8671\n",
      "Epoch 1937/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7703 - accuracy: 0.8676 - val_loss: 16.0669 - val_accuracy: 0.8749\n",
      "Epoch 1938/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8017 - accuracy: 0.8586 - val_loss: 22.8087 - val_accuracy: 0.8487\n",
      "Epoch 1939/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8473 - accuracy: 0.8685 - val_loss: 17.7180 - val_accuracy: 0.8186\n",
      "Epoch 1940/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9667 - accuracy: 0.8644 - val_loss: 17.9442 - val_accuracy: 0.8768\n",
      "Epoch 1941/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7417 - accuracy: 0.8761 - val_loss: 15.8018 - val_accuracy: 0.8749\n",
      "Epoch 1942/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6866 - accuracy: 0.8715 - val_loss: 15.5652 - val_accuracy: 0.8632\n",
      "Epoch 1943/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7145 - accuracy: 0.8734 - val_loss: 16.7542 - val_accuracy: 0.8904\n",
      "Epoch 1944/2000\n",
      "4123/4123 [==============================] - 0s 20us/step - loss: 14.3876 - accuracy: 0.8756 - val_loss: 20.0976 - val_accuracy: 0.8594\n",
      "Epoch 1945/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8183 - accuracy: 0.8707 - val_loss: 18.3784 - val_accuracy: 0.8371\n",
      "Epoch 1946/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0076 - accuracy: 0.8625 - val_loss: 14.7848 - val_accuracy: 0.8807\n",
      "Epoch 1947/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7917 - accuracy: 0.8768 - val_loss: 25.6193 - val_accuracy: 0.8700\n",
      "Epoch 1948/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 14.9745 - accuracy: 0.8775 - val_loss: 23.0723 - val_accuracy: 0.8836\n",
      "Epoch 1949/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 14.8340 - accuracy: 0.8715 - val_loss: 25.2343 - val_accuracy: 0.8448\n",
      "Epoch 1950/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.7167 - accuracy: 0.8787 - val_loss: 17.0451 - val_accuracy: 0.8875\n",
      "Epoch 1951/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 14.8780 - accuracy: 0.8821 - val_loss: 21.6613 - val_accuracy: 0.8710\n",
      "Epoch 1952/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.9045 - accuracy: 0.8778 - val_loss: 20.0790 - val_accuracy: 0.8817\n",
      "Epoch 1953/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.8015 - accuracy: 0.8802 - val_loss: 25.4194 - val_accuracy: 0.8720\n",
      "Epoch 1954/2000\n",
      "4123/4123 [==============================] - 0s 26us/step - loss: 14.8101 - accuracy: 0.8770 - val_loss: 19.3148 - val_accuracy: 0.8778\n",
      "Epoch 1955/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.0114 - accuracy: 0.8802 - val_loss: 22.0815 - val_accuracy: 0.8652\n",
      "Epoch 1956/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.8308 - accuracy: 0.8727 - val_loss: 13.9786 - val_accuracy: 0.8826\n",
      "Epoch 1957/2000\n",
      "4123/4123 [==============================] - 0s 24us/step - loss: 14.4608 - accuracy: 0.8688 - val_loss: 17.0196 - val_accuracy: 0.8826\n",
      "Epoch 1958/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.6911 - accuracy: 0.8688 - val_loss: 20.2089 - val_accuracy: 0.8671\n",
      "Epoch 1959/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 15.0763 - accuracy: 0.8702 - val_loss: 19.6458 - val_accuracy: 0.8613\n",
      "Epoch 1960/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.9605 - accuracy: 0.8668 - val_loss: 22.6724 - val_accuracy: 0.8526\n",
      "Epoch 1961/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6135 - accuracy: 0.8746 - val_loss: 20.8808 - val_accuracy: 0.8826\n",
      "Epoch 1962/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6499 - accuracy: 0.8865 - val_loss: 16.7580 - val_accuracy: 0.8758\n",
      "Epoch 1963/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.1940 - accuracy: 0.8799 - val_loss: 16.3987 - val_accuracy: 0.8574\n",
      "Epoch 1964/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8966 - accuracy: 0.8795 - val_loss: 22.3815 - val_accuracy: 0.8671\n",
      "Epoch 1965/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.5576 - accuracy: 0.8763 - val_loss: 22.5882 - val_accuracy: 0.8788\n",
      "Epoch 1966/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0677 - accuracy: 0.8809 - val_loss: 16.5949 - val_accuracy: 0.8652\n",
      "Epoch 1967/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7984 - accuracy: 0.8841 - val_loss: 20.8034 - val_accuracy: 0.8555\n",
      "Epoch 1968/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8871 - accuracy: 0.8649 - val_loss: 16.2905 - val_accuracy: 0.8855\n",
      "Epoch 1969/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7956 - accuracy: 0.8778 - val_loss: 22.2914 - val_accuracy: 0.8875\n",
      "Epoch 1970/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0500 - accuracy: 0.8792 - val_loss: 16.9645 - val_accuracy: 0.8758\n",
      "Epoch 1971/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.4092 - accuracy: 0.8790 - val_loss: 22.8402 - val_accuracy: 0.9040\n",
      "Epoch 1972/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9107 - accuracy: 0.8695 - val_loss: 21.4970 - val_accuracy: 0.8797\n",
      "Epoch 1973/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6657 - accuracy: 0.8603 - val_loss: 22.7521 - val_accuracy: 0.8254\n",
      "Epoch 1974/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.5668 - accuracy: 0.8748 - val_loss: 24.1400 - val_accuracy: 0.8322\n",
      "Epoch 1975/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.6320 - accuracy: 0.8853 - val_loss: 24.0064 - val_accuracy: 0.8574\n",
      "Epoch 1976/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6768 - accuracy: 0.8724 - val_loss: 23.5344 - val_accuracy: 0.8497\n",
      "Epoch 1977/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.7477 - accuracy: 0.8710 - val_loss: 16.7615 - val_accuracy: 0.8914\n",
      "Epoch 1978/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7067 - accuracy: 0.8722 - val_loss: 19.0322 - val_accuracy: 0.8952\n",
      "Epoch 1979/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8296 - accuracy: 0.8744 - val_loss: 21.4498 - val_accuracy: 0.8865\n",
      "Epoch 1980/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.4142 - accuracy: 0.8797 - val_loss: 19.8805 - val_accuracy: 0.8904\n",
      "Epoch 1981/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 15.0253 - accuracy: 0.8778 - val_loss: 20.3002 - val_accuracy: 0.8729\n",
      "Epoch 1982/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 14.8311 - accuracy: 0.8790 - val_loss: 18.5331 - val_accuracy: 0.8710\n",
      "Epoch 1983/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.8535 - accuracy: 0.8765 - val_loss: 23.8838 - val_accuracy: 0.8477\n",
      "Epoch 1984/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.9524 - accuracy: 0.8681 - val_loss: 20.2490 - val_accuracy: 0.8681\n",
      "Epoch 1985/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9082 - accuracy: 0.8756 - val_loss: 20.6809 - val_accuracy: 0.8594\n",
      "Epoch 1986/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.9221 - accuracy: 0.8807 - val_loss: 21.6955 - val_accuracy: 0.8574\n",
      "Epoch 1987/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8173 - accuracy: 0.8741 - val_loss: 19.6464 - val_accuracy: 0.8807\n",
      "Epoch 1988/2000\n",
      "4123/4123 [==============================] - 0s 23us/step - loss: 15.0327 - accuracy: 0.8712 - val_loss: 19.0374 - val_accuracy: 0.8778\n",
      "Epoch 1989/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7386 - accuracy: 0.8724 - val_loss: 17.2687 - val_accuracy: 0.8700\n",
      "Epoch 1990/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.6803 - accuracy: 0.8654 - val_loss: 23.2191 - val_accuracy: 0.8526\n",
      "Epoch 1991/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8057 - accuracy: 0.8758 - val_loss: 17.2345 - val_accuracy: 0.8468\n",
      "Epoch 1992/2000\n",
      "4123/4123 [==============================] - 0s 21us/step - loss: 14.7635 - accuracy: 0.8681 - val_loss: 25.9873 - val_accuracy: 0.7944\n",
      "Epoch 1993/2000\n",
      "4123/4123 [==============================] - 0s 22us/step - loss: 14.8360 - accuracy: 0.8736 - val_loss: 22.1364 - val_accuracy: 0.8885\n",
      "Epoch 1994/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 14.7692 - accuracy: 0.8605 - val_loss: 23.1439 - val_accuracy: 0.8448\n",
      "Epoch 1995/2000\n",
      "4123/4123 [==============================] - 0s 27us/step - loss: 14.8562 - accuracy: 0.8554 - val_loss: 23.7886 - val_accuracy: 0.8254\n",
      "Epoch 1996/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.7690 - accuracy: 0.8751 - val_loss: 19.3411 - val_accuracy: 0.8681\n",
      "Epoch 1997/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.6654 - accuracy: 0.8702 - val_loss: 19.4337 - val_accuracy: 0.8817\n",
      "Epoch 1998/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.8849 - accuracy: 0.8746 - val_loss: 21.9436 - val_accuracy: 0.8671\n",
      "Epoch 1999/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 14.9391 - accuracy: 0.8797 - val_loss: 20.4626 - val_accuracy: 0.8729\n",
      "Epoch 2000/2000\n",
      "4123/4123 [==============================] - 0s 25us/step - loss: 15.0266 - accuracy: 0.8719 - val_loss: 15.6940 - val_accuracy: 0.8807\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_test,y_test), epochs=training_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1751.76773078   84.47641139 1694.46276816   50.81048621 1618.58402303\n",
      "   64.54566391 1767.68374248   60.84249749 1844.7595246    44.2053483\n",
      " 1584.34925926  180.71388889 1666.16998469  123.59915773 1666.54179586\n",
      "   82.07745365 1790.13368984  145.61377604 1610.11135997  113.62685899\n",
      " 1773.43449872   33.07627471 1697.67095023   88.46600302 1715.23625897\n",
      "  163.7135084  1506.10597983  156.43760036 1635.25868951  156.46682189]\n",
      "[1754.5549     91.64721  1695.4012     51.62926  1620.1421     66.634186\n",
      " 1769.8777     60.849033 1846.1808     39.312065 1598.3193    182.69206\n",
      " 1668.8192    124.254974 1671.3055     86.821045 1793.9081    147.4376\n",
      " 1619.6869    111.64371  1777.5789     31.942505 1699.1553     97.138\n",
      " 1721.9653    165.9671   1513.5698    164.71869  1636.6245    158.32753 ]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print(y_test[0])\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss']) \n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for y_1 -> y_2\n",
      "--------------------------------------\n",
      "RMSE is 282.7448210112196\n",
      "R2 score is 0.8324789873154358\n",
      "\n",
      "\n",
      "The model performance for y_2 -> y_3\n",
      "--------------------------------------\n",
      "RMSE is 347.23366007038794\n",
      "R2 score is 0.6704590737926245\n",
      "\n",
      "\n",
      "The model performance for y_3 -> y_4\n",
      "--------------------------------------\n",
      "RMSE is 401.9622510448943\n",
      "R2 score is 0.4661864241475423\n",
      "\n",
      "\n",
      "The model performance for y_4 -> y_5\n",
      "--------------------------------------\n",
      "RMSE is 450.56106878386277\n",
      "R2 score is 0.22825854078079166\n",
      "\n",
      "\n",
      "The model performance for y_5 -> y_6\n",
      "--------------------------------------\n",
      "RMSE is 494.8666270619463\n",
      "R2 score is -0.049278203704609065\n",
      "\n",
      "\n",
      "The model performance for y_6 -> y_7\n",
      "--------------------------------------\n",
      "RMSE is 536.0094140406396\n",
      "R2 score is -0.3677914049323256\n",
      "\n",
      "\n",
      "The model performance for y_7 -> y_8\n",
      "--------------------------------------\n",
      "RMSE is 574.612733854102\n",
      "R2 score is -0.7107179197638236\n",
      "\n",
      "\n",
      "The model performance for y_8 -> y_9\n",
      "--------------------------------------\n",
      "RMSE is 611.1447584476293\n",
      "R2 score is -1.0945042208288212\n",
      "\n",
      "\n",
      "The model performance for y_9 -> y_10\n",
      "--------------------------------------\n",
      "RMSE is 645.9402813195188\n",
      "R2 score is -1.5216198002627939\n",
      "\n",
      "\n",
      "The model performance for y_10 -> y_11\n",
      "--------------------------------------\n",
      "RMSE is 679.2611874166508\n",
      "R2 score is -1.9837001109559944\n",
      "\n",
      "\n",
      "The model performance for y_11 -> y_12\n",
      "--------------------------------------\n",
      "RMSE is 711.3210086529783\n",
      "R2 score is -2.510523955217769\n",
      "\n",
      "\n",
      "The model performance for y_12 -> y_13\n",
      "--------------------------------------\n",
      "RMSE is 742.3052323706133\n",
      "R2 score is -3.105993662650581\n",
      "\n",
      "\n",
      "The model performance for y_13 -> y_14\n",
      "--------------------------------------\n",
      "RMSE is 772.3386481590259\n",
      "R2 score is -3.7547447367465376\n",
      "\n",
      "\n",
      "The model performance for y_14 -> y_15\n",
      "--------------------------------------\n",
      "RMSE is 801.5325414816309\n",
      "R2 score is -4.436254242401949\n",
      "\n",
      "\n",
      "The model performance for y_15 -> y_16\n",
      "--------------------------------------\n",
      "RMSE is 829.9927559319042\n",
      "R2 score is -5.169990379563003\n",
      "\n",
      "\n",
      "The model performance for y_16 -> y_17\n",
      "--------------------------------------\n",
      "RMSE is 857.8968669862321\n",
      "R2 score is -5.9059736281399715\n",
      "\n",
      "\n",
      "The model performance for y_17 -> y_18\n",
      "--------------------------------------\n",
      "RMSE is 885.31693507774\n",
      "R2 score is -6.700784147377807\n",
      "\n",
      "\n",
      "The model performance for y_18 -> y_19\n",
      "--------------------------------------\n",
      "RMSE is 912.3135917013868\n",
      "R2 score is -7.552693449871546\n",
      "\n",
      "\n",
      "The model performance for y_19 -> y_20\n",
      "--------------------------------------\n",
      "RMSE is 938.9333222590931\n",
      "R2 score is -8.458009392989409\n",
      "\n",
      "\n",
      "The model performance for y_20 -> y_21\n",
      "--------------------------------------\n",
      "RMSE is 965.2338197502687\n",
      "R2 score is -9.406585228222896\n",
      "\n",
      "\n",
      "The model performance for y_21 -> y_22\n",
      "--------------------------------------\n",
      "RMSE is 991.2702848797969\n",
      "R2 score is -10.400388975638524\n",
      "\n",
      "\n",
      "The model performance for y_22 -> y_23\n",
      "--------------------------------------\n",
      "RMSE is 1017.1146492360076\n",
      "R2 score is -11.441736928911462\n",
      "\n",
      "\n",
      "The model performance for y_23 -> y_24\n",
      "--------------------------------------\n",
      "RMSE is 1042.8213584413813\n",
      "R2 score is -12.536215536587061\n",
      "\n",
      "\n",
      "The model performance for y_24 -> y_25\n",
      "--------------------------------------\n",
      "RMSE is 1068.40727675869\n",
      "R2 score is -13.683746568164578\n",
      "\n",
      "\n",
      "The model performance for y_25 -> y_26\n",
      "--------------------------------------\n",
      "RMSE is 1093.8477867657423\n",
      "R2 score is -14.874646157629481\n",
      "\n",
      "\n",
      "The model performance for y_26 -> y_27\n",
      "--------------------------------------\n",
      "RMSE is 1119.1851762206588\n",
      "R2 score is -16.102767056669187\n",
      "\n",
      "\n",
      "The model performance for y_27 -> y_28\n",
      "--------------------------------------\n",
      "RMSE is 1144.4378714193358\n",
      "R2 score is -17.35701321116443\n",
      "\n",
      "\n",
      "The model performance for y_28 -> y_29\n",
      "--------------------------------------\n",
      "RMSE is 1169.6284059666189\n",
      "R2 score is -18.63159855868887\n",
      "\n",
      "\n",
      "The model performance for y_29 -> y_30\n",
      "--------------------------------------\n",
      "RMSE is 1194.7514971259889\n",
      "R2 score is -19.93706494437563\n",
      "\n",
      "\n",
      "The model performance for y_30 -> y_31\n",
      "--------------------------------------\n",
      "RMSE is 1219.811325870419\n",
      "R2 score is -21.288068266839705\n",
      "\n",
      "\n",
      "The model performance for y_31 -> y_32\n",
      "--------------------------------------\n",
      "RMSE is 1244.8187326981351\n",
      "R2 score is -22.683095990677387\n",
      "\n",
      "\n",
      "The model performance for y_32 -> y_33\n",
      "--------------------------------------\n",
      "RMSE is 1269.7812973692198\n",
      "R2 score is -24.137035876215894\n",
      "\n",
      "\n",
      "The model performance for y_33 -> y_34\n",
      "--------------------------------------\n",
      "RMSE is 1294.69634423986\n",
      "R2 score is -25.65980893982594\n",
      "\n",
      "\n",
      "The model performance for y_34 -> y_35\n",
      "--------------------------------------\n",
      "RMSE is 1319.5655208694207\n",
      "R2 score is -27.240452619812054\n",
      "\n",
      "\n",
      "The model performance for y_35 -> y_36\n",
      "--------------------------------------\n",
      "RMSE is 1344.4083980405462\n",
      "R2 score is -28.875002252265876\n",
      "\n",
      "\n",
      "The model performance for y_36 -> y_37\n",
      "--------------------------------------\n",
      "RMSE is 1369.2185308901696\n",
      "R2 score is -30.551860735521927\n",
      "\n",
      "\n",
      "The model performance for y_37 -> y_38\n",
      "--------------------------------------\n",
      "RMSE is 1393.9966917146976\n",
      "R2 score is -32.277594090911194\n",
      "\n",
      "\n",
      "The model performance for y_38 -> y_39\n",
      "--------------------------------------\n",
      "RMSE is 1418.756780588371\n",
      "R2 score is -34.03673391615499\n",
      "\n",
      "\n",
      "The model performance for y_39 -> y_40\n",
      "--------------------------------------\n",
      "RMSE is 1443.5295482791778\n",
      "R2 score is -35.82957497216077\n",
      "\n",
      "\n",
      "The model performance for y_40 -> y_41\n",
      "--------------------------------------\n",
      "RMSE is 1468.3653430485028\n",
      "R2 score is -37.6385112067283\n",
      "\n",
      "\n",
      "The model performance for y_41 -> y_42\n",
      "--------------------------------------\n",
      "RMSE is 1493.277479058569\n",
      "R2 score is -39.48378480791674\n",
      "\n",
      "\n",
      "The model performance for y_42 -> y_43\n",
      "--------------------------------------\n",
      "RMSE is 1518.2748790145895\n",
      "R2 score is -41.3518011313641\n",
      "\n",
      "\n",
      "The model performance for y_43 -> y_44\n",
      "--------------------------------------\n",
      "RMSE is 1543.3805359582716\n",
      "R2 score is -43.23695635010416\n",
      "\n",
      "\n",
      "The model performance for y_44 -> y_45\n",
      "--------------------------------------\n",
      "RMSE is 1568.6516988744613\n",
      "R2 score is -45.13512806619883\n",
      "\n",
      "\n",
      "The model performance for y_45 -> y_46\n",
      "--------------------------------------\n",
      "RMSE is 1594.1054129097136\n",
      "R2 score is -47.036582471825206\n",
      "\n",
      "\n",
      "The model performance for y_46 -> y_47\n",
      "--------------------------------------\n",
      "RMSE is 1619.7487042739442\n",
      "R2 score is -48.945572154533274\n",
      "\n",
      "\n",
      "The model performance for y_47 -> y_48\n",
      "--------------------------------------\n",
      "RMSE is 1645.5758231826603\n",
      "R2 score is -50.86814483160269\n",
      "\n",
      "\n",
      "The model performance for y_48 -> y_49\n",
      "--------------------------------------\n",
      "RMSE is 1671.571261979309\n",
      "R2 score is -52.767126030339824\n",
      "\n",
      "\n",
      "The model performance for y_49 -> y_50\n",
      "--------------------------------------\n",
      "RMSE is 1697.6667616330753\n",
      "R2 score is -54.6835353943197\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_i_predict =  model.predict(np.array(X))\n",
    "for i in range(1, n):\n",
    "    y_i_predict = model.predict(y_i_predict)\n",
    "    rmse = (np.sqrt(mean_squared_error(df_n_rounds['y_' + str(i+1)].tolist(), y_i_predict)))\n",
    "    r2 = r2_score(df_n_rounds['y_' + str(i+1)].tolist(), y_i_predict)\n",
    "\n",
    "    print(\"The model performance for y_{} -> y_{}\".format(i, i+1))\n",
    "    print(\"--------------------------------------\")\n",
    "    print('RMSE is {}'.format(rmse))\n",
    "    print('R2 score is {}'.format(r2))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bitf17e3ae0e0b5412f8624a209625ef4a0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
